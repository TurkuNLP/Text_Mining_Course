{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering exercises\n",
    "\n",
    "This is a modified, more compact version of some of code from the notebook on clustering. You may wish to use this as a starting point for doing some of the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Import the necessary libraries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import sklearn.cluster\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data\n",
    "\n",
    "Note that the word vector files are found on the server, so you need to either work there or make copies.\n",
    "\n",
    "Feel free to add your own words here, but note that the code only loads vectors for the most common words (`limit` argument to `load_word2vec_format`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_WV_PATH = \"/course_data/textmine/wordvecs/GoogleNews-vectors-negative300.bin\"\n",
    "FI_WV_PATH = \"/course_data/textmine/wordvecs/pb34_wf_200_v2.bin\"\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(FI_WV_PATH, binary=True, limit=20000)\n",
    "words = [\n",
    "    \"koira\", \"kissa\", \"tietokone\", \"näyttö\", \"syödä\", \"juoda\", \"kävellä\", \"juosta\", \"yksi\", \"kaksi\", \"1\", \"2\",\n",
    "    \"hyvä\", \"paha\", \"ruma\", \"onnellinen\", \"onneton\", \"ja\", \"tai\", \"mitä\", \"että\", \"oikein\", \"todella\",\"hyvin\"\n",
    "]\n",
    "\n",
    "# If you prefer to work with English, uncomment the following lines:\n",
    "# wv = KeyedVectors.load_word2vec_format(EN_WV_PATH, binary=True, limit=20000)\n",
    "# words= [\n",
    "#     \"dog\", \"cat\", \"computer\", \"monitor\", \"eat\", \"drink\", \"walk\", \"run\", \"one\", \"two\", \"1\", \"2\",\n",
    "#     \"good\", \"bad\", \"ugly\", \"happy\", \"unhappy\", \"or\", \"what\", \"that\", \"right\", \"very\", \"well\"\n",
    "# ]\n",
    "\n",
    "wv.init_sims(replace=True)    # normalize\n",
    "\n",
    "word_indices = [wv.vocab[w].index for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sklearn.cluster.MiniBatchKMeans(batch_size=5000, n_clusters=20, random_state=1234)\n",
    "distances = k.fit_transform(wv.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_label(words, labels):\n",
    "    grouped = defaultdict(list)\n",
    "    for word, label in zip(words, labels):\n",
    "            grouped[label].append(word)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def show_grouped(words, labels):\n",
    "    grouped = group_by_label(words, labels)\n",
    "    return DataFrame(list(sorted(grouped.items())), columns=['label', 'words']).style.hide_index()\n",
    "\n",
    "\n",
    "show_grouped(words, k.labels_[word_indices])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
