{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "* Recognize named entities (places, people, events, companies, etc...) in text\n",
    "* It is a classification task, not a simple dictionary lookup problem\n",
    "    * Why? - list of entities is open and never complete\n",
    "    * Presence in a dictionary is of course a good feature\n",
    "    \n",
    "# NER as classification\n",
    "\n",
    "* Can't reasonably classify text (sub-)sequences\n",
    "* Must classify individual tokens\n",
    "* *BIO* coding most popular:\n",
    "    * A token can **B**egin an entity, be **I**nside an entity, or be **O**utside an entity\n",
    "    * Often the **B** class is associated with entity type\n",
    "* After this, it could be a very simple multiclass classification task. In the data below,\n",
    "  every token can belong to one of these five classes **B-org**, **I-org**, **B-pro**, **I-pro**, **O**\n",
    "* You can try to train a normal classifier on this data and see what happens\n",
    "    * Features: the word itself, POS tags, words before and after, word shape (capitalization, etc.) - whatever you find useful\n",
    "* These are all individual decisions on the tokens:\n",
    "    * **Independent of each other**\n",
    "    * Have prediction errors that you must deal with: I without B, B-org followed by I-pro, etc...\n",
    "    * You just do something with these errors\n",
    "    \n",
    "## NER data\n",
    "\n",
    "* Need annotated data to train\n",
    "* Lots of publicly available datasets for various languages and domains out there\n",
    "* Finnish: https://github.com/mpsilfve/finer-data\n",
    "    * Looks like this: https://github.com/mpsilfve/finer-data/blob/master/digitoday/ner_train_data_annotated/tietoturva_section/1.csv\n",
    "    * Needs to be turned into something like this:\n",
    "\n",
    "```\n",
    "B-org   Nokia\n",
    "O       ja\n",
    "B-org   Continental\n",
    "O       kehittävät\n",
    "O       erittäin\n",
    "O       tarkkaa\n",
    "O       karttateknologiaa\n",
    "B-pro   Electronic\n",
    "I-pro   Horizon\n",
    "I-pro   -alustalle\n",
    "O       ,\n",
    "O       jonka\n",
    "O       on\n",
    "O       tarkoitus\n",
    "O       pystyä\n",
    "O       jatkuvasti\n",
    "O       paikantamaan\n",
    "```\n",
    "  \n",
    "# Sequence classification\n",
    "\n",
    "* Individual decisions on tokens do not take into account dependencies between classes\n",
    "* Exactly the sort of \"*I must be preceded by B or I of same class*\" restrictions\n",
    "    * But also less hard, probabilistic constraints\n",
    "* Taking into account class dependencies gives a better model (hopefully :)\n",
    "\n",
    "## Hidden Markov Models (HMM)\n",
    "\n",
    "* The classic sequence classifier\n",
    "* Assume an underlying \"hidden\" sequence of class labels, which generates the visible sequence of words\n",
    "* Model the probability of a label following another one + a label producing a word\n",
    "    * P(I-pro|B-pro)\n",
    "    * P(Nokia|B-org)\n",
    "* These can be obtained by counting in the training data\n",
    "* Decoding: Viterbi algorithm - efficient polynomial algorithm to find the best hidden sequence of labels for the observed data (the sentence)\n",
    "* Restricted in its modelling capabilities by the generative approach it takes\n",
    "    * These two probabilities is pretty much all we've got to play with\n",
    "\n",
    "## Conditional Random Fields (CRF)\n",
    "\n",
    "I won't go into any real details here, you can check out one of the many tutorials out there if you want to know more about the inner workings of CRFs and the way they're trained. Like [this one](http://www.cs.upc.edu/~aquattoni/AllMyPapers/crf_tutorial_talk.pdf).\n",
    "\n",
    "* The go-to sequence classifier\n",
    "* Does not model in a generative manner like HMMs do:\n",
    "    * Arbitrary features, not just the HMM-style conditional probabilities\n",
    "    * The model learns weights for these features, much like an SVM would\n",
    "    * Anything you like from the input sequence can be turned into a feature\n",
    "    * In linear-chain CRFs, the current and previous (and future) tag also enters the equation\n",
    "* Trained in an iterative fashion (can get stuck in a local optimum)\n",
    "* Decoded in much the same way as HMMs - efficient polynomial algorithm to find the best sequence of labels\n",
    "\n",
    "* From a practical point of view:\n",
    "    * [CRFsuite](http://www.chokkan.org/software/crfsuite/) is a good general CRF training software\n",
    "    * [NERSuite](http://nersuite.nlplab.org/) a driver script for *CRFsuite* with predefined features tuned for the NER task\n",
    "    * CoreNLP also has a NER annotator (remember we played with it on one of the first lectures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NER pipeline for Finnish\n",
    "\n",
    "## Parsed training data\n",
    "\n",
    "* Contains NER label and selected columns from conllu\n",
    "\n",
    "```\n",
    "B-org   Nokia   Nokia   PROPN   Case=Nom|Number=Sing    nsubj\n",
    "O       ja      ja      CONJ    _       cc\n",
    "B-org   Continental     Continental     PROPN   Case=Nom|Number=Sing    conj\n",
    "O       kehittävät      kehittää        VERB    Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act root\n",
    "O       erittäin        erittäin        ADV     _       advmod\n",
    "O       tarkkaa tarkka  ADJ     Case=Par|Degree=Pos|Number=Sing amod\n",
    "O       karttateknologiaa       kartta#teknologia       NOUN    Case=Par|Number=Sing    dobj\n",
    "B-pro   Electronic      Electronic      PROPN   _       name\n",
    "I-pro   Horizon Horizon PROPN   Case=Gen|Number=Sing    nmod:poss\n",
    "I-pro   -alustalle      alusta  NOUN    Case=All|Number=Sing    nmod\n",
    "O       ,       ,       PUNCT   _       punct\n",
    "O       jonka   joka    PRON    Case=Gen|Number=Sing|PronType=Rel       nsubj\n",
    "O       on      olla    VERB    Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act cop\n",
    "O       tarkoitus       tarkoitus       NOUN    Case=Nom|Number=Sing    acl:relcl\n",
    "O       pystyä  pystyä  VERB    InfForm=1|Number=Sing|VerbForm=Inf|Voice=Act    xcomp:ds\n",
    "O       jatkuvasti      jatkuvasti      ADV     _       advmod\n",
    "O       paikantamaan    paikantaa       VERB    Case=Ill|InfForm=3|Number=Sing|VerbForm=Inf|Voice=Act   xcomp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 13497 sentences, 180178 examples, 13 classes \n",
      "\n",
      "155944 O\n",
      "8592 B-ORG\n",
      "4270 B-PRO\n",
      "2886 I-PRO\n",
      "2029 B-PER\n",
      "1937 I-ORG\n",
      "1754 B-LOC\n",
      "1094 I-PER\n",
      "904 B-DATE\n",
      "463 I-DATE\n",
      "131 I-LOC\n",
      "91 B-EVENT\n",
      "83 I-EVENT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import collections\n",
    "\n",
    "def read_data(f):\n",
    "    sent=[]\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        if not line:\n",
    "            if sent:\n",
    "                yield sent\n",
    "                sent=[]\n",
    "        else:\n",
    "            sent.append(line)\n",
    "    if sent:\n",
    "        yield sent\n",
    "        \n",
    "f=open(\"/course_data/textmine/ner-fi/digitoday.2014.train.conllu\", encoding=\"utf-8\")\n",
    "labels=[]\n",
    "examples=[]\n",
    "count=0\n",
    "for sent in read_data(f):\n",
    "    for i,line in enumerate(sent):\n",
    "        label,word=line.split(u\"\\t\")[:2]\n",
    "        labels.append(label)\n",
    "    count+=1\n",
    "f.close()\n",
    "\n",
    "print(\"Training data size:\", count, \"sentences,\", len(labels), \"examples,\", len(set(labels)), \"classes\", \"\\n\")\n",
    "        \n",
    "counter=collections.Counter(labels)\n",
    "for key in sorted(counter, key=counter.get, reverse=True):\n",
    "    print(counter[key],key)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "* simple features:\n",
    "* current: word, character n-grams, pos, morphology, dependency type, uppercased, is first/last token\n",
    "* previous/next: word, pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example featurized:\n",
      "O ['Im', 'mp', 'pe', 'er', 'ri', 'iu', 'um', 'mi', 'Imp', 'mpe', 'per', 'eri', 'riu', 'ium', 'umi', 'Impe', 'mper', 'peri', 'eriu', 'rium', 'iumi', 'word=Imperiumi', 'pos=NOUN', 'deprel=Case=Nom|Number=Sing', 'N', 'isupper', 'firsttoken', 'nextword=laajenee', 'nextpos=VERB', 'thisnext=VERBNOUN']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def create_features(i,sent,analyzer):\n",
    "    #        print token\n",
    "    feats=[]\n",
    "    cols=sent[i].split(u\"\\t\")\n",
    "    label,word=cols[0],cols[1]\n",
    "    feats=analyzer(word) # character n-grams\n",
    "    feats.append(u\"word=\"+word)\n",
    "    feats.append(u\"pos=\"+cols[3])\n",
    "    feats.append(u\"deprel=\"+cols[5])\n",
    "    if cols[4]!=u\"_\":\n",
    "        for fe in cols[4].split(u\"|\"):\n",
    "            feats.append(fe)\n",
    "    if word[0].isupper()==True:\n",
    "        feats.append(u\"isupper\")\n",
    "\n",
    "    if i!=0: # take previous token\n",
    "        feats.append(u\"preword=\"+sent[i-1].split(u\"\\t\")[1])\n",
    "        feats.append(u\"prepos=\"+sent[i-1].split(u\"\\t\")[3])\n",
    "        # pre and current pos\n",
    "        feats.append(u\"prethis=\"+sent[i-1].split(u\"\\t\")[3]+cols[3])\n",
    "    else:\n",
    "        feats.append(u\"firsttoken\")\n",
    "    if i<len(sent)-1:\n",
    "        feats.append(u\"nextword=\"+sent[i+1].split(u\"\\t\")[1])\n",
    "        feats.append(u\"nextpos=\"+sent[i+1].split(u\"\\t\")[3])\n",
    "        # current and next pos\n",
    "        feats.append(u\"thisnext=\"+sent[i+1].split(u\"\\t\")[3]+cols[3])\n",
    "    else:\n",
    "        feats.append(u\"lasttoken\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "import sklearn.feature_extraction\n",
    "vectorizer=sklearn.feature_extraction.text.TfidfVectorizer(analyzer='char',ngram_range=(2,4),lowercase=False)\n",
    "analyzer=vectorizer.build_analyzer()\n",
    "\n",
    "f=open(\"/course_data/textmine/ner-fi/digitoday.2014.train.conllu\", encoding=\"utf-8\")\n",
    "labels=[]\n",
    "examples=[]\n",
    "for sent in read_data(f):\n",
    "    for i,line in enumerate(sent):\n",
    "        label,word=line.split(u\"\\t\")[:2]\n",
    "        labels.append(label)\n",
    "        examples.append(create_features(i,sent,analyzer))\n",
    "    examples.append(None) # sentence boundary\n",
    "    labels.append(None)\n",
    "f.close()\n",
    "\n",
    "print(\"First example featurized:\")\n",
    "print(labels[0],examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save featurized data for crf\n",
    "\n",
    "* scikit learn does not have crf, so must save data and run it in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to train-data.featurized\n",
      "\n",
      "O\tIm\tmp\tpe\ter\tri\tiu\tum\tmi\tImp\tmpe\tper\teri\triu\tium\tumi\tImpe\tmper\tperi\teriu\trium\tiumi\tword=Imperiumi\tpos=NOUN\tdeprel=Case=Nom|Number=Sing\tN\tisupper\tfirsttoken\tnextword=laajenee\tnextpos=VERB\tthisnext=VERBNOUN\n",
      "\n",
      "O\tla\taa\taj\tje\ten\tne\tee\tlaa\taaj\taje\tjen\tene\tnee\tlaaj\taaje\tajen\tjene\tenee\tword=laajenee\tpos=VERB\tdeprel=Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\tV\tpreword=Imperiumi\tprepos=NOUN\tprethis=NOUNVERB\tnextword=_\tnextpos=PUNCT\tthisnext=PUNCTVERB\n",
      "\n",
      "O\tword=_\tpos=PUNCT\tdeprel=_\tPunct\tpreword=laajenee\tprepos=VERB\tprethis=VERBPUNCT\tnextword=Maailman\tnextpos=NOUN\tthisnext=NOUNPUNCT\n",
      "\n",
      "O\tMa\taa\tai\til\tlm\tma\tan\tMaa\taai\tail\tilm\tlma\tman\tMaai\taail\tailm\tilma\tlman\tword=Maailman\tpos=NOUN\tdeprel=Case=Gen|Number=Sing\tN\tisupper\tpreword=_\tprepos=PUNCT\tprethis=PUNCTNOUN\tnextword=suurin\tnextpos=ADJ\tthisnext=ADJNOUN\n",
      "\n",
      "O\tsu\tuu\tur\tri\tin\tsuu\tuur\turi\trin\tsuur\tuuri\turin\tword=suurin\tpos=ADJ\tdeprel=Case=Nom|Degree=Sup|Number=Sing\tA\tpreword=Maailman\tprepos=NOUN\tprethis=NOUNADJ\tnextword=verkkokauppa\tnextpos=NOUN\tthisnext=NOUNADJ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ffile=open(\"train-data.featurized\", \"w\", encoding=\"utf-8\")\n",
    "for example,label in zip(examples,labels):\n",
    "    if example is None: # add empty line, new sentence starts\n",
    "        assert label is None\n",
    "        ffile.write(u\"\\n\")\n",
    "        continue\n",
    "    feat=u\"\\t\".join(e for e in example)\n",
    "    feat=feat.replace(u\":\",u\"_\") # crfsuite special character, escape/change it\n",
    "    ffile.write(u\"\\t\".join(t for t in (label,feat))+u\"\\n\")\n",
    "ffile.close()\n",
    "print(\"Saved to train-data.featurized\")\n",
    "print()\n",
    "\n",
    "# just checking the file looks ok\n",
    "with open(\"train-data.featurized\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines()[:5]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 smp edu 3917818 Mar  8 14:01 x00\n",
      "-rw-r--r-- 1 smp edu 3897534 Mar  8 14:01 x01\n",
      "-rw-r--r-- 1 smp edu 3905399 Mar  8 14:01 x02\n",
      "-rw-r--r-- 1 smp edu 3925088 Mar  8 14:01 x03\n",
      "-rw-r--r-- 1 smp edu 3957527 Mar  8 14:01 x04\n",
      "-rw-r--r-- 1 smp edu 3980124 Mar  8 14:01 x05\n",
      "-rw-r--r-- 1 smp edu 3962859 Mar  8 14:01 x06\n",
      "-rw-r--r-- 1 smp edu 3938585 Mar  8 14:01 x07\n",
      "-rw-r--r-- 1 smp edu 3810774 Mar  8 14:01 x08\n",
      "-rw-r--r-- 1 smp edu 2719565 Mar  8 14:01 x09\n",
      "CRFSuite 0.12.2  Copyright (c) 2007-2013 Naoaki Okazaki\n",
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 223293\n",
      "Seconds required: 1.318\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.000000\n",
      "c2: 1.000000\n",
      "num_memories: 6\n",
      "max_iterations: 80\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 269673.650303\n",
      "Feature norm: 1.000000\n",
      "Error norm: 175744.610692\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 0.000005\n",
      "Seconds required for this iteration: 1.000\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 137015.950120\n",
      "Feature norm: 3.830317\n",
      "Error norm: 57373.738941\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.343316\n",
      "Seconds required for this iteration: 1.060\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 106803.245227\n",
      "Feature norm: 3.576801\n",
      "Error norm: 47589.634319\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.567\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 76611.859336\n",
      "Feature norm: 3.503955\n",
      "Error norm: 17596.140484\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.377064\n",
      "Seconds required for this iteration: 1.014\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 71093.462820\n",
      "Feature norm: 3.838386\n",
      "Error norm: 13767.265370\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.512\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 53284.933284\n",
      "Feature norm: 5.592793\n",
      "Error norm: 8926.617394\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.506\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 44191.033782\n",
      "Feature norm: 8.096894\n",
      "Error norm: 10860.273941\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.515\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 37955.830785\n",
      "Feature norm: 9.559087\n",
      "Error norm: 6328.795708\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.521\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 34538.877197\n",
      "Feature norm: 10.839324\n",
      "Error norm: 5697.454445\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.545\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 31903.132358\n",
      "Feature norm: 12.008866\n",
      "Error norm: 4632.640721\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.553\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 26906.743881\n",
      "Feature norm: 14.969590\n",
      "Error norm: 5525.416232\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.511\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 23737.611162\n",
      "Feature norm: 18.978316\n",
      "Error norm: 3757.032662\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.506\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 22680.864207\n",
      "Feature norm: 19.072599\n",
      "Error norm: 2461.441656\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.506\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 21308.666904\n",
      "Feature norm: 19.059568\n",
      "Error norm: 2519.158593\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.520\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 20196.078277\n",
      "Feature norm: 19.423594\n",
      "Error norm: 3032.830571\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.521\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 19177.169834\n",
      "Feature norm: 21.437912\n",
      "Error norm: 6149.561572\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.497\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 17439.156434\n",
      "Feature norm: 21.496975\n",
      "Error norm: 1918.734662\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.500\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 16812.013535\n",
      "Feature norm: 21.949609\n",
      "Error norm: 1656.208007\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.516\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 16025.011268\n",
      "Feature norm: 22.981995\n",
      "Error norm: 1954.640057\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.500\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 15592.890671\n",
      "Feature norm: 25.495058\n",
      "Error norm: 4901.125121\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.497\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 14472.265551\n",
      "Feature norm: 26.087410\n",
      "Error norm: 1649.901281\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.520\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 14098.584869\n",
      "Feature norm: 26.597509\n",
      "Error norm: 1176.741210\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.507\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 13520.440642\n",
      "Feature norm: 27.862812\n",
      "Error norm: 1388.754452\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.498\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 12772.382842\n",
      "Feature norm: 29.722058\n",
      "Error norm: 1838.318011\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.503\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 12331.554494\n",
      "Feature norm: 33.667378\n",
      "Error norm: 3162.585448\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.513\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 11659.183209\n",
      "Feature norm: 32.898911\n",
      "Error norm: 1110.902713\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.504\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 11428.429877\n",
      "Feature norm: 33.061971\n",
      "Error norm: 794.227554\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.513\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 11153.278267\n",
      "Feature norm: 33.625100\n",
      "Error norm: 858.220798\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.508\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 10698.340667\n",
      "Feature norm: 35.171520\n",
      "Error norm: 1049.109063\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.493\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 10447.092449\n",
      "Feature norm: 36.755354\n",
      "Error norm: 1696.732014\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.333804\n",
      "Seconds required for this iteration: 1.038\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 10089.551628\n",
      "Feature norm: 38.307644\n",
      "Error norm: 933.619363\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.494\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 9801.309479\n",
      "Feature norm: 39.795465\n",
      "Error norm: 657.729649\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.506\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 9519.723026\n",
      "Feature norm: 41.323321\n",
      "Error norm: 751.026608\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.480\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 9489.529414\n",
      "Feature norm: 43.972520\n",
      "Error norm: 2759.800141\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.515\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 9030.281642\n",
      "Feature norm: 44.175105\n",
      "Error norm: 879.988228\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.497\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 8891.002570\n",
      "Feature norm: 44.316947\n",
      "Error norm: 508.511944\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.503\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 8751.114139\n",
      "Feature norm: 44.670690\n",
      "Error norm: 572.137613\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.468\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 8588.113509\n",
      "Feature norm: 45.212126\n",
      "Error norm: 600.201892\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.484\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 8460.353634\n",
      "Feature norm: 46.351164\n",
      "Error norm: 1154.625045\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.355320\n",
      "Seconds required for this iteration: 0.982\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 8251.892117\n",
      "Feature norm: 47.382586\n",
      "Error norm: 594.631546\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.491\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 8104.018896\n",
      "Feature norm: 48.341015\n",
      "Error norm: 443.047063\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.496\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 7957.133968\n",
      "Feature norm: 49.440420\n",
      "Error norm: 449.735508\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.491\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 7858.993445\n",
      "Feature norm: 51.031899\n",
      "Error norm: 1397.146615\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.493\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 7677.473961\n",
      "Feature norm: 51.905624\n",
      "Error norm: 558.516225\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.490\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 7598.318838\n",
      "Feature norm: 52.100372\n",
      "Error norm: 415.588741\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.490\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 7502.622292\n",
      "Feature norm: 52.611453\n",
      "Error norm: 423.635690\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.485\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 7419.201710\n",
      "Feature norm: 53.151066\n",
      "Error norm: 482.508088\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.524\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 7359.306053\n",
      "Feature norm: 54.371260\n",
      "Error norm: 942.618645\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.491\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 7272.220084\n",
      "Feature norm: 54.167322\n",
      "Error norm: 397.684855\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.502\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 7208.692283\n",
      "Feature norm: 54.168322\n",
      "Error norm: 340.398973\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.508\n",
      "\n",
      "***** Iteration #51 *****\n",
      "Loss: 7158.862378\n",
      "Feature norm: 54.419796\n",
      "Error norm: 401.841691\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.489\n",
      "\n",
      "***** Iteration #52 *****\n",
      "Loss: 7070.924593\n",
      "Feature norm: 55.034255\n",
      "Error norm: 683.484704\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.476\n",
      "\n",
      "***** Iteration #53 *****\n",
      "Loss: 7005.928773\n",
      "Feature norm: 55.848917\n",
      "Error norm: 642.148431\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.518\n",
      "\n",
      "***** Iteration #54 *****\n",
      "Loss: 6957.630860\n",
      "Feature norm: 55.828185\n",
      "Error norm: 312.303838\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.510\n",
      "\n",
      "***** Iteration #55 *****\n",
      "Loss: 6917.104679\n",
      "Feature norm: 55.925218\n",
      "Error norm: 270.313363\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.483\n",
      "\n",
      "***** Iteration #56 *****\n",
      "Loss: 6872.613657\n",
      "Feature norm: 56.143609\n",
      "Error norm: 342.815258\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.510\n",
      "\n",
      "***** Iteration #57 *****\n",
      "Loss: 6804.098915\n",
      "Feature norm: 56.534941\n",
      "Error norm: 329.750779\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.488\n",
      "\n",
      "***** Iteration #58 *****\n",
      "Loss: 6764.585745\n",
      "Feature norm: 56.944860\n",
      "Error norm: 525.312583\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.426182\n",
      "Seconds required for this iteration: 1.010\n",
      "\n",
      "***** Iteration #59 *****\n",
      "Loss: 6711.312719\n",
      "Feature norm: 57.111826\n",
      "Error norm: 271.900303\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.483\n",
      "\n",
      "***** Iteration #60 *****\n",
      "Loss: 6668.383405\n",
      "Feature norm: 57.178772\n",
      "Error norm: 246.537996\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.502\n",
      "\n",
      "***** Iteration #61 *****\n",
      "Loss: 6631.555544\n",
      "Feature norm: 57.221954\n",
      "Error norm: 278.870336\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.495\n",
      "\n",
      "***** Iteration #62 *****\n",
      "Loss: 6559.251585\n",
      "Feature norm: 57.316656\n",
      "Error norm: 279.895879\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.518\n",
      "\n",
      "***** Iteration #63 *****\n",
      "Loss: 6531.591695\n",
      "Feature norm: 57.220579\n",
      "Error norm: 582.734791\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.375818\n",
      "Seconds required for this iteration: 0.971\n",
      "\n",
      "***** Iteration #64 *****\n",
      "Loss: 6474.411886\n",
      "Feature norm: 57.247947\n",
      "Error norm: 281.087129\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.490\n",
      "\n",
      "***** Iteration #65 *****\n",
      "Loss: 6440.481895\n",
      "Feature norm: 57.170310\n",
      "Error norm: 180.225402\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.496\n",
      "\n",
      "***** Iteration #66 *****\n",
      "Loss: 6401.512610\n",
      "Feature norm: 56.967033\n",
      "Error norm: 198.024930\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.493\n",
      "\n",
      "***** Iteration #67 *****\n",
      "Loss: 6358.332875\n",
      "Feature norm: 56.695725\n",
      "Error norm: 299.454970\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.504\n",
      "\n",
      "***** Iteration #68 *****\n",
      "Loss: 6326.734033\n",
      "Feature norm: 56.413674\n",
      "Error norm: 332.753910\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.523163\n",
      "Seconds required for this iteration: 0.982\n",
      "\n",
      "***** Iteration #69 *****\n",
      "Loss: 6289.774447\n",
      "Feature norm: 56.191254\n",
      "Error norm: 186.780031\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.508\n",
      "\n",
      "***** Iteration #70 *****\n",
      "Loss: 6261.904313\n",
      "Feature norm: 56.070076\n",
      "Error norm: 198.217130\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.515\n",
      "\n",
      "***** Iteration #71 *****\n",
      "Loss: 6239.103337\n",
      "Feature norm: 55.888788\n",
      "Error norm: 306.457540\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.499\n",
      "\n",
      "***** Iteration #72 *****\n",
      "Loss: 6216.918979\n",
      "Feature norm: 55.801478\n",
      "Error norm: 267.305117\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.512\n",
      "\n",
      "***** Iteration #73 *****\n",
      "Loss: 6200.193587\n",
      "Feature norm: 55.755892\n",
      "Error norm: 209.926982\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.516\n",
      "\n",
      "***** Iteration #74 *****\n",
      "Loss: 6166.544332\n",
      "Feature norm: 55.560049\n",
      "Error norm: 140.809485\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.496\n",
      "\n",
      "***** Iteration #75 *****\n",
      "Loss: 6143.819255\n",
      "Feature norm: 55.358728\n",
      "Error norm: 149.511311\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.490\n",
      "\n",
      "***** Iteration #76 *****\n",
      "Loss: 6131.326326\n",
      "Feature norm: 55.206610\n",
      "Error norm: 278.959325\n",
      "Active features: 223293\n",
      "Line search trials: 2\n",
      "Line search step: 0.500557\n",
      "Seconds required for this iteration: 1.005\n",
      "\n",
      "***** Iteration #77 *****\n",
      "Loss: 6113.055746\n",
      "Feature norm: 55.015466\n",
      "Error norm: 150.806513\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.496\n",
      "\n",
      "***** Iteration #78 *****\n",
      "Loss: 6100.853996\n",
      "Feature norm: 54.925520\n",
      "Error norm: 116.395416\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.491\n",
      "\n",
      "***** Iteration #79 *****\n",
      "Loss: 6083.530958\n",
      "Feature norm: 54.763643\n",
      "Error norm: 172.813566\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.500\n",
      "\n",
      "***** Iteration #80 *****\n",
      "Loss: 6075.842794\n",
      "Feature norm: 54.672724\n",
      "Error norm: 251.606396\n",
      "Active features: 223293\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.486\n",
      "\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 44.787\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 223293 (223293)\n",
      "Number of active attributes: 176473 (176473)\n",
      "Number of active labels: 13 (13)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.150\n",
      "\n",
      "-rw-r--r-- 1 smp edu 14M Mar  8 14:01 ner.model\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# split training data\n",
    "cat train-data.featurized | split -l 20000 -d\n",
    "ls -la x*\n",
    "\n",
    "# train crfsuite\n",
    "# -a training algorithm: lbfgs\n",
    "# -m save model to ner.model\n",
    "crfsuite learn -a lbfgs -p max_iterations=80 -m ner.model -l x[0-9][0-9]\n",
    "\n",
    "ls -lh ner.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model to tag text from parsebank\n",
    "\n",
    "* We want to find named entities from parsebank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pb.test.conllu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-118179a20ffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# now test it with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pb.test.conllu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pb.test.conllu'"
     ]
    }
   ],
   "source": [
    "# now test it with this\n",
    "with open(\"pb.test.conllu\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines()[:10]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crfsuite tagging\n",
    "\n",
    "* Remember to featurize the data also here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 smp edu 0 Mar  8 14:02 predicted.labels\n",
      "-rw-r--r-- 1 smp edu 0 Mar  8 14:02 predicted.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: pb.test.conllu: No such file or directory\n",
      "python: can't open file '/home/jmnybl/NER/featurize.py': [Errno 2] No such file or directory\n",
      "paste: pb.test.conllu: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat pb.test.conllu | python /home/jmnybl/NER/featurize.py > pb.test.featurized\n",
    "\n",
    "crfsuite tag -m ner.model pb.test.featurized > predicted.labels\n",
    "\n",
    "# combine predictions and original text\n",
    "paste predicted.labels pb.test.conllu > predicted.txt\n",
    "\n",
    "ls -lh predicted*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at the output\n",
    "\n",
    "* Print sentences with named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sent(sent):\n",
    "    for line in sent:\n",
    "        print(\"\\t\".join(t for t in line.strip().split(\"\\t\")[:5])) # make it look prettier\n",
    "    print()\n",
    "    \n",
    "i=0\n",
    "with open(\"predicted.txt\", encoding=\"utf-8\") as f:\n",
    "    for sent in read_data(f):\n",
    "        for line in sent:\n",
    "            if line.strip().split(\"\\t\")[0]!=\"O\":\n",
    "                print_sent(sent)\n",
    "                i+=1\n",
    "                break\n",
    "        if i>5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
