{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The why's of classifiers and regularization\n",
    "\n",
    "* The SVM really learns a weight vector, with a weight for every feature\n",
    "* Above hyperplane (positive class) test: $ \\vec{w}\\cdot \\vec{x} + b \\gt 0 $ where $ \\vec{w} $ is the learned weight vector, $ \\vec{x} $ is the feature vector you are classifying, and $ b $ is a bias.\n",
    "* So we just sum the elementwise multiplication of the features with the learned weights, and add a bias\n",
    "\n",
    "## Most discriminative features\n",
    "\n",
    "The weights correlate with the importance of the feature for the classification. Let's see for ourselves on the movie review data from the last demos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 positive and 12500 negative reviews\n"
     ]
    }
   ],
   "source": [
    "# Read data in (these are one review per file)\n",
    "import glob\n",
    "import codecs\n",
    "\n",
    "def read_dir(dir_name):\n",
    "    texts=[]\n",
    "    for f_name in sorted(glob.glob(dir_name+\"/*.txt\")):\n",
    "        with codecs.open(f_name,\"r\",\"utf-8\") as f:\n",
    "            texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "train_pos_txt=read_dir(\"imdb/train/pos\")\n",
    "train_neg_txt=read_dir(\"imdb/train/neg\")\n",
    "test_pos_txt=read_dir(\"imdb/test/pos\")\n",
    "test_neg_txt=read_dir(\"imdb/test/neg\")\n",
    "\n",
    "print len(train_pos_txt), \"positive and\", len(train_neg_txt), \"negative reviews\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst -5.04284864046\n",
      "waste -3.84302809294\n",
      "awful -3.66709733104\n",
      "boring -3.30642775532\n",
      "bad -3.29585913666\n",
      "disappointment -3.22802725648\n",
      "poorly -3.04569604489\n",
      "poor -2.94538722211\n",
      "disappointing -2.86117762915\n",
      "worse -2.72027362264\n",
      "fails -2.64784124737\n",
      "terrible -2.64249575048\n",
      "lacks -2.6293188406\n",
      "mess -2.5912934151\n",
      "dull -2.50818415226\n",
      "nothing -2.45162316557\n",
      "unfortunately -2.3782031781\n",
      "horrible -2.35114065677\n",
      "annoying -2.30886533656\n",
      "save -2.29264857263\n",
      "avoid -2.16329662223\n",
      "laughable -2.16206626355\n",
      "ridiculous -2.15838484198\n",
      "unfunny -2.08066875969\n",
      "weak -2.05548219122\n",
      "forgettable -2.03245698378\n",
      "badly -2.03199956277\n",
      "supposed -2.02040781557\n",
      "lame -2.0079412708\n",
      "lousy -1.94495953337\n",
      "------------------------\n",
      "love 1.76886158776\n",
      "carrey 1.7814144629\n",
      "liked 1.78228883306\n",
      "subtle 1.83466969424\n",
      "well 1.85343988421\n",
      "appreciated 1.86413443733\n",
      "incredible 1.87133672818\n",
      "job 1.90344759777\n",
      "rare 1.91900092273\n",
      "enjoyed 1.92269534387\n",
      "brilliant 1.94120781876\n",
      "it 1.94821522476\n",
      "perfectly 1.95311731401\n",
      "funniest 1.95993067312\n",
      "fun 1.97053350177\n",
      "favorite 2.02905385856\n",
      "highly 2.05547965401\n",
      "amazing 2.10590298042\n",
      "superb 2.11944902946\n",
      "loved 2.12378754454\n",
      "surprisingly 2.15637284592\n",
      "wonderfully 2.18114603448\n",
      "refreshing 2.24529692485\n",
      "enjoyable 2.2568262515\n",
      "today 2.33023045956\n",
      "wonderful 2.34444618192\n",
      "best 2.47013920988\n",
      "perfect 2.85271784191\n",
      "great 3.40059266998\n",
      "excellent 3.49920573328\n"
     ]
    }
   ],
   "source": [
    "tfidf_v=TfidfVectorizer(sublinear_tf=True) #sublinear_tf flattens the tf scores a bit (runs them through a log function)\n",
    "d=tfidf_v.fit_transform(train_pos_txt+train_neg_txt)\n",
    "d_test=tfidf_v.transform(test_pos_txt+test_neg_txt)\n",
    "lin_c=LinearSVC(C=1.0) #I tried and this is a good C value\n",
    "lin_c.fit(d,[1]*len(train_pos_txt)+[0]*len(train_neg_txt))\n",
    "#the learned feature weights are in lin_c.coef_[0]\n",
    "f_names=tfidf_v.get_feature_names()\n",
    "sorted_by_weight=sorted(zip(lin_c.coef_[0],f_names))\n",
    "for f_weight,f_name in sorted_by_weight[:30]:\n",
    "    print f_name, f_weight\n",
    "print \"------------------------\"\n",
    "for f_weight,f_name in sorted_by_weight[-30:]:\n",
    "    print f_name, f_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Key concepts (explained during the lecture, google if absent):\n",
    "* Regularization\n",
    "  * Need to avoid overfitting training examples\n",
    "  * Keeping the magnitude of the SVM weight vector (hyperplane) small means that spurious individual features cannot be given very high weights to overfit to your training data\n",
    "  * In other words, the weights must be kept sane\n",
    "* L1 and L2 regularization\n",
    "  * L1 sum of absolute values is kept small\n",
    "  * L2 sum of squares is kept small\n",
    "* In fig below the point on the left line optimizes the L1 norm and on the right line optimizes the L2 norm. $ w_2 $ is a strict zero for L1 but not for L2\n",
    "  \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/f/fd/L1_and_L2_balls.jpg\" />\n",
    "\n",
    "# Feature selection with L1\n",
    "\n",
    "As you have seen, unlike L2, the L1 regularization tends to drive feature weights down to strict zero. It is therefore very useful for in/out feature selection. Let us try with the same IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** L2 **********\n",
      "C=0.01   Accuracy=86.10%   Non-zero weight features: 74824\n",
      "C=0.03   Accuracy=87.98%   Non-zero weight features: 74032\n",
      "C=0.05   Accuracy=88.68%   Non-zero weight features: 73088\n",
      "C=0.10   Accuracy=88.92%   Non-zero weight features: 71238\n",
      "C=1.00   Accuracy=88.01%   Non-zero weight features: 64477\n",
      "C=10.00   Accuracy=85.80%   Non-zero weight features: 62097\n",
      "\n",
      "\n",
      "*********** L1 **********\n",
      "C=0.01   Accuracy=73.49%   Non-zero weight features: 21\n",
      "C=0.03   Accuracy=81.63%   Non-zero weight features: 119\n",
      "C=0.05   Accuracy=83.98%   Non-zero weight features: 209\n",
      "C=0.10   Accuracy=86.44%   Non-zero weight features: 394\n",
      "C=1.00   Accuracy=87.88%   Non-zero weight features: 3970\n",
      "C=10.00   Accuracy=85.36%   Non-zero weight features: 6587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy\n",
    "\n",
    "tfidf_v=TfidfVectorizer(sublinear_tf=True)\n",
    "d=tfidf_v.fit_transform(train_pos_txt+train_neg_txt)\n",
    "d_test=tfidf_v.transform(test_pos_txt+test_neg_txt)\n",
    "\n",
    "# First with L2 which is the default\n",
    "print \"*********** L2 **********\"\n",
    "for C in (0.01,0.03,0.05,0.1,1.0,10):\n",
    "    lin_c=LinearSVC(C=C)\n",
    "    lin_c.fit(d,[1]*len(train_pos_txt)+[0]*len(train_neg_txt))\n",
    "    print \"C=%04.2f   Accuracy=%.2f%%   Non-zero weight features: %d\"%(C,lin_c.score(d_test,[1]*len(test_pos_txt)+[0]*len(test_neg_txt))*100.0,numpy.count_nonzero(lin_c.coef_))\n",
    "print \n",
    "print\n",
    "print \"*********** L1 **********\"\n",
    "for C in (0.01,0.03,0.05,0.1,1.0,10):\n",
    "    lin_c=LinearSVC(penalty=\"l1\",C=C,dual=False) #these settings are needed for L1\n",
    "    lin_c.fit(d,[1]*len(train_pos_txt)+[0]*len(train_neg_txt))\n",
    "    print \"C=%04.2f   Accuracy=%.2f%%   Non-zero weight features: %d\"%(C, lin_c.score(d_test,[1]*len(test_pos_txt)+[0]*len(test_neg_txt))*100.0,numpy.count_nonzero(lin_c.coef_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like C=0.01 gives us only **21** active features. Let's look at them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad -5.80960603215\n",
      "worst -4.76305681117\n",
      "waste -2.52218371608\n",
      "no -2.29481501206\n",
      "awful -1.87703501105\n",
      "nothing -1.26514803954\n",
      "boring -1.09520869636\n",
      "even -0.680857894709\n",
      "plot -0.494747346774\n",
      "terrible -0.468445491958\n",
      "minutes -0.442163097956\n",
      "just -0.437272508868\n",
      "poor -0.330544770183\n",
      "stupid -0.122586460651\n",
      "very 0.196431419642\n",
      "well 0.265343065818\n",
      "wonderful 0.610334460291\n",
      "love 1.21605247426\n",
      "excellent 1.56261628434\n",
      "best 1.58308357965\n",
      "great 3.78397235444\n"
     ]
    }
   ],
   "source": [
    "#Let's try this one\n",
    "lin_c=LinearSVC(penalty=\"l1\",C=0.01,dual=False)\n",
    "lin_c.fit(d,[1]*len(train_pos_txt)+[0]*len(train_neg_txt))\n",
    "feats=numpy.nonzero(lin_c.coef_) #List of indices where the coef is not zero\n",
    "f_names=tfidf_v.get_feature_names()\n",
    "for f_weight,f_name in sorted((lin_c.coef_[0][idx],f_names[idx]) for idx in feats[1]):\n",
    "    print f_name, f_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...not bad(?)\n",
    "\n",
    "...and that's all the features ever used to get 73% accuracy on the task (which mind you is not very good compared to the 88% we see otherwise and the 94% reported in the paper this data comes from). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst -6.87349592774\n",
      "waste -5.35435625783\n",
      "awful -5.01860127605\n",
      "bad -4.4911046273\n",
      "boring -3.94362135886\n",
      "poor -3.64374427939\n",
      "poorly -3.550536664\n",
      "dull -3.39664453478\n",
      "fails -3.22196148183\n",
      "terrible -3.10702704783\n",
      "nothing -2.97105160271\n",
      "mess -2.90293775497\n",
      "unfortunately -2.89159274004\n",
      "disappointing -2.8064114785\n",
      "horrible -2.77848952548\n",
      "annoying -2.72574521534\n",
      "worse -2.67771457585\n",
      "disappointment -2.67286381622\n",
      "lame -2.48326262442\n",
      "ridiculous -2.42347315866\n",
      "supposed -2.4103855913\n",
      "pointless -2.34258712999\n",
      "no -2.31902773125\n",
      "avoid -2.31359887562\n",
      "stupid -2.25299710512\n",
      "laughable -2.19388787459\n",
      "oh -2.15841896888\n",
      "script -2.14880225756\n",
      "minutes -2.14077101761\n",
      "save -2.08975151902\n",
      "badly -2.0858420394\n",
      "instead -2.06403385676\n",
      "lacks -1.83856101787\n",
      "unfunny -1.76695332212\n",
      "unless -1.6771504156\n",
      "crap -1.65092507076\n",
      "pathetic -1.50644537582\n",
      "looks -1.50542942059\n",
      "just -1.47719166217\n",
      "wasted -1.40232726332\n",
      "even -1.37908439281\n",
      "weak -1.34762895768\n",
      "predictable -1.32278439817\n",
      "plot -1.32116346684\n",
      "attempt -1.30704859478\n",
      "wooden -1.29346449524\n",
      "mediocre -1.28952712742\n",
      "least -1.27300558367\n",
      "redeeming -1.20937660825\n",
      "money -1.18102250943\n",
      "couldn -1.15297665824\n",
      "any -1.12147575849\n",
      "wonder -1.12095636946\n",
      "cheap -1.11018653208\n",
      "was -1.09449965179\n",
      "why -1.09280625225\n",
      "not -1.07897699609\n",
      "silly -1.06192016291\n",
      "basically -1.03898202098\n",
      "someone -1.03179166345\n",
      "bored -1.02912157824\n",
      "effort -1.01377490718\n",
      "half -1.00965490113\n",
      "would -0.988011995529\n",
      "seems -0.938830288283\n",
      "idea -0.938613396392\n",
      "dreadful -0.933288027842\n",
      "original -0.915625672144\n",
      "sorry -0.897762041596\n",
      "guess -0.874197689751\n",
      "problem -0.84954117148\n",
      "garbage -0.845449822635\n",
      "only -0.831155515546\n",
      "bunch -0.818100099723\n",
      "disappointed -0.817814712704\n",
      "reason -0.813924442186\n",
      "forgettable -0.807216511992\n",
      "better -0.798780023728\n",
      "tries -0.797485302071\n",
      "off -0.790498159591\n",
      "enough -0.786499138498\n",
      "premise -0.781943582099\n",
      "lack -0.768949602372\n",
      "make -0.762176918705\n",
      "director -0.757371538819\n",
      "none -0.756199317378\n",
      "don -0.732608154591\n",
      "anything -0.731931248\n",
      "tedious -0.718158688732\n",
      "then -0.712664512353\n",
      "pretentious -0.70576951492\n",
      "dumb -0.658337805102\n",
      "if -0.654413253359\n",
      "ok -0.645814532709\n",
      "acting -0.62685084552\n",
      "doesn -0.626189318955\n",
      "painful -0.613149034259\n",
      "failed -0.594986017092\n",
      "decent -0.591342304885\n",
      "might -0.582621284159\n",
      "thing -0.578329897328\n",
      "re -0.573848346446\n",
      "been -0.569248734625\n",
      "christian -0.560816283818\n",
      "much -0.555237622783\n",
      "there -0.554542261333\n",
      "were -0.551945702155\n",
      "mst3k -0.549992172997\n",
      "they -0.546802796533\n",
      "sadly -0.541156498883\n",
      "flat -0.534898980788\n",
      "didn -0.528672908671\n",
      "grade -0.523241429161\n",
      "joke -0.518249184371\n",
      "could -0.516489243653\n",
      "insult -0.509704923539\n",
      "trying -0.479684829157\n",
      "too -0.451720218288\n",
      "have -0.433361685014\n",
      "movie -0.432575369589\n",
      "lousy -0.426570726266\n",
      "apparently -0.424873916229\n",
      "unbelievable -0.420687083729\n",
      "looking -0.41941741958\n",
      "obvious -0.415485423525\n",
      "except -0.406502528751\n",
      "neither -0.40386310396\n",
      "interesting -0.393509597189\n",
      "looked -0.393236159603\n",
      "either -0.387332491488\n",
      "actors -0.383474802161\n",
      "seemed -0.364668879598\n",
      "this -0.357020620634\n",
      "making -0.351027550852\n",
      "okay -0.347190080984\n",
      "producers -0.31534092377\n",
      "do -0.313256249911\n",
      "low -0.312979739972\n",
      "nudity -0.308222147128\n",
      "book -0.298375967074\n",
      "wouldn -0.282319946715\n",
      "br -0.274827266236\n",
      "or -0.272304192819\n",
      "material -0.272167249966\n",
      "mildly -0.262482585677\n",
      "guy -0.259166059082\n",
      "wrong -0.240799757856\n",
      "bland -0.237481438169\n",
      "something -0.234582668822\n",
      "production -0.223210669509\n",
      "sex -0.222070286091\n",
      "should -0.219627023523\n",
      "nowhere -0.215275417039\n",
      "excuse -0.206374538853\n",
      "wasn -0.199606290556\n",
      "am -0.195265898661\n",
      "barely -0.191722451465\n",
      "uninteresting -0.188013514553\n",
      "did -0.185136996229\n",
      "turkey -0.182074671279\n",
      "maybe -0.175699793789\n",
      "completely -0.170558098597\n",
      "brain -0.166310958714\n",
      "total -0.160214957541\n",
      "absurd -0.153951022597\n",
      "hoping -0.150469564377\n",
      "actor -0.146548080999\n",
      "horror -0.144321565297\n",
      "slow -0.136030413987\n",
      "mean -0.134111999364\n",
      "gore -0.12979644098\n",
      "watching -0.120639544401\n",
      "care -0.115778510809\n",
      "far -0.11455852772\n",
      "blah -0.0794576538172\n",
      "trash -0.0714120626675\n",
      "writing -0.0703099807016\n",
      "christmas -0.0650984299028\n",
      "want -0.0623884385197\n",
      "rent -0.0481612360135\n",
      "budget -0.0479670997071\n",
      "unconvincing -0.046121225119\n",
      "left -0.0450808641665\n",
      "vampire -0.0271419485705\n",
      "rubbish -0.0247309932043\n",
      "point -0.0242380619047\n",
      "over -0.0239764150105\n",
      "interest -0.0232322491899\n",
      "write -0.0193784846438\n",
      "falls -0.00364544411072\n",
      "had -0.00191250148426\n",
      "find 0.000890852185592\n",
      "again 0.00316804725016\n",
      "appreciate 0.00399374788329\n",
      "course 0.0130138273367\n",
      "things 0.0134826453685\n",
      "without 0.0153578920648\n",
      "last 0.0178741802937\n",
      "those 0.0239746894763\n",
      "ever 0.0267613986725\n",
      "dark 0.0335175851872\n",
      "reality 0.0351664710022\n",
      "complex 0.0405228821277\n",
      "thought 0.0456173294761\n",
      "thriller 0.0521141286626\n",
      "expecting 0.0548162256178\n",
      "comedy 0.0682182544876\n",
      "top 0.0734628796346\n",
      "ride 0.0758672623834\n",
      "others 0.0834617232785\n",
      "subtitles 0.0866965630977\n",
      "season 0.0899943922375\n",
      "plays 0.0956296179477\n",
      "friendship 0.0969551523235\n",
      "know 0.0979564589353\n",
      "tears 0.100173691383\n",
      "films 0.106149808144\n",
      "while 0.107569710394\n",
      "along 0.118294429159\n",
      "recommend 0.126002386478\n",
      "father 0.128609558802\n",
      "once 0.134074812387\n",
      "city 0.136806777475\n",
      "who 0.137798952528\n",
      "stunning 0.138145298281\n",
      "romantic 0.141851340589\n",
      "tale 0.143944051806\n",
      "war 0.144265144793\n",
      "our 0.147413539863\n",
      "stewart 0.147573983422\n",
      "tells 0.14805920513\n",
      "must 0.1485583016\n",
      "when 0.161731247667\n",
      "other 0.162668993347\n",
      "intense 0.163621888691\n",
      "man 0.166257329361\n",
      "ways 0.169510922198\n",
      "throughout 0.182091953746\n",
      "release 0.190037657036\n",
      "together 0.192805831972\n",
      "small 0.197798901048\n",
      "episode 0.203200240661\n",
      "freedom 0.217770371664\n",
      "gives 0.219255012651\n",
      "fine 0.231772409836\n",
      "able 0.239765358055\n",
      "plenty 0.244431974291\n",
      "its 0.247795224622\n",
      "saw 0.248162556197\n",
      "american 0.257188514047\n",
      "emotions 0.258795610214\n",
      "many 0.261900508612\n",
      "genius 0.262265407562\n",
      "available 0.271002994156\n",
      "overall 0.274389066937\n",
      "right 0.276009574643\n",
      "10 0.276600718229\n",
      "vhs 0.286143247093\n",
      "glad 0.292754072878\n",
      "us 0.294640564534\n",
      "oscar 0.294831211288\n",
      "genre 0.295145965654\n",
      "think 0.295441880937\n",
      "future 0.295847776495\n",
      "lot 0.305943584867\n",
      "caught 0.317825967917\n",
      "as 0.321910309363\n",
      "truly 0.322315928756\n",
      "finest 0.325822575517\n",
      "although 0.346296798864\n",
      "family 0.353415055087\n",
      "is 0.357172443128\n",
      "young 0.358688552922\n",
      "quite 0.364809866976\n",
      "new 0.376045197124\n",
      "relationship 0.376888459725\n",
      "story 0.384345312894\n",
      "time 0.38952386611\n",
      "believable 0.391680675444\n",
      "delightful 0.40561560867\n",
      "knowing 0.405784751011\n",
      "episodes 0.406308322976\n",
      "played 0.408704289161\n",
      "everyone 0.415156029413\n",
      "beauty 0.422238797275\n",
      "jack 0.426762380343\n",
      "now 0.432344018072\n",
      "journey 0.432499242771\n",
      "my 0.448130973007\n",
      "surprisingly 0.449992379573\n",
      "his 0.455419619378\n",
      "often 0.457506301662\n",
      "action 0.464993045427\n",
      "worth 0.474534283833\n",
      "has 0.49618106194\n",
      "sometimes 0.503944841475\n",
      "unlike 0.511924429708\n",
      "more 0.547762816879\n",
      "first 0.553263520109\n",
      "though 0.561273114769\n",
      "nice 0.561605744354\n",
      "easy 0.569676899221\n",
      "times 0.571837517749\n",
      "remember 0.578976288616\n",
      "later 0.60146952924\n",
      "him 0.625555373064\n",
      "sweet 0.635486525708\n",
      "outstanding 0.644783632691\n",
      "day 0.661178322527\n",
      "recommended 0.665164123106\n",
      "own 0.676242587733\n",
      "human 0.683142103248\n",
      "lives 0.699834627896\n",
      "performances 0.71803315394\n",
      "works 0.723579528379\n",
      "series 0.72920809892\n",
      "different 0.737031138641\n",
      "realistic 0.741260322295\n",
      "dvd 0.752532211115\n",
      "each 0.756703787058\n",
      "awesome 0.816374907912\n",
      "solid 0.824846982957\n",
      "fascinating 0.828003420024\n",
      "performance 0.830452997608\n",
      "hilarious 0.871464470465\n",
      "may 0.874147950152\n",
      "you 0.882479779064\n",
      "moving 0.883784979098\n",
      "greatest 0.884106528609\n",
      "years 0.904605307243\n",
      "terrific 0.91065374742\n",
      "atmosphere 0.913482129707\n",
      "good 0.938221257534\n",
      "see 0.939540630253\n",
      "refreshing 0.94079752792\n",
      "powerful 0.942211778822\n",
      "surprised 0.958187030977\n",
      "masterpiece 0.985342132376\n",
      "touching 0.986743004438\n",
      "entertaining 0.997711840381\n",
      "most 1.00452732657\n",
      "subtle 1.0395895876\n",
      "classic 1.0438323049\n",
      "true 1.05262477746\n",
      "unique 1.06221711014\n",
      "strong 1.07709170585\n",
      "shows 1.08124967953\n",
      "always 1.0816848761\n",
      "incredible 1.08534702289\n",
      "gem 1.09621286277\n",
      "funniest 1.09973981566\n",
      "enjoy 1.11070770226\n",
      "makes 1.15670235704\n",
      "seen 1.17717145681\n",
      "especially 1.19880647791\n",
      "will 1.24724349263\n",
      "beautifully 1.26612564155\n",
      "bit 1.2719330956\n",
      "liked 1.29275939535\n",
      "life 1.32456422033\n",
      "job 1.32557293284\n",
      "heart 1.35308240546\n",
      "simple 1.35324904419\n",
      "rare 1.36374885849\n",
      "perfectly 1.41914863102\n",
      "very 1.42307126538\n",
      "it 1.48725766162\n",
      "fantastic 1.4979006418\n",
      "both 1.53537745915\n",
      "definitely 1.53916860259\n",
      "enjoyable 1.54716826148\n",
      "still 1.55822942435\n",
      "and 1.58072453247\n",
      "world 1.62426401045\n",
      "beautiful 1.638684455\n",
      "enjoyed 1.65035840794\n",
      "noir 1.65790591782\n",
      "also 1.67889970189\n",
      "loved 1.78433411296\n",
      "wonderfully 1.86990908092\n",
      "fun 1.87937708373\n",
      "love 1.95418720644\n",
      "highly 2.03324992545\n",
      "superb 2.03975175835\n",
      "well 2.04268780029\n",
      "brilliant 2.16965392518\n",
      "favorite 2.20449604861\n",
      "today 2.35968093886\n",
      "amazing 2.67293722755\n",
      "wonderful 2.81750351349\n",
      "best 3.0682763041\n",
      "perfect 3.32115576221\n",
      "great 4.10842479147\n",
      "excellent 4.21041200963\n"
     ]
    }
   ],
   "source": [
    "#Let's try this one - 394 features\n",
    "lin_c=LinearSVC(penalty=\"l1\",C=0.1,dual=False)\n",
    "lin_c.fit(d,[1]*len(train_pos_txt)+[0]*len(train_neg_txt))\n",
    "feats=numpy.nonzero(lin_c.coef_) #List of indices where the coef is not zero\n",
    "f_names=tfidf_v.get_feature_names()\n",
    "for f_weight,f_name in sorted((lin_c.coef_[0][idx],f_names[idx]) for idx in feats[1]):\n",
    "    print f_name, f_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Let's yet test the effect of the sublinear_tf option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad -5.08123163107\n",
      "worst -4.38981930799\n",
      "no -2.34662691435\n",
      "waste -2.02745498996\n",
      "awful -1.39197174668\n",
      "even -0.979188595952\n",
      "nothing -0.912777476398\n",
      "boring -0.891127772481\n",
      "just -0.888671837571\n",
      "was -0.541189528328\n",
      "to -0.534307473047\n",
      "they -0.514391761016\n",
      "plot -0.411256591686\n",
      "br -0.210465862914\n",
      "movie -0.15522111619\n",
      "terrible -0.143288441578\n",
      "this -0.141724247277\n",
      "minutes -0.126692192144\n",
      "there -0.0272097939993\n",
      "wonderful 0.0366115803371\n",
      "his 0.0968399465279\n",
      "as 0.119787864376\n",
      "is 0.143553932311\n",
      "well 0.249518189519\n",
      "very 0.325843067457\n",
      "excellent 0.990287868212\n",
      "love 1.09597880933\n",
      "best 1.35149402781\n",
      "and 1.73153913202\n",
      "great 3.5491986854\n"
     ]
    }
   ],
   "source": [
    "#Let me switch the sublinear_tf off - see how the common word features creep in\n",
    "tfidf_v=TfidfVectorizer()\n",
    "d=tfidf_v.fit_transform(train_pos_txt+train_neg_txt)\n",
    "d_test=tfidf_v.transform(test_pos_txt+test_neg_txt)\n",
    "lin_c=LinearSVC(penalty=\"l1\",C=0.01,dual=False)\n",
    "lin_c.fit(d,[1]*len(train_pos_txt)+[0]*len(train_neg_txt))\n",
    "feats=numpy.nonzero(lin_c.coef_)\n",
    "f_names=tfidf_v.get_feature_names()\n",
    "for f_weight,f_name in sorted((lin_c.coef_[0][idx],f_names[idx]) for idx in feats[1]):\n",
    "    print f_name, f_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
