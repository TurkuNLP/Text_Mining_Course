{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "simstring_phon.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/Text_Mining_Course/blob/master/simstring_phon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unZTKx1pCZoY"
      },
      "source": [
        "# Phonetic mapping of names\n",
        "\n",
        "* Captures regularities in name transliterations\n",
        "* Map name to a representation which is (hopefully) common to all its different transliterations\n",
        "* E.g. for Arabic names, you might want to drop vowels\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zftmHuiGCZoh",
        "outputId": "055413be-c412-427a-ce3a-3ce034b2a774"
      },
      "source": [
        "!pip install abydos\n",
        "!pip install http://dl.turkunlp.org/textual-data-analysis-course-data/simstring-1.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: abydos in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.7/dist-packages (from abydos) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from abydos) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->abydos) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->abydos) (2.4.7)\n",
            "Collecting simstring==1.1\n",
            "\u001b[?25l  Downloading http://dl.turkunlp.org/textual-data-analysis-course-data/simstring-1.1-cp37-cp37m-linux_x86_64.whl (893kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 261kB/s \n",
            "\u001b[?25hInstalling collected packages: simstring\n",
            "Successfully installed simstring-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYLQDs3vCZoj"
      },
      "source": [
        "import simstring\n",
        "import abydos"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UltiQv0JCZok",
        "outputId": "9cc6c221-9906-402c-f99d-39d6b0ffe9f8"
      },
      "source": [
        "import abydos.phonetic\n",
        "encoder=abydos.phonetic.Metaphone()\n",
        "print(encoder.encode(\"Daniil Shafran\"))\n",
        "print(encoder.encode(\"Daniel Shafran\"))\n",
        "print(encoder.encode(\"Evgeni Mravinsky\"))\n",
        "print(encoder.encode(\"Yevgeny Mravinsky\"))\n",
        "print(encoder.encode(\"Yevgeny Mriavinsky\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TNLXFRN\n",
            "TNLXFRN\n",
            "EFJNMRFNSK\n",
            "YFJNMRFNSK\n",
            "YFJNMRFNSK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4jyHpN3EZP7",
        "outputId": "98f43ac5-b294-4f5e-885d-f5554f88542d"
      },
      "source": [
        "!wget -nc http://dl.turkunlp.org/textual-data-analysis-course-data/wikidata.fi.bz2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-10 16:56:45--  http://dl.turkunlp.org/textual-data-analysis-course-data/wikidata.fi.bz2\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56380139 (54M) [application/octet-stream]\n",
            "Saving to: ‘wikidata.fi.bz2’\n",
            "\n",
            "wikidata.fi.bz2     100%[===================>]  53.77M  15.6MB/s    in 3.4s    \n",
            "\n",
            "2021-03-10 16:56:49 (15.6 MB/s) - ‘wikidata.fi.bz2’ saved [56380139/56380139]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C918iEzTCZol",
        "outputId": "b9389eb9-d826-4fce-9707-f2b10a525966"
      },
      "source": [
        "from tqdm import tqdm #progress-bar\n",
        "import pickle\n",
        "import os\n",
        "import bz2\n",
        "\n",
        "\n",
        "os.makedirs(\"wikidata_phon.db\",exist_ok=True)\n",
        "db=simstring.writer(\"wikidata_phon.db/wikidata_phon.db\")\n",
        "\n",
        "name_mapping={} #phonetic -> set(names)\n",
        "\n",
        "with bz2.open(\"wikidata.fi.bz2\",\"rt\") as f:\n",
        "    for line in tqdm(f):\n",
        "        line=line.strip()\n",
        "        # 4-col file with string, two urls, and official label\n",
        "        # let us index the strings\n",
        "        s,url1,url2,label=line.split(\"\\t\")\n",
        "        encoded_s=encoder.encode(s)\n",
        "        if encoded_s not in name_mapping: #a new string\n",
        "            db.insert(encoded_s)\n",
        "        name_mapping.setdefault(encoded_s,set()).add(s) #remember the string\n",
        "db.close()\n",
        "\n",
        "#store the name mapping \n",
        "with open(\"wikidata_phon.db/name_mapping.pickle\",\"wb\") as f:\n",
        "    pickle.dump(name_mapping,f)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3995911it [02:14, 29650.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNvf4niSCZom"
      },
      "source": [
        "import pickle\n",
        "with open(\"wikidata_phon.db/name_mapping.pickle\",\"rb\") as f:\n",
        "    name_mapping=pickle.load(f)\n",
        "    \n",
        "db=simstring.reader(\"wikidata_phon.db/wikidata_phon.db\")\n",
        "db.metric=simstring.cosine"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6GMdnzNCZon",
        "outputId": "33001c69-bef4-4b6a-aa5f-684291be9902"
      },
      "source": [
        "def retrieve_phon(s,db,threshold,encoder,name_mapping):\n",
        "    db.threshold=threshold\n",
        "    phon_hits=db.retrieve(encoder.encode(s))\n",
        "    return [name_mapping[ph] for ph in phon_hits]\n",
        "print(retrieve_phon(\"Tarja Halunen\",db,0.9,encoder,name_mapping)) #success\n",
        "print(retrieve_phon(\"Vlodymyr Puutin\",db,0.9,encoder,name_mapping)) #success\n",
        "print(retrieve_phon(\"Oleg Gordyievskyi\",db,0.9,encoder,name_mapping)) #fail\n",
        "print(retrieve_phon(\"Oleg Kordievski\",db,0.8,encoder,name_mapping)) #fail\n",
        "print(retrieve_phon(\"Oleg Gordyievskyi\",db,0.8,encoder,name_mapping)) #fail\n",
        "print(retrieve_phon(\"Oleg Gordievski\",db,0.8,encoder,name_mapping)) #fail"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'Tarja Halonen', 'Tarja Helanen'}]\n",
            "[{'Vladimir Putin'}, {'Vladimir Potanin'}]\n",
            "[]\n",
            "[{'Oleg Ogorodov'}]\n",
            "[]\n",
            "[{'Olga Rotševa'}, {'Gardavská', 'Carte physique', 'Gratofsky'}, {'Luokka:Eredivisie'}, {'Oleg Gordievski'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p7qswiGCZop"
      },
      "source": [
        "## Possible improvements\n",
        "\n",
        "* These techniques compress the names by removing many vowels\n",
        "* 3-grams in simstring might be too long"
      ]
    }
  ]
}