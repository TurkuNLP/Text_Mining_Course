{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "In a nutshell (details will be explained during the lecture)\n",
    "\n",
    "- Assign input text into categories, either predefined (supervised) or not (unsupervised/clustering)\n",
    "  - Spam / not spam\n",
    "  - One of several topics\n",
    "  - Who is the author?\n",
    "  - ...\n",
    "- Done with machine learning\n",
    "  - We covered clustering last week, so now we look into **supervised** classification\n",
    "  - Main difference: unsupervised = no training data, supervised = training data\n",
    "- Training data:\n",
    "  - Ready examples of documents and their classes\n",
    "  - Learn the task from these examples\n",
    "  - Unsupervised = we don't know the classes, supervised = we know the classes\n",
    "- Training: text features + model induction algorithm -> model\n",
    "- Classification: text features + model -> predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "- Represent each document for the classifier\n",
    "- E.g.\n",
    "  - Bag of Words (BoW)\n",
    "  - Character N-Grams\n",
    "  - Document metadata\n",
    "  - PoS tags\n",
    "  - ...you name it, someone tried it...\n",
    "  \n",
    "Let's try on Suomi24 VRT data\n",
    "\n",
    "```\n",
    "<text discussionarea=\"Suhteet\" subsections=\"Sinkut\" title=\"Jos ATM hypp√§isi benjihypyn\" views=\"0\" cid=\"unspecified\" anonnick=\"√§tmink√§inen\" comms=\"9\" year=\"2015\" date=\"12.05.2015\" dateto=\"20150512\" tid=\"13592337\" datefrom=\"20150512\" time=\"22:50\" sect=\"Suhteet\" subsect=\"Sinkut\" ssubsect=\"\" sssubsect=\"\" ssssubsect=\"\" sssssubsect=\"\" ssssssubsect=\"\" urlboard=\"http://keskustelu.suomi24.fi/t/13592337\" urlmsg=\"http://keskustelu.suomi24.fi/t/13592337\">\n",
    "<paragraph>\n",
    "<sentence>\n",
    "Niin    1       niin    Adv     CASECHANGE_Up   2       advmod\n",
    "parantaisiko    2       parantaa        V       PRS_Sg3|VOICE_Act|MOOD_Cond|CLIT_Qst    0       ROOT\n",
    "se      3       se      Pron    SUBCAT_Dem|NUM_Sg|CASE_Nom      2       nsubj\n",
    "h√§nen   4       h√§n     Pron    SUBCAT_Pers|NUM_Sg|CASE_Gen     5       poss\n",
    "markkina-arvoaan        5       markkina-arvo   N       NUM_Sg|CASE_Par|POSS_Px3        2       dobj\n",
    "naisten 6       nainen  N       NUM_Pl|CASE_Gen 7       poss\n",
    "silmiss√§        7       silm√§   N       NUM_Pl|CASE_Ine 2       nommod\n",
    "?       8       ?       Punct   _       2       punct\n",
    "</sentence>\n",
    "</paragraph>\n",
    "</text>\n",
    "<text discussionarea=\"Suhteet\" subsections=\"Sinkut\" title=\"Jos ATM hypp√§isi benjihypyn\" cid=\"79614512\" anonnick=\"NaisetOvatElukoita\" comms=\"9\" views=\"\" date=\"20.06.2015\" dateto=\"20150620\" year=\"2015\" tid=\"13592337\" datefrom=\"20150620\" time=\"20:34\" sect=\"Suhteet\" subsect=\"Sinkut\" ssubsect=\"\" sssubsect=\"\" ssssubsect=\"\" sssssubsect=\"\" ssssssubsect=\"\" urlboard=\"http://keskustelu.suomi24.fi/t/13592337\" urlmsg=\"http://keskustelu.suomi24.fi/t/13592337#comment-79614512\">\n",
    "<paragraph>\n",
    "<sentence>\n",
    "No      1       no      Interj  CASECHANGE_Up   3       intj\n",
    "jos     2       jos     Adv     _       3       advmod\n",
    "teet    3       tehd√§   V       PRS_Sg2|VOICE_Act|TENSE_Prs|MOOD_Ind    0       ROOT\n",
    "sen     4       se      Pron    SUBCAT_Dem|NUM_Sg|CASE_Gen      5       poss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document count: 12453\n",
      "Distinct topics: Paikkakunnat, Tori, Koti ja rakentaminen, Ty√∂ ja opiskelu, Ajanviete, Nuoret, Ruoka ja juoma, MainPage, Suhteet, Lemmikit, Matkailu, Suomi24, Perhe, Ajoneuvot ja liikenne, Yhteiskunta, Tiede ja teknologia, Harrastukset, Viihde ja kulttuuri, Muoti ja kauneus, Ryhm√§t, Urheilu ja kuntoilu, Talous, Terveys\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import codecs\n",
    "txt_re=re.compile(ur'^<text discussionarea=\"(.*?)\".*tid=\"([0-9]+?)\"',re.U)\n",
    "ignore_re=re.compile(ur'^</?(text|sentence|paragraph)')\n",
    "\n",
    "\n",
    "def read_vrt(inp):\n",
    "    \"\"\"Function to read the Suomi24 VRT format\"\"\"\n",
    "    current_topic=None #topic name\n",
    "    current_tid=None #discussion thread number\n",
    "    words=[] #words in the discussion\n",
    "    for line in inp:\n",
    "        line=line.strip()\n",
    "        match=txt_re.match(line)\n",
    "        if match: #we have a new post\n",
    "            if match.group(2)!=current_tid and words:#...and it is not part of the current thread\n",
    "                yield current_topic, words\n",
    "                words=[]\n",
    "            current_topic=match.group(1) #Pick groups out of the regular expression\n",
    "            current_tid=match.group(2)\n",
    "        if ignore_re.match(line):\n",
    "            continue\n",
    "        columns=line.split(u\"\\t\")\n",
    "        if not columns[1].isdigit(): #there seem to be few broken ones, skip\n",
    "            continue\n",
    "        words.append(columns[2].lower())\n",
    "    else: #for loop ran out of items\n",
    "        if words:\n",
    "            yield current_topic, words\n",
    "\n",
    "topics=[] #list of strings\n",
    "texts=[] #list of strings\n",
    "with codecs.open(\"s24.vrt\",\"r\",\"utf-8\") as f:\n",
    "    for topic, words in read_vrt(f):\n",
    "        topics.append(topic)\n",
    "        texts.append(u\" \".join(words))\n",
    "\n",
    "print \"Document count:\", len(topics)\n",
    "print \"Distinct topics:\", u\", \".join(set(topics))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF.IDF weights\n",
    "\n",
    "$$ TF\\cdot\\frac{N}{DF} $$\n",
    "\n",
    "* TF - term frequency - count of term in current document\n",
    "* N - number of documents in the data\n",
    "* DF - number of documents with the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents x features (12453, 229764)\n",
      "feature matrix\n",
      "  (0, 227112)\t0.13654656756\n",
      "  (0, 227095)\t0.109876693955\n",
      "  (0, 226981)\t0.112921934495\n",
      "  (0, 223285)\t0.0671284409095\n",
      "  (0, 219663)\t0.0644993532335\n",
      "  (0, 218297)\t0.0261740937501\n",
      "  (0, 217821)\t0.0602237358203\n",
      "  (0, 215121)\t0.0799111500286\n",
      "  (0, 208541)\t0.0322894333732\n",
      "  (0, 208466)\t0.104748001507\n",
      "  (0, 203132)\t0.0731111585761\n",
      "  (0, 202008)\t0.0455023327263\n",
      "  (0, 200001)\t0.150731517533\n",
      "  (0, 199437)\t0.0306226943858\n",
      "  (0, 199156)\t0.0911279995445\n",
      "  (0, 198843)\t0.100900616753\n",
      "  (0, 198766)\t0.0270201961422\n",
      "  (0, 190661)\t0.0596916611611\n",
      "  (0, 187069)\t0.0299879590476\n",
      "  (0, 180836)\t0.0968389976216\n",
      "  (0, 176730)\t0.0316865123023\n",
      "  (0, 176630)\t0.0637229924694\n",
      "  (0, 175613)\t0.0543242115156\n",
      "  (0, 175480)\t0.112138936284\n",
      "  (0, 171781)\t0.0798338024262\n",
      "  :\t:\n",
      "  (12452, 51024)\t0.0471395227882\n",
      "  (12452, 49511)\t0.0523624941598\n",
      "  (12452, 47227)\t0.0938046288728\n",
      "  (12452, 39342)\t0.0198309929611\n",
      "  (12452, 38446)\t0.0428498935496\n",
      "  (12452, 36926)\t0.0342077174773\n",
      "  (12452, 35690)\t0.0402627124092\n",
      "  (12452, 33898)\t0.063963055679\n",
      "  (12452, 22045)\t0.221856562337\n",
      "  (12452, 22028)\t0.110637013986\n",
      "  (12452, 21767)\t0.0563268241309\n",
      "  (12452, 18529)\t0.0501545164628\n",
      "  (12452, 18505)\t0.0745904885567\n",
      "  (12452, 17933)\t0.0327734929389\n",
      "  (12452, 16719)\t0.0671784333884\n",
      "  (12452, 16541)\t0.0404879839675\n",
      "  (12452, 15929)\t0.059314092321\n",
      "  (12452, 15615)\t0.025171807376\n",
      "  (12452, 15520)\t0.0538450978686\n",
      "  (12452, 13416)\t0.0543064632033\n",
      "  (12452, 1439)\t0.163055672364\n",
      "  (12452, 1283)\t0.0283312901216\n",
      "  (12452, 1267)\t0.0325255517423\n",
      "  (12452, 1246)\t0.151895838882\n",
      "  (12452, 973)\t0.0452302655056\n",
      "features\n",
      "1 !\n",
      "5001 16:12\n",
      "10001 4770r-kone\n",
      "15001 aerosoli|pakkaus\n",
      "20001 ansaitsekkaan\n",
      "25001 bailu\n",
      "30001 counter\n",
      "35001 ellinooraaa\n",
      "40001 eu|ajo|kortti\n",
      "45001 grupperna\n",
      "50001 henkil√∂|tunniste\n",
      "55001 http://jukkawallin.puheenvuoro.uusisuomi.fi/197028-toistaako-historia-jalleen-itseaan\n",
      "60001 http://yle.fi/uutiset/kiihottavia_pornoloytoja_ei_juuri_somepaivityksissa_jaeta/7851960\n",
      "65001 hyys√§√§m√§√§√§n\n",
      "70001 inverkar\n",
      "75001 joukko|vaino\n",
      "80001 kaksois|kytkin\n",
      "85001 keksi\n",
      "90001 kissanraksua\n",
      "95001 koukero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2641: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_extraction\n",
    "\n",
    "def tokenizer(txt):\n",
    "    \"\"\"Simple whitespace tokenizer\"\"\"\n",
    "    return txt.split()\n",
    "\n",
    "#Extract the features\n",
    "tfidf_v=sklearn.feature_extraction.text.TfidfVectorizer(tokenizer=tokenizer) #,max_df=0.9\n",
    "d=tfidf_v.fit_transform(texts)\n",
    "print \"documents x features\", d.shape\n",
    "print \"feature matrix\"\n",
    "print d\n",
    "print \"features\"\n",
    "fnames=tfidf_v.get_feature_names()\n",
    "for feature_id in range(1,100000,5000):\n",
    "    print feature_id,fnames[feature_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "* Will be explained during the lecture, Google if you couldn't attend\n",
    "* Key concepts:\n",
    "  - Separating hyperplane\n",
    "  - Margin\n",
    "  - Errors and slack variables\n",
    "  - The parameter C\n",
    "  - Regularization\n",
    "  \n",
    "<img src=\"http://docs.opencv.org/2.4/_images/sample-errors-dist.png\"/>\n",
    "\n",
    "* Multiclass classification = number of classes > 2\n",
    "* One vs all = train a classifier for each class, pick the max score\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "* Will be explained during the lecture, Google key concepts if you couldn't attend\n",
    "* Key concepts:\n",
    "  - Accuracy, Precision, Recall, F-score\n",
    "  - Train / Development / Test Data\n",
    "  - Crossvalidation\n",
    "  - Overfitting\n",
    "  - Parameter optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.010  Accuracy=37.42%\n",
      "C=0.100  Accuracy=59.82%\n",
      "C=1.000  Accuracy=66.68%\n",
      "C=10.000  Accuracy=66.62%\n",
      "C=100.000  Accuracy=65.95%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.cross_validation\n",
    "X_train,X_test,Y_train,Y_test=sklearn.cross_validation.train_test_split(d, topics, test_size=0.3, random_state=0)\n",
    "\n",
    "for C in (0.01,0.1,1,10,100):\n",
    "    lin_clf = sklearn.svm.LinearSVC(C=C)\n",
    "    lin_clf.fit(X_train,Y_train)\n",
    "    print \"C=%.3f  Accuracy=%.2f%%\"%(C,lin_clf.score(X_test,Y_test)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...66% is not bad, keeping in mind we have 23 classes to choose from.\n",
    "\n",
    "# Random baseline\n",
    "\n",
    "* That we have 23 classes doesn't mean our baseline is 1/23!\n",
    "* Class imbalance\n",
    "* Accuracy susceptible to this!\n",
    "\n",
    "How do we fare compared to making random choices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier predicting most frequent class: 28.88%\n",
      "Dummy classifier predicting at random by class dist.: 13.01%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.dummy\n",
    "dummy=sklearn.dummy.DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train,Y_train)\n",
    "print \"Dummy classifier predicting most frequent class: %.2f%%\"%(dummy.score(X_test,Y_test)*100.0)\n",
    "dummy=sklearn.dummy.DummyClassifier(strategy=\"stratified\")\n",
    "dummy.fit(X_train,Y_train)\n",
    "print \"Dummy classifier predicting at random by class dist.: %.2f%%\"%(dummy.score(X_test,Y_test)*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if you predict the most frequent class, you get to 28% accuracy and with the simple SVM we get 66% accuracy. I.e we can safely say the classifier is learning something. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character n-grams\n",
    "\n",
    "* Quite popular choice\n",
    "* Does it work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents x features (12453, 229764)\n",
      "feature matrix\n",
      "  (0, 327495)\t0.0279364084575\n",
      "  (0, 327494)\t0.0246940006294\n",
      "  (0, 326082)\t0.0284459123917\n",
      "  (0, 326081)\t0.0195666672323\n",
      "  (0, 325561)\t0.0570182735877\n",
      "  (0, 325556)\t0.0397059026255\n",
      "  (0, 323870)\t0.0145962063742\n",
      "  (0, 323857)\t0.0141140700881\n",
      "  (0, 323698)\t0.0329225192112\n",
      "  (0, 323691)\t0.0325440317323\n",
      "  (0, 323579)\t0.013446493561\n",
      "  (0, 323569)\t0.00752836225688\n",
      "  (0, 323164)\t0.0143551104277\n",
      "  (0, 323159)\t0.0139049754487\n",
      "  (0, 322949)\t0.0260674398704\n",
      "  (0, 322948)\t0.0252456237298\n",
      "  (0, 322845)\t0.0755417813006\n",
      "  (0, 322843)\t0.0727451050801\n",
      "  (0, 322632)\t0.0144044808613\n",
      "  (0, 322621)\t0.0124514648769\n",
      "  (0, 322401)\t0.0172161118601\n",
      "  (0, 322400)\t0.0151691640639\n",
      "  (0, 322151)\t0.0413451316873\n",
      "  (0, 322141)\t0.0229695854203\n",
      "  (0, 321922)\t0.0415038550878\n",
      "  :\t:\n",
      "  (12452, 7121)\t0.012006175183\n",
      "  (12452, 7119)\t0.0228802062083\n",
      "  (12452, 7107)\t0.0191241708685\n",
      "  (12452, 7104)\t0.00912417192638\n",
      "  (12452, 7100)\t0.0192372220089\n",
      "  (12452, 7093)\t0.0294206477113\n",
      "  (12452, 6326)\t0.0169746067645\n",
      "  (12452, 6325)\t0.0132810244705\n",
      "  (12452, 6323)\t0.0135998608957\n",
      "  (12452, 6281)\t0.0216733813397\n",
      "  (12452, 1349)\t0.0633947077443\n",
      "  (12452, 1348)\t0.0606419300251\n",
      "  (12452, 1307)\t0.0101769197325\n",
      "  (12452, 1304)\t0.0127530473273\n",
      "  (12452, 1303)\t0.0182593358082\n",
      "  (12452, 1216)\t0.0191201747253\n",
      "  (12452, 1215)\t0.0154287139419\n",
      "  (12452, 1214)\t0.0241872736056\n",
      "  (12452, 1207)\t0.0239623912573\n",
      "  (12452, 1174)\t0.0168917636929\n",
      "  (12452, 1163)\t0.0550608416555\n",
      "  (12452, 899)\t0.00946902812298\n",
      "  (12452, 893)\t0.00828576678397\n",
      "  (12452, 881)\t0.0133338344521\n",
      "  (12452, 850)\t0.0174998320168\n",
      "features\n",
      "1 \u0005 ( \n",
      "5001  70e\n",
      "10001  hah\n",
      "15001  sil\n",
      "20001  ‚ñ™ h\n",
      "25001 *k1\n",
      "30001 -31_\n",
      "35001 -zi-\n",
      "40001 .vul\n",
      "45001 /non\n",
      "50001 05/\n",
      "55001 1093\n",
      "60001 1‚Äì45\n",
      "65001 2cb\n",
      "70001 39-\n",
      "75001 4844\n",
      "80001 564b\n",
      "85001 6767\n",
      "90001 7_r\n",
      "95001 8p v\n"
     ]
    }
   ],
   "source": [
    "tfidf_v_char=sklearn.feature_extraction.text.TfidfVectorizer(analyzer='char',ngram_range=(3,4)) #,max_df=0.9\n",
    "d_char=tfidf_v_char.fit_transform(texts)\n",
    "print \"documents x features\", d.shape\n",
    "print \"feature matrix\"\n",
    "print d_char\n",
    "print \"features\"\n",
    "fnames=tfidf_v_char.get_feature_names()\n",
    "for feature_id in range(1,100000,5000):\n",
    "    print feature_id,fnames[feature_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.010  Accuracy=43.98%\n",
      "C=0.100  Accuracy=63.30%\n",
      "C=1.000  Accuracy=68.55%\n"
     ]
    }
   ],
   "source": [
    "X_train_char,X_test_char,Y_train_char,Y_test_char=\\\n",
    "    sklearn.cross_validation.train_test_split(d_char, topics, test_size=0.3, random_state=0)\n",
    "\n",
    "for C in (0.01,0.1,1):\n",
    "    lin_clf_char = sklearn.svm.LinearSVC(C=C)\n",
    "    lin_clf_char.fit(X_train_char,Y_train_char)\n",
    "    print \"C=%.3f  Accuracy=%.2f%%\"%(C,lin_clf_char.score(X_test_char,Y_test_char)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forget about words and you'll get better numbers! Cool, eh? :)\n",
    "\n",
    "Does this generalize? Let's run on Finnish tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I gathered a bunch of totally random Finnish tweets, will my model work?\n",
    "import json\n",
    "\n",
    "tweets=[]\n",
    "with open(\"fin_tweets.json\",\"r\") as f:\n",
    "    for lineno,line in enumerate(f):\n",
    "        line=line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            tweet=json.loads(line)\n",
    "        except ValueError: #some of these are broken\n",
    "            continue\n",
    "        tweets.append(tweet[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(886, 336566)\n",
      "Yhteiskunta  ---  RT @zeekends: wcw babe ; isha asli sofia rye vanessa üëÖ\n",
      "Yhteiskunta  ---  DaanLuyten #TilItHappensToYou #BestMovieSong #iHeartAwards\n",
      "Yhteiskunta  ---  Mulla on kangasv√§ri√§ farkuissa rip üò¢üò¢ https://t.co/67iudMBfuj\n",
      "Yhteiskunta  ---  @MaayronFerreira IJAEJIOEJIOEAJOIEAJI\n",
      "Yhteiskunta  ---  #NowPlaying BFC-radio (@BFC_radio) https://t.co/xYZVlndWyG ‚Ä¶ #Erdioo\n",
      "Yhteiskunta  ---  omfg esQUEJ MEESTOYJ\n",
      "Yhteiskunta  ---  Meik√§ oli jo hetken pitk√§perjantaissa. Ja nyt on vasta kiiraskeskiviikko. P√§iv√§t sekoo kun on n√§it√§ pyhi√§.\n",
      "Yhteiskunta  ---  [22:59:10] 118.113.52.162:4384 &gt;&gt; :1433 (TCP:SYN)\n",
      "Ty√∂ ja opiskelu  ---  Oho tukkani on ekaa kertaa vuosiin mitassa jossa se alkaa aaltoilla ellen kampaa sit√§ suoraksi suihkun j√§lkeen. Hassua.\n",
      "Yhteiskunta  ---  #vibrator adulttoys #sextoys https://t.co/dk83khR6lo\n",
      "Yhteiskunta  ---  T√§n√§√§n osui Hip Hop ja Rap YouTube Video Suomessa.„ÄåCheek„Äç's „ÄéKuka Muu Muka„Äè https://t.co/pQQ8kJTWiL\n",
      "Yhteiskunta  ---  [23:00:26] 125.123.234.198:2980 &gt;&gt; :1433 (TCP:SYN)\n",
      "Yhteiskunta  ---  #fucking adulttoys #vibrator https://t.co/fixAjHsUTT\n",
      "Viihde ja kulttuuri  ---  #Lowongan kerja Sales Finance Business Partner - Mondelƒìz International Jakarta https://t.co/VBxzdYnJCN #loker lowker\n",
      "Yhteiskunta  ---  Tykk√§sin @YouTube-videosta, jonka teki @pixeldan https://t.co/IIJcOiWOpu Batman v Superman Massive Mystery Box Unboxing! - Lego,\n",
      "Yhteiskunta  ---  @nicolettching @Mdcarigaba @Espanto2001 zxcvbnm kyaaaah üòçüòÇ\n",
      "Ajanviete  ---  Uva passa https://t.co/vbn2dUmGw1\n",
      "Yhteiskunta  ---  #fucking adulttoys #sextoys https://t.co/W2O7prQfli\n",
      "Yhteiskunta  ---  RT @imazlum: Dr. Itƒ±r Toks√∂z presenting us on Peace Studies, Syria and Refugees #wednesdaytalks @itirtoksoz @MURCIR https://t.co/VZem98vrwo\n",
      "Yhteiskunta  ---  #sextoys adulttoys #masturbating https://t.co/DDPzcocs8P\n",
      "Yhteiskunta  ---  #fucking adulttoys #analdildo https://t.co/59lnPa0FDF\n",
      "Paikkakunnat  ---  Suomessa henkil√∂st√∂johtajat junnaavat yh√§ tehokkuudessa, kun muualla sitouttaminen on t√§rke√§√§\n",
      "https://t.co/TF0OSuLaGD\n",
      "Yhteiskunta  ---  Seiy≈´ : Kanako Mitsuhashi (1999)\n",
      "Yhteiskunta  ---  RT @Partiokuuluu: Monikulttuurisen rekrytoinnin t√§rkein sana on tervetuloa! https://t.co/OsDf9IhaUG #partioscout #rasisminvastainenviikko #‚Ä¶\n",
      "Yhteiskunta  ---  TPS:n p√§√§valmentaja Mika Laurikainen on nimennyt kokoonpanon illan FC Honka-TPS-otteluun #FCTPS #SuomenCup #Ykk√∂nen https://t.co/hACuGsdWh2\n",
      "Yhteiskunta  ---  RT @KiipulaAO: Ajankohtainen julkaisu, ammattitaitomaajoukkueemme juuri kisojen kynnyksell√§! #Abilympics #ammatillinenkoulutus https://t.co‚Ä¶\n",
      "Yhteiskunta  ---  @AjatustenVanki en oo vege. Kanasalaatti on hyv√§√§ x) enk√§ sy√∂ muutenkaan kuin kanahamppareita xD\n",
      "Yhteiskunta  ---  RT @prillvers_kudus: @Prillverskubdg_ amiin YRA\n",
      "#CantWaitAnnivPV5th\n",
      "Yhteiskunta  ---  RT @KouvolanSanomat: Suomen ensimm√§inen Youtube -opintojakso Kaakkois-Suomen ammattikorkeakouluun‚Äâ‚Äî‚Äâopettajina maan suosituimmat‚Ä¶ https://t‚Ä¶\n",
      "Yhteiskunta  ---  Mikkeli: pahoinpitely L√§nsi-Savo 23.3.2016 15:54 18-vuotias nainen puukotti samanik√§is.. #Mikkeli https://t.co/Op9cRbdPCd\n",
      "Yhteiskunta  ---  @kenekk0317 lhmtalrtjstytyftyudrstysryfyjdsfgudtgyhimfti,yhimjnfyundrtmdrtujndrtrdtmutymdrthnrtyndrturydtydhkgfyildtysrtsyssryisrys\n",
      "Yhteiskunta  ---  Kirjoitus antoi kuvan, ett√§ miehille keskivartalolihavuus on ep√§terveellist√§, naisille \"ei kivan n√§k√∂ist√§\". Yll√§ttik√∂ neg. palaute? @ksmlfi\n",
      "Yhteiskunta  ---  LIVE-l√§hetys #Periscope-sovelluksessa: jooo laulua niin o https://t.co/WXgGHgrAX3\n",
      "Yhteiskunta  ---  11:11 wigetta\n",
      "Yhteiskunta  ---  @JuusoQ Ranskanbulldoggi-mittelspitz, on s√∂p√∂!\n",
      "Suhteet  ---  RT @Nduweybadass: Which Rihanna? Rihanna Rihanna or Rihanna Mkhwanazi https://t.co/XghUBGt007\n",
      "Yhteiskunta  ---  @BTS_twt jin~san kakkoi desu  ^^\n",
      "Yhteiskunta  ---  RT @MitasanSharp: MX-3070N / MX-3570N / MX-4070N (Phoenix)\n",
      " \n",
      "Geli≈ümi≈ü CR4 teknolojisiyle Yeni Sharp renkli √ºr√ºnleri‚Ä¶ https://t.co/XwgZz32DY1\n",
      "Yhteiskunta  ---  RT @lehtinen_esa: Suomessa HR-johto keskittyy HR-j√§rjestelmiin, muualla yrityskulttuurin vahvistamiseen ja ihmisten sitouttamiseen.https://‚Ä¶\n",
      "Yhteiskunta  ---  Ruuvi s√§ve! Karjala kadulla Alppilassa. Mit√§ vaa ruuvei! Sheiiiiiiiit! #studio #construction #prolevel #t√∂rkeduni https://t.co/cyXIFSthbC\n",
      "Yhteiskunta  ---  @skewnger hello joo oppa!\n",
      "Yhteiskunta  ---  @TopiYrjl Ei varmasti. Ai ett√§ sit√§ paskamyrskyn m√§√§r√§√§. :D\n",
      "Yhteiskunta  ---  RT @kskokoomus: @alexstubb vastaanottaa Saarij√§rven #kokoomuksen terveiset Harri Lehtiselt√§ ja Esa J√§rviselt√§. https://t.co/5ir4WfTxjy\n",
      "Yhteiskunta  ---  huurhun shuu https://t.co/xyQU8fmtmM\n",
      "Yhteiskunta  ---  #sextoys adulttoys #cockring https://t.co/6Cgg1eiVMd\n",
      "Yhteiskunta  ---  @kuningaskulutta Olisi ollut turhauttavaa joutua siirt√§m√§√§n p√§ivitt√§iset raha-asiat lainan vuoksi. Jotenkin tykk√§√§n, kun ovat erill√§√§n.\n",
      "Yhteiskunta  ---  RT @OutwardBoundFIN: Satavuotiaan Mallan luonnonpuiston uusi tunnus kunnioittaa alueen ainutlaatuista luontoa https://t.co/jT5YMi5VoB https‚Ä¶\n",
      "Yhteiskunta  ---  RT @GreenpeaceSuomi: My√∂s YK:n ihmisoikeusvaltuutettu liittyi mets√§hallituslain arvostelijoihin! #mets√§hallituslaki @UNHumanRights https://‚Ä¶\n",
      "Yhteiskunta  ---  Kuva: Meteoriitti sy√∂ksyi Mikkeliin ‚Äì tulipallo n√§kyi satojen kilometrien p√§√§h√§n {iltasanomat} https://t.co/ML75s9Uvnx\n",
      "Yhteiskunta  ---  RT @catwomaine: slvsufudjbshuygxv https://t.co/aHkyyGFpSX\n",
      "Yhteiskunta  ---  ZXCVBNM\n"
     ]
    }
   ],
   "source": [
    "d_tweet_char=tfidf_v_char.transform(tweets)\n",
    "print d_tweet_char.shape\n",
    "for counter,(tweet, cls) in enumerate(zip(tweets,lin_clf_char.predict(d_tweet_char))):\n",
    "    print cls, \" --- \", tweet\n",
    "    if counter==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-O\n",
    "\n",
    "Oh good lord - twitter is such crap! [pulling hair 1AM the night before the lecture] Let's try to apply some of our newly acquired skills to recover. :| How about we try run the tweets through the parser and check the words against the top-most Finnish vocabulary and only keep tweets of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oho tukka olla eka kerta vuosi mitta joka se alkaa aaltoilla josei kammata se suora suihku j√§lkeen . hassu .\n",
      "@kuningaskulutta olla olla turhauttaa joutua siirt√§√§ p√§ivitt√§inen raha-asia laina vuoksi . jotenkin tyk√§t√§ , kun olla erill√§√§n .\n",
      "@maijalarmo tuoda Felix uusi korkki olla ihan ykk√∂nen\n",
      "ei haluu liikkua , pit√§√§ menn√§ kauppa mut ulkona sata lumi ja m√§ olla ruokakooma p√§√§ll√§ ugh\n",
      "@BornForFiNRS m√§ ei √§rsytt√§√§ viel√§ koska vet√§√§ just pussi fanipaloi ja nyt sattua maha lol\n",
      "@RenneKorppila vai sellanen kaveri . m√§ ei toisaalta mik√§√§n ihme ett√§ei olla koskaan kuulla ko . tyyppi .\n",
      "@Kinukki sanoma olla selv√§ , ett√§ ei uskoa olla v√§√§r√§ kun arvella sin√§ kertoa t√§m√§ itse ,olethan aikuinen ..\n",
      "@Nysses ei . olla ilo huomata ett√§ min√§ @jysk_fi t√§m√§ tapahtua p√§ivitt√§in ja asiakaspalvelu olla kunnia-asia .\n",
      "paitsi ain olla kiva n√§h√§ √§mmii tappelees mut veikka t√§m√§ menoo vappun sata lumi\n",
      "RT @SaaraHuttunen : m√§ haluta olla terve ja onnellinen . muu prioriteetti m√§ ei nyt olla . toki koulu ois kiva joskus valmistua\n"
     ]
    }
   ],
   "source": [
    "import lwvlib\n",
    "wv=lwvlib.load(\"pb34_lemma_200_v2.bin\",70000,70000)\n",
    "\n",
    "def read_conllu(inp):\n",
    "    tweet=[] #list of lemmas\n",
    "    for line in inp:\n",
    "        line=line.strip().replace(u\"#\",u\"\")\n",
    "        if not line:\n",
    "            yield tweet\n",
    "            tweet=[]\n",
    "        else:\n",
    "            tweet.append(line.split(u\"\\t\")[2])\n",
    "            \n",
    "import re\n",
    "wrdre=re.compile(u\"^[a-z√§√∂√•-]+$\")\n",
    "def known_words(tweet):\n",
    "    return sum(1 for word in tweet if word in wv.words and wrdre.match(word))\n",
    "\n",
    "tweets=[]\n",
    "with codecs.open(\"fin_tweets.conllu\",\"r\",\"utf-8\") as f:\n",
    "    for tweet in read_conllu(f):\n",
    "        if float(known_words(tweet))/len(tweet)>0.7:\n",
    "            tweets.append(u\" \".join(tweet).replace(u\"#\",u\"|\"))\n",
    "for t in tweets[:10]:\n",
    "    print t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 336566)\n",
      "Koti ja rakentaminen  ---  oho tukka olla eka kerta vuosi mitta joka se alkaa aaltoilla josei kammata se suora suihku j√§lkeen . hassu .\n",
      "\n",
      "Yhteiskunta  ---  @kuningaskulutta olla olla turhauttaa joutua siirt√§√§ p√§ivitt√§inen raha-asia laina vuoksi . jotenkin tyk√§t√§ , kun olla erill√§√§n .\n",
      "\n",
      "Paikkakunnat  ---  @maijalarmo tuoda Felix uusi korkki olla ihan ykk√∂nen\n",
      "\n",
      "Suhteet  ---  ei haluu liikkua , pit√§√§ menn√§ kauppa mut ulkona sata lumi ja m√§ olla ruokakooma p√§√§ll√§ ugh\n",
      "\n",
      "Suhteet  ---  @BornForFiNRS m√§ ei √§rsytt√§√§ viel√§ koska vet√§√§ just pussi fanipaloi ja nyt sattua maha lol\n",
      "\n",
      "Yhteiskunta  ---  @RenneKorppila vai sellanen kaveri . m√§ ei toisaalta mik√§√§n ihme ett√§ei olla koskaan kuulla ko . tyyppi .\n",
      "\n",
      "Suhteet  ---  @Kinukki sanoma olla selv√§ , ett√§ ei uskoa olla v√§√§r√§ kun arvella sin√§ kertoa t√§m√§ itse ,olethan aikuinen ..\n",
      "\n",
      "Yhteiskunta  ---  @Nysses ei . olla ilo huomata ett√§ min√§ @jysk_fi t√§m√§ tapahtua p√§ivitt√§in ja asiakaspalvelu olla kunnia-asia .\n",
      "\n",
      "Yhteiskunta  ---  paitsi ain olla kiva n√§h√§ √§mmii tappelees mut veikka t√§m√§ menoo vappun sata lumi\n",
      "\n",
      "Nuoret  ---  RT @SaaraHuttunen : m√§ haluta olla terve ja onnellinen . muu prioriteetti m√§ ei nyt olla . toki koulu ois kiva joskus valmistua\n",
      "\n",
      "Yhteiskunta  ---  @gynsy @MikiHoijer tarkistaa viel√§ , ett√§ kuusi se pit√§√§ alkaa . kerta olla kytt√§ enemm√§n kuin osallistuja .\n",
      "\n",
      "Paikkakunnat  ---  Nonii , nyt paikka v√§h√§n enemm√§n t√§ynn√§ . h√§m√§r√§sti t√§ytty√§ t√§√§ n√§in pienes ajaa\n",
      "\n",
      "Yhteiskunta  ---  @MaipuMaire @Mallas6 hyv√§ niin . saaristo se h√§ijy kaveri joka levitt√§√§ h√§ijy tauti .\n",
      "\n",
      "Urheilu ja kuntoilu  ---  ja niin se olla , ett√§ kova treeni jo itsess√§√§n olla stressi ja vied√§ energia palautua ja henkinen stressi viel√§ . hy√∂tyk√§ytt√∂ siis !\n",
      "\n",
      "Lemmikit  ---  @maailmanvaltias enkkuu ! jos lykky siis k√§yd√§ ja p√§√§st√§ ... suunta ehk√§ opettaja mut ei sulkea muu vaihtoehtoi pois jos mieli muuttua !\n",
      "\n",
      "Yhteiskunta  ---  @ManninenJoonas katsottavahko ? varmaan se vaihe kun ei en√§√§ pysy√§ hereill√§ tai muuten keskitty√§ elokuva mitenk√§√§n\n",
      "\n",
      "Paikkakunnat  ---  @yleuutiset ei olla kun merkki mik√§ viitata suomalainen astia teollisuus . t√§mm√∂inen joskus tehd√§ suomi\n",
      "\n",
      "Ty√∂ ja opiskelu  ---  @emohilkka m√§ voida my√∂s kirjoa ka essee ennen ku syke alkaa\n",
      "\n",
      "Yhteiskunta  ---  @Mirppu @Elmatule ei se toi aika pian loppua . vartija viimeist√§√§n puhaltaa peli poikki .\n",
      "\n",
      "Suhteet  ---  psykologia olla niin mielenkiintosta tyk√§t√§\n",
      "\n",
      "Yhteiskunta  ---  @BLAKKIIIIISSSSS jos suoraan sanoa , olla s√§√§litt√§v√§ jos ruveta tubettajaksi vain raha ja maine takia . Tubenomithautaan\n",
      "\n",
      "Suhteet  ---  ei juuri kuunnella david bowien musa mut t√§lleen pinnallisesti voida sanoa ett√§ olla se kyll√§ perkele kaunis √§ij√§\n",
      "\n",
      "Yhteiskunta  ---  kuka helvetti tuoda t√§nne k√§mpp√§ suklaa ? terve possu .\n",
      "\n",
      "Yhteiskunta  ---  olla melko varma , ett√§ joku m√§ naapuri ulkoiluttaa kissa , kun tulla ty√∂ koti . h√§mmenty√§ . ulkona olla pakkanen .\n",
      "\n",
      "Paikkakunnat  ---  nonii nyt olla eve aino ja elina tehd√§ jo konsepti kai se itekki piakkoin voida tiet√§√§ ett√§ se kyll√§ √§rsytt√§√§ moni anteeksi etuk√§teen : )\n",
      "\n",
      "Yhteiskunta  ---  @heikki_hakala olla edelleen h√§mi ja kummi Moskova matka tulos . ett√§ mik√§ se oikein olla siis .\n",
      "\n",
      "Paikkakunnat  ---  @wwimpula voida vaan alkaa hoitaa omia asioida puhelin tolleen üòÇ? ?\n",
      "\n",
      "Paikkakunnat  ---  se olla se vaihe menett√§√§ tapaus ku pizzeria osata tilaus ..\n",
      "\n",
      "Suhteet  ---  @montuttaja @mitavittualehti nyt olla vied√§ valkoinen itseinho ihan uusi taso WhiteGenocideIsReal\n",
      "\n",
      "Urheilu ja kuntoilu  ---  @LottaEmpi m√§ salisuunnitelma menn√§ muu suunnitelma kanssa ketju pl√∂rin√§ , huomenna treeni taas sali !\n",
      "\n",
      "Paikkakunnat  ---  t√§√§ olla sellanen cannot unsee tilanne itq\n",
      "\n",
      "Yhteiskunta  ---  onneksi olla internet ja urpoja joka purkaa oma vitutus .\n",
      "\n",
      "Yhteiskunta  ---  olla tuo syke vaan niin mukiinmenev√§ sarja n√§in keskiviikkoilta üëå\n",
      "\n",
      "Suhteet  ---  @dragmenialI √§iti ja isk√§ m√§ el√§√§ olla niin ihana\n",
      "\n",
      "Suhteet  ---  nyt kun olla t√§ysik√§nen ni mut pist√§√§ aina maistella alkoholijuomii . t√§n√§√§n testi vadelmaskumppa - kaikki nauro ku irvistell√§ vaan :(\n",
      "\n",
      "Paikkakunnat  ---  voida kyl olla ei ite j√§nnitt√§√§ enemm√§n ku poikkis mut olla se iso juttu esitt√§yty√§ koko suku ! etenkin ku olla muuttamas yhteen ihan pian\n",
      "\n",
      "Yhteiskunta  ---  t√§√§ TIsuomi olla pit√§√§ tulla l√§√§ppij√§ kohu aika . üòÉ se olla olla helvetti irti\n",
      "\n",
      "Yhteiskunta  ---  halu toi nyt pelk√§st√§√§ jo esteettinen syy , herra varjella\n",
      "\n",
      "Yhteiskunta  ---  @maaaw joku vanki olla varmaan taas unohtua palata loma\n",
      "\n",
      "Paikkakunnat  ---  @dragmenialI s√§ olla ja kato nyt tota t√§ydellinen konsepti\n",
      "\n",
      "Yhteiskunta  ---  @suski_kaukinen @laurahaimila tuo olla h√∂lm√∂ jopa sin√§ n√§pp√§imist√∂ . rasismi t√§m√§ ketju olla kaikki puoli\n",
      "\n",
      "Yhteiskunta  ---  hetki ihmetell√§ ett√§ei yksik√§√§n ottelu olla menn√§ viel√§ jatkorei 'ille , mut t√§√§ uusi formaatti mukaan voida p√§√§tty√§ tasan . Nj√§h..\n",
      "\n",
      "Yhteiskunta  ---  vaarallinen\n",
      "\n",
      "Suhteet  ---  ai vittu . tajuta just ei m√§ ei voida jatkaa ku tajuta saattaa spoilaa . sori .\n",
      "\n",
      "Viihde ja kulttuuri  ---  pitk√§ kausi takana . upea hetki ja my√∂s pieni pettymys tunne . t√§m√§ kaivaa voima ja palata vahva ensi kausi ! Ketter√§\n",
      "\n",
      "Suhteet  ---  tai no , ymm√§rt√§√§ jos se olla kuva joka vied√§ koko aukeama ... mutta kuitenkin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_tweet_char=tfidf_v_char.transform(tweets)\n",
    "print d_tweet_char.shape\n",
    "for counter,(tweet, cls) in enumerate(zip(tweets,lin_clf_char.predict(d_tweet_char))):\n",
    "    print cls, \" --- \", tweet\n",
    "    print\n",
    "    if counter==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And how about the vectors, do they help any?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.10225586,  0.08287574,  0.04128639, ...,  0.01366414,\n",
       "         0.14373324,  0.17274647],\n",
       "       [-0.05364433, -0.01276515,  0.0603284 , ...,  0.00620707,\n",
       "         0.19762445,  0.13600904],\n",
       "       [-0.06920946,  0.01818488,  0.03807921, ...,  0.02176174,\n",
       "         0.13039736,  0.17019013],\n",
       "       ..., \n",
       "       [-0.07167699,  0.06385985,  0.05177857, ..., -0.00953654,\n",
       "         0.17387475,  0.13991461],\n",
       "       [-0.06337436,  0.04784775,  0.04624651, ...,  0.03932344,\n",
       "         0.09021433,  0.12855842],\n",
       "       [-0.10096667,  0.06961406,  0.01622496, ..., -0.01524248,\n",
       "         0.14144494,  0.164709  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lwvlib\n",
    "import numpy\n",
    "wv=lwvlib.load(\"pb34_lemma_200_v2.bin\",50000,50000)\n",
    "\n",
    "def doc2vec(txt,wv,i,data_matrix):\n",
    "    \"\"\"Text with whitespace tokenization\n",
    "    wv\n",
    "    i - which row are we filling\n",
    "    data_matrix - and to where?\"\"\"\n",
    "    for w in txt.split():\n",
    "        w=w.lower()\n",
    "        dim=wv.get(w)\n",
    "        if dim==None:\n",
    "            continue\n",
    "        data_matrix[i]+=wv.vectors[dim]\n",
    "\n",
    "#topics,texts\n",
    "data_matrix=numpy.zeros((len(texts),wv.vectors.shape[1]))\n",
    "for i,txt in enumerate(texts):\n",
    "    doc2vec(txt,wv,i,data_matrix)\n",
    "sklearn.preprocessing.normalize(data_matrix,copy=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls=sklearn.svm.LinearSVC(C=1.0)\n",
    "cls.fit(data_matrix[:10000],topics[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59315124337545866"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.score(data_matrix[10000:],topics[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 23\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "0s - loss: 2.6129 - acc: 0.2510 - val_loss: 2.3120 - val_acc: 0.3457\n",
      "Epoch 2/100\n",
      "0s - loss: 2.3415 - acc: 0.3149 - val_loss: 2.1417 - val_acc: 0.3963\n",
      "Epoch 3/100\n",
      "0s - loss: 2.2013 - acc: 0.3466 - val_loss: 2.0366 - val_acc: 0.4387\n",
      "Epoch 4/100\n",
      "0s - loss: 2.0875 - acc: 0.3940 - val_loss: 1.9314 - val_acc: 0.4633\n",
      "Epoch 5/100\n",
      "0s - loss: 1.9935 - acc: 0.4280 - val_loss: 1.8639 - val_acc: 0.4880\n",
      "Epoch 6/100\n",
      "0s - loss: 1.9230 - acc: 0.4533 - val_loss: 1.8401 - val_acc: 0.4793\n",
      "Epoch 7/100\n",
      "1s - loss: 1.8661 - acc: 0.4650 - val_loss: 1.7977 - val_acc: 0.4993\n",
      "Epoch 8/100\n",
      "0s - loss: 1.8140 - acc: 0.4759 - val_loss: 1.7457 - val_acc: 0.5007\n",
      "Epoch 9/100\n",
      "1s - loss: 1.7796 - acc: 0.4880 - val_loss: 1.7327 - val_acc: 0.5083\n",
      "Epoch 10/100\n",
      "1s - loss: 1.7398 - acc: 0.4964 - val_loss: 1.6941 - val_acc: 0.5173\n",
      "Epoch 11/100\n",
      "0s - loss: 1.7191 - acc: 0.5017 - val_loss: 1.7063 - val_acc: 0.5160\n",
      "Epoch 12/100\n",
      "0s - loss: 1.7055 - acc: 0.5049 - val_loss: 1.6559 - val_acc: 0.5253\n",
      "Epoch 13/100\n",
      "0s - loss: 1.6659 - acc: 0.5131 - val_loss: 1.6372 - val_acc: 0.5297\n",
      "Epoch 14/100\n",
      "0s - loss: 1.6457 - acc: 0.5190 - val_loss: 1.6180 - val_acc: 0.5417\n",
      "Epoch 15/100\n",
      "1s - loss: 1.6239 - acc: 0.5279 - val_loss: 1.6176 - val_acc: 0.5430\n",
      "Epoch 16/100\n",
      "0s - loss: 1.6152 - acc: 0.5306 - val_loss: 1.6246 - val_acc: 0.5350\n",
      "Epoch 17/100\n",
      "0s - loss: 1.5962 - acc: 0.5377 - val_loss: 1.6113 - val_acc: 0.5527\n",
      "Epoch 18/100\n",
      "0s - loss: 1.5836 - acc: 0.5441 - val_loss: 1.5843 - val_acc: 0.5473\n",
      "Epoch 19/100\n",
      "0s - loss: 1.5668 - acc: 0.5463 - val_loss: 1.6136 - val_acc: 0.5357\n",
      "Epoch 20/100\n",
      "0s - loss: 1.5509 - acc: 0.5487 - val_loss: 1.5529 - val_acc: 0.5610\n",
      "Epoch 21/100\n",
      "0s - loss: 1.5444 - acc: 0.5500 - val_loss: 1.5548 - val_acc: 0.5637\n",
      "Epoch 22/100\n",
      "0s - loss: 1.5230 - acc: 0.5573 - val_loss: 1.5401 - val_acc: 0.5650\n",
      "Epoch 23/100\n",
      "0s - loss: 1.5199 - acc: 0.5566 - val_loss: 1.5399 - val_acc: 0.5677\n",
      "Epoch 24/100\n",
      "0s - loss: 1.5040 - acc: 0.5600 - val_loss: 1.5418 - val_acc: 0.5670\n",
      "Epoch 25/100\n",
      "1s - loss: 1.4990 - acc: 0.5650 - val_loss: 1.5400 - val_acc: 0.5663\n",
      "Epoch 26/100\n",
      "0s - loss: 1.4863 - acc: 0.5644 - val_loss: 1.5799 - val_acc: 0.5650\n",
      "Epoch 27/100\n",
      "0s - loss: 1.4825 - acc: 0.5757 - val_loss: 1.5298 - val_acc: 0.5747\n",
      "Epoch 28/100\n",
      "0s - loss: 1.4687 - acc: 0.5699 - val_loss: 1.5570 - val_acc: 0.5633\n",
      "Epoch 29/100\n",
      "0s - loss: 1.4687 - acc: 0.5687 - val_loss: 1.5111 - val_acc: 0.5773\n",
      "Epoch 30/100\n",
      "0s - loss: 1.4544 - acc: 0.5791 - val_loss: 1.5511 - val_acc: 0.5573\n",
      "Epoch 31/100\n",
      "0s - loss: 1.4565 - acc: 0.5770 - val_loss: 1.5242 - val_acc: 0.5763\n",
      "Epoch 32/100\n",
      "0s - loss: 1.4483 - acc: 0.5826 - val_loss: 1.5211 - val_acc: 0.5730\n",
      "Epoch 33/100\n",
      "0s - loss: 1.4363 - acc: 0.5890 - val_loss: 1.5351 - val_acc: 0.5683\n",
      "Epoch 34/100\n",
      "0s - loss: 1.4245 - acc: 0.5843 - val_loss: 1.5412 - val_acc: 0.5670\n",
      "Epoch 35/100\n",
      "0s - loss: 1.4311 - acc: 0.5809 - val_loss: 1.5053 - val_acc: 0.5793\n",
      "Epoch 36/100\n",
      "0s - loss: 1.4338 - acc: 0.5817 - val_loss: 1.5109 - val_acc: 0.5800\n",
      "Epoch 37/100\n",
      "0s - loss: 1.4166 - acc: 0.5893 - val_loss: 1.5241 - val_acc: 0.5750\n",
      "Epoch 38/100\n",
      "0s - loss: 1.4235 - acc: 0.5836 - val_loss: 1.5037 - val_acc: 0.5780\n",
      "Epoch 39/100\n",
      "0s - loss: 1.4074 - acc: 0.5917 - val_loss: 1.5105 - val_acc: 0.5800\n",
      "Epoch 40/100\n",
      "0s - loss: 1.4006 - acc: 0.5947 - val_loss: 1.5131 - val_acc: 0.5783\n",
      "Epoch 41/100\n",
      "0s - loss: 1.4018 - acc: 0.5921 - val_loss: 1.5198 - val_acc: 0.5763\n",
      "Epoch 42/100\n",
      "0s - loss: 1.3951 - acc: 0.5943 - val_loss: 1.4977 - val_acc: 0.5813\n",
      "Epoch 43/100\n",
      "0s - loss: 1.3921 - acc: 0.5971 - val_loss: 1.4965 - val_acc: 0.5863\n",
      "Epoch 44/100\n",
      "0s - loss: 1.3955 - acc: 0.5927 - val_loss: 1.4909 - val_acc: 0.5843\n",
      "Epoch 45/100\n",
      "0s - loss: 1.3809 - acc: 0.5957 - val_loss: 1.4978 - val_acc: 0.5820\n",
      "Epoch 46/100\n",
      "0s - loss: 1.3818 - acc: 0.5917 - val_loss: 1.4897 - val_acc: 0.5903\n",
      "Epoch 47/100\n",
      "1s - loss: 1.3701 - acc: 0.5937 - val_loss: 1.5173 - val_acc: 0.5760\n",
      "Epoch 48/100\n",
      "0s - loss: 1.3614 - acc: 0.5944 - val_loss: 1.5074 - val_acc: 0.5823\n",
      "Epoch 49/100\n",
      "0s - loss: 1.3704 - acc: 0.5984 - val_loss: 1.5107 - val_acc: 0.5817\n",
      "Epoch 50/100\n",
      "0s - loss: 1.3783 - acc: 0.5999 - val_loss: 1.4935 - val_acc: 0.5860\n",
      "Epoch 51/100\n",
      "0s - loss: 1.3530 - acc: 0.6056 - val_loss: 1.5132 - val_acc: 0.5793\n",
      "Epoch 52/100\n",
      "0s - loss: 1.3714 - acc: 0.5930 - val_loss: 1.4853 - val_acc: 0.5883\n",
      "Epoch 53/100\n",
      "0s - loss: 1.3640 - acc: 0.5987 - val_loss: 1.4997 - val_acc: 0.5850\n",
      "Epoch 54/100\n",
      "0s - loss: 1.3604 - acc: 0.5964 - val_loss: 1.5126 - val_acc: 0.5820\n",
      "Epoch 55/100\n",
      "0s - loss: 1.3503 - acc: 0.6040 - val_loss: 1.5120 - val_acc: 0.5773\n",
      "Epoch 56/100\n",
      "0s - loss: 1.3523 - acc: 0.6059 - val_loss: 1.5267 - val_acc: 0.5777\n",
      "Epoch 57/100\n",
      "0s - loss: 1.3525 - acc: 0.6007 - val_loss: 1.5142 - val_acc: 0.5737\n",
      "Epoch 58/100\n",
      "0s - loss: 1.3473 - acc: 0.6014 - val_loss: 1.4944 - val_acc: 0.5873\n",
      "Epoch 59/100\n",
      "0s - loss: 1.3259 - acc: 0.6107 - val_loss: 1.5035 - val_acc: 0.5893\n",
      "Epoch 60/100\n",
      "0s - loss: 1.3465 - acc: 0.5994 - val_loss: 1.5118 - val_acc: 0.5803\n",
      "Epoch 61/100\n",
      "0s - loss: 1.3354 - acc: 0.6074 - val_loss: 1.5268 - val_acc: 0.5760\n",
      "Epoch 62/100\n",
      "0s - loss: 1.3414 - acc: 0.6000 - val_loss: 1.4950 - val_acc: 0.5833\n",
      "Epoch 63/100\n",
      "0s - loss: 1.3336 - acc: 0.6094 - val_loss: 1.5093 - val_acc: 0.5853\n",
      "Epoch 64/100\n",
      "0s - loss: 1.3253 - acc: 0.6090 - val_loss: 1.5079 - val_acc: 0.5787\n",
      "Epoch 65/100\n",
      "0s - loss: 1.3305 - acc: 0.6071 - val_loss: 1.5115 - val_acc: 0.5783\n",
      "Epoch 66/100\n",
      "0s - loss: 1.3297 - acc: 0.6047 - val_loss: 1.4960 - val_acc: 0.5920\n",
      "Epoch 67/100\n",
      "0s - loss: 1.3138 - acc: 0.6159 - val_loss: 1.5264 - val_acc: 0.5820\n",
      "Epoch 68/100\n",
      "0s - loss: 1.3197 - acc: 0.6124 - val_loss: 1.5528 - val_acc: 0.5573\n",
      "Epoch 69/100\n",
      "0s - loss: 1.3251 - acc: 0.6110 - val_loss: 1.4878 - val_acc: 0.5893\n",
      "Epoch 70/100\n",
      "0s - loss: 1.3239 - acc: 0.6091 - val_loss: 1.5268 - val_acc: 0.5710\n",
      "Epoch 71/100\n",
      "0s - loss: 1.3154 - acc: 0.6096 - val_loss: 1.5037 - val_acc: 0.5830\n",
      "Epoch 72/100\n",
      "0s - loss: 1.3123 - acc: 0.6117 - val_loss: 1.4922 - val_acc: 0.5850\n",
      "Epoch 73/100\n",
      "0s - loss: 1.3217 - acc: 0.6079 - val_loss: 1.5418 - val_acc: 0.5673\n",
      "Epoch 74/100\n",
      "0s - loss: 1.3188 - acc: 0.6131 - val_loss: 1.5183 - val_acc: 0.5677\n",
      "Epoch 75/100\n",
      "0s - loss: 1.3114 - acc: 0.6121 - val_loss: 1.4928 - val_acc: 0.5920\n",
      "Epoch 76/100\n",
      "0s - loss: 1.3135 - acc: 0.6087 - val_loss: 1.5069 - val_acc: 0.5833\n",
      "Epoch 77/100\n",
      "0s - loss: 1.3030 - acc: 0.6133 - val_loss: 1.5143 - val_acc: 0.5803\n",
      "Epoch 78/100\n",
      "0s - loss: 1.3113 - acc: 0.6130 - val_loss: 1.5007 - val_acc: 0.5860\n",
      "Epoch 79/100\n",
      "0s - loss: 1.3096 - acc: 0.6139 - val_loss: 1.4949 - val_acc: 0.5847\n",
      "Epoch 80/100\n",
      "0s - loss: 1.2992 - acc: 0.6123 - val_loss: 1.4960 - val_acc: 0.5903\n",
      "Epoch 81/100\n",
      "0s - loss: 1.3000 - acc: 0.6101 - val_loss: 1.5184 - val_acc: 0.5727\n",
      "Epoch 82/100\n",
      "0s - loss: 1.2911 - acc: 0.6200 - val_loss: 1.5222 - val_acc: 0.5777\n",
      "Epoch 83/100\n",
      "0s - loss: 1.3045 - acc: 0.6043 - val_loss: 1.5245 - val_acc: 0.5797\n",
      "Epoch 84/100\n",
      "0s - loss: 1.3004 - acc: 0.6153 - val_loss: 1.5131 - val_acc: 0.5860\n",
      "Epoch 85/100\n",
      "0s - loss: 1.2900 - acc: 0.6203 - val_loss: 1.4997 - val_acc: 0.5917\n",
      "Epoch 86/100\n",
      "0s - loss: 1.2929 - acc: 0.6111 - val_loss: 1.4995 - val_acc: 0.5890\n",
      "Epoch 87/100\n",
      "0s - loss: 1.2876 - acc: 0.6161 - val_loss: 1.5144 - val_acc: 0.5860\n",
      "Epoch 88/100\n",
      "0s - loss: 1.2857 - acc: 0.6166 - val_loss: 1.5300 - val_acc: 0.5787\n",
      "Epoch 89/100\n",
      "0s - loss: 1.2852 - acc: 0.6173 - val_loss: 1.5049 - val_acc: 0.5820\n",
      "Epoch 90/100\n",
      "0s - loss: 1.2913 - acc: 0.6184 - val_loss: 1.5159 - val_acc: 0.5817\n",
      "Epoch 91/100\n",
      "0s - loss: 1.2869 - acc: 0.6177 - val_loss: 1.5020 - val_acc: 0.5903\n",
      "Epoch 92/100\n",
      "0s - loss: 1.2873 - acc: 0.6173 - val_loss: 1.5200 - val_acc: 0.5730\n",
      "Epoch 93/100\n",
      "0s - loss: 1.2797 - acc: 0.6159 - val_loss: 1.5273 - val_acc: 0.5857\n",
      "Epoch 94/100\n",
      "0s - loss: 1.2877 - acc: 0.6196 - val_loss: 1.4955 - val_acc: 0.5930\n",
      "Epoch 95/100\n",
      "0s - loss: 1.2841 - acc: 0.6219 - val_loss: 1.5359 - val_acc: 0.5683\n",
      "Epoch 96/100\n",
      "0s - loss: 1.2686 - acc: 0.6194 - val_loss: 1.5136 - val_acc: 0.5930\n",
      "Epoch 97/100\n",
      "0s - loss: 1.2768 - acc: 0.6214 - val_loss: 1.4957 - val_acc: 0.5933\n",
      "Epoch 98/100\n",
      "0s - loss: 1.2842 - acc: 0.6203 - val_loss: 1.5309 - val_acc: 0.5813\n",
      "Epoch 99/100\n",
      "0s - loss: 1.2671 - acc: 0.6231 - val_loss: 1.5351 - val_acc: 0.5817\n",
      "Epoch 100/100\n",
      "0s - loss: 1.2643 - acc: 0.6230 - val_loss: 1.5179 - val_acc: 0.5850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14376f90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe we could try with some nonlinear stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import keras.optimizers\n",
    "import keras.utils.np_utils\n",
    "\n",
    "def class2id(topics):\n",
    "    d={}\n",
    "    nums=[]\n",
    "    for t in topics:\n",
    "        nums.append(d.setdefault(t,len(d)))\n",
    "    return nums,d\n",
    "\n",
    "topic_numbers,class_dict=class2id(topics)\n",
    "topic_numbers_matrix=keras.utils.np_utils.to_categorical(topic_numbers)\n",
    "dim_in,dim_internal,dim_out=data_matrix.shape[1],200,len(class_dict)\n",
    "\n",
    "print dim_in, dim_internal,dim_out\n",
    "\n",
    "#Neural network:\n",
    "model = Sequential()\n",
    "#Non-linear layer #1\n",
    "model.add(Dense(dim_internal, input_dim=dim_in))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(dim_internal))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Linear projection at the end\n",
    "model.add(Dense(dim_out))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,class_mode='categorical')\n",
    "#Learn!\n",
    "model.fit(data_matrix[:10000],topic_numbers_matrix[:10000],verbose=2,batch_size=200,show_accuracy=True,validation_split=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2453/2453 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58622095393395846"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \n",
    "import sklearn.metrics\n",
    "\n",
    "sklearn.metrics.accuracy_score(topic_numbers[10000:],model.predict_classes(data_matrix[10000:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
