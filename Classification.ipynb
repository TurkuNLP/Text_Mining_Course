{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "In a nutshell (details will be explained during the lecture)\n",
    "\n",
    "- Assign input text into categories, either predefined (supervised) or not (unsupervised/clustering)\n",
    "  - Spam / not spam\n",
    "  - One of several topics\n",
    "  - Who is the author?\n",
    "  - ...\n",
    "- Done with machine learning\n",
    "  - We covered clustering last week, so now we look into **supervised** classification\n",
    "  - Main difference: unsupervised = no training data, supervised = training data\n",
    "- Training data:\n",
    "  - Ready examples of documents and their classes\n",
    "  - Learn the task from these examples\n",
    "  - Unsupervised = we don't know the classes, supervised = we know the classes\n",
    "- Training: text features + model induction algorithm -> model\n",
    "- Classification: text features + model -> predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "- Represent each document for the classifier\n",
    "- E.g.\n",
    "  - Bag of Words (BoW)\n",
    "  - Character N-Grams\n",
    "  - Document metadata\n",
    "  - PoS tags\n",
    "  - ...you name it, someone tried it...\n",
    "  \n",
    "Let's try on Suomi24 VRT data\n",
    "\n",
    "```\n",
    "<text discussionarea=\"Suhteet\" subsections=\"Sinkut\" title=\"Jos ATM hyppäisi benjihypyn\" views=\"0\" cid=\"unspecified\" anonnick=\"ätminkäinen\" comms=\"9\" year=\"2015\" date=\"12.05.2015\" dateto=\"20150512\" tid=\"13592337\" datefrom=\"20150512\" time=\"22:50\" sect=\"Suhteet\" subsect=\"Sinkut\" ssubsect=\"\" sssubsect=\"\" ssssubsect=\"\" sssssubsect=\"\" ssssssubsect=\"\" urlboard=\"http://keskustelu.suomi24.fi/t/13592337\" urlmsg=\"http://keskustelu.suomi24.fi/t/13592337\">\n",
    "<paragraph>\n",
    "<sentence>\n",
    "Niin    1       niin    Adv     CASECHANGE_Up   2       advmod\n",
    "parantaisiko    2       parantaa        V       PRS_Sg3|VOICE_Act|MOOD_Cond|CLIT_Qst    0       ROOT\n",
    "se      3       se      Pron    SUBCAT_Dem|NUM_Sg|CASE_Nom      2       nsubj\n",
    "hänen   4       hän     Pron    SUBCAT_Pers|NUM_Sg|CASE_Gen     5       poss\n",
    "markkina-arvoaan        5       markkina-arvo   N       NUM_Sg|CASE_Par|POSS_Px3        2       dobj\n",
    "naisten 6       nainen  N       NUM_Pl|CASE_Gen 7       poss\n",
    "silmissä        7       silmä   N       NUM_Pl|CASE_Ine 2       nommod\n",
    "?       8       ?       Punct   _       2       punct\n",
    "</sentence>\n",
    "</paragraph>\n",
    "</text>\n",
    "<text discussionarea=\"Suhteet\" subsections=\"Sinkut\" title=\"Jos ATM hyppäisi benjihypyn\" cid=\"79614512\" anonnick=\"NaisetOvatElukoita\" comms=\"9\" views=\"\" date=\"20.06.2015\" dateto=\"20150620\" year=\"2015\" tid=\"13592337\" datefrom=\"20150620\" time=\"20:34\" sect=\"Suhteet\" subsect=\"Sinkut\" ssubsect=\"\" sssubsect=\"\" ssssubsect=\"\" sssssubsect=\"\" ssssssubsect=\"\" urlboard=\"http://keskustelu.suomi24.fi/t/13592337\" urlmsg=\"http://keskustelu.suomi24.fi/t/13592337#comment-79614512\">\n",
    "<paragraph>\n",
    "<sentence>\n",
    "No      1       no      Interj  CASECHANGE_Up   3       intj\n",
    "jos     2       jos     Adv     _       3       advmod\n",
    "teet    3       tehdä   V       PRS_Sg2|VOICE_Act|TENSE_Prs|MOOD_Ind    0       ROOT\n",
    "sen     4       se      Pron    SUBCAT_Dem|NUM_Sg|CASE_Gen      5       poss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document count: 12453\n",
      "Distinct topics: Paikkakunnat, Tori, Koti ja rakentaminen, Työ ja opiskelu, Ajanviete, Nuoret, Ruoka ja juoma, MainPage, Suhteet, Lemmikit, Matkailu, Suomi24, Perhe, Ajoneuvot ja liikenne, Yhteiskunta, Tiede ja teknologia, Harrastukset, Viihde ja kulttuuri, Muoti ja kauneus, Ryhmät, Urheilu ja kuntoilu, Talous, Terveys\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import codecs\n",
    "txt_re=re.compile(ur'^<text discussionarea=\"(.*?)\".*tid=\"([0-9]+?)\"',re.U)\n",
    "ignore_re=re.compile(ur'^</?(text|sentence|paragraph)')\n",
    "\n",
    "\n",
    "def read_vrt(inp):\n",
    "    \"\"\"Function to read the Suomi24 VRT format\"\"\"\n",
    "    current_topic=None #topic name\n",
    "    current_tid=None #discussion thread number\n",
    "    words=[] #words in the discussion\n",
    "    for line in inp:\n",
    "        line=line.strip()\n",
    "        match=txt_re.match(line)\n",
    "        if match: #we have a new post\n",
    "            if match.group(2)!=current_tid and words:#...and it is not part of the current thread\n",
    "                yield current_topic, words\n",
    "                words=[]\n",
    "            current_topic=match.group(1) #Pick groups out of the regular expression\n",
    "            current_tid=match.group(2)\n",
    "        if ignore_re.match(line):\n",
    "            continue\n",
    "        columns=line.split(u\"\\t\")\n",
    "        if not columns[1].isdigit(): #there seem to be few broken ones, skip\n",
    "            continue\n",
    "        words.append(columns[2].lower())\n",
    "    else: #for loop ran out of items\n",
    "        if words:\n",
    "            yield current_topic, words\n",
    "\n",
    "topics=[] #list of strings\n",
    "texts=[] #list of strings\n",
    "with codecs.open(\"s24.vrt\",\"r\",\"utf-8\") as f:\n",
    "    for topic, words in read_vrt(f):\n",
    "        topics.append(topic)\n",
    "        texts.append(u\" \".join(words))\n",
    "\n",
    "print \"Document count:\", len(topics)\n",
    "print \"Distinct topics:\", u\", \".join(set(topics))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF.IDF weights\n",
    "\n",
    "$$ TF\\cdot\\frac{N}{DF} $$\n",
    "\n",
    "* TF - term frequency - count of term in current document\n",
    "* N - number of documents in the data\n",
    "* DF - number of documents with the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents x features (12453, 229764)\n",
      "feature matrix\n",
      "  (0, 227112)\t0.13654656756\n",
      "  (0, 227095)\t0.109876693955\n",
      "  (0, 226981)\t0.112921934495\n",
      "  (0, 223285)\t0.0671284409095\n",
      "  (0, 219663)\t0.0644993532335\n",
      "  (0, 218297)\t0.0261740937501\n",
      "  (0, 217821)\t0.0602237358203\n",
      "  (0, 215121)\t0.0799111500286\n",
      "  (0, 208541)\t0.0322894333732\n",
      "  (0, 208466)\t0.104748001507\n",
      "  (0, 203132)\t0.0731111585761\n",
      "  (0, 202008)\t0.0455023327263\n",
      "  (0, 200001)\t0.150731517533\n",
      "  (0, 199437)\t0.0306226943858\n",
      "  (0, 199156)\t0.0911279995445\n",
      "  (0, 198843)\t0.100900616753\n",
      "  (0, 198766)\t0.0270201961422\n",
      "  (0, 190661)\t0.0596916611611\n",
      "  (0, 187069)\t0.0299879590476\n",
      "  (0, 180836)\t0.0968389976216\n",
      "  (0, 176730)\t0.0316865123023\n",
      "  (0, 176630)\t0.0637229924694\n",
      "  (0, 175613)\t0.0543242115156\n",
      "  (0, 175480)\t0.112138936284\n",
      "  (0, 171781)\t0.0798338024262\n",
      "  :\t:\n",
      "  (12452, 51024)\t0.0471395227882\n",
      "  (12452, 49511)\t0.0523624941598\n",
      "  (12452, 47227)\t0.0938046288728\n",
      "  (12452, 39342)\t0.0198309929611\n",
      "  (12452, 38446)\t0.0428498935496\n",
      "  (12452, 36926)\t0.0342077174773\n",
      "  (12452, 35690)\t0.0402627124092\n",
      "  (12452, 33898)\t0.063963055679\n",
      "  (12452, 22045)\t0.221856562337\n",
      "  (12452, 22028)\t0.110637013986\n",
      "  (12452, 21767)\t0.0563268241309\n",
      "  (12452, 18529)\t0.0501545164628\n",
      "  (12452, 18505)\t0.0745904885567\n",
      "  (12452, 17933)\t0.0327734929389\n",
      "  (12452, 16719)\t0.0671784333884\n",
      "  (12452, 16541)\t0.0404879839675\n",
      "  (12452, 15929)\t0.059314092321\n",
      "  (12452, 15615)\t0.025171807376\n",
      "  (12452, 15520)\t0.0538450978686\n",
      "  (12452, 13416)\t0.0543064632033\n",
      "  (12452, 1439)\t0.163055672364\n",
      "  (12452, 1283)\t0.0283312901216\n",
      "  (12452, 1267)\t0.0325255517423\n",
      "  (12452, 1246)\t0.151895838882\n",
      "  (12452, 973)\t0.0452302655056\n",
      "features\n",
      "1 !\n",
      "5001 16:12\n",
      "10001 4770r-kone\n",
      "15001 aerosoli|pakkaus\n",
      "20001 ansaitsekkaan\n",
      "25001 bailu\n",
      "30001 counter\n",
      "35001 ellinooraaa\n",
      "40001 eu|ajo|kortti\n",
      "45001 grupperna\n",
      "50001 henkilö|tunniste\n",
      "55001 http://jukkawallin.puheenvuoro.uusisuomi.fi/197028-toistaako-historia-jalleen-itseaan\n",
      "60001 http://yle.fi/uutiset/kiihottavia_pornoloytoja_ei_juuri_somepaivityksissa_jaeta/7851960\n",
      "65001 hyysäämäään\n",
      "70001 inverkar\n",
      "75001 joukko|vaino\n",
      "80001 kaksois|kytkin\n",
      "85001 keksi\n",
      "90001 kissanraksua\n",
      "95001 koukero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2641: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_extraction\n",
    "\n",
    "def tokenizer(txt):\n",
    "    \"\"\"Simple whitespace tokenizer\"\"\"\n",
    "    return txt.split()\n",
    "\n",
    "#Extract the features\n",
    "tfidf_v=sklearn.feature_extraction.text.TfidfVectorizer(tokenizer=tokenizer) #,max_df=0.9\n",
    "d=tfidf_v.fit_transform(texts)\n",
    "print \"documents x features\", d.shape\n",
    "print \"feature matrix\"\n",
    "print d\n",
    "print \"features\"\n",
    "fnames=tfidf_v.get_feature_names()\n",
    "for feature_id in range(1,100000,5000):\n",
    "    print feature_id,fnames[feature_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "* Will be explained during the lecture, Google if you couldn't attend\n",
    "* Key concepts:\n",
    "  - Separating hyperplane\n",
    "  - Margin\n",
    "  - Errors and slack variables\n",
    "  - The parameter C\n",
    "  - Regularization\n",
    "  \n",
    "<img src=\"http://docs.opencv.org/2.4/_images/sample-errors-dist.png\"/>\n",
    "\n",
    "* Multiclass classification = number of classes > 2\n",
    "* One vs all = train a classifier for each class, pick the max score\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "* Will be explained during the lecture, Google key concepts if you couldn't attend\n",
    "* Key concepts:\n",
    "  - Accuracy, Precision, Recall, F-score\n",
    "  - Train / Development / Test Data\n",
    "  - Crossvalidation\n",
    "  - Overfitting\n",
    "  - Parameter optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.010  Accuracy=37.42%\n",
      "C=0.100  Accuracy=59.82%\n",
      "C=1.000  Accuracy=66.68%\n",
      "C=10.000  Accuracy=66.62%\n",
      "C=100.000  Accuracy=65.95%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.cross_validation\n",
    "X_train,X_test,Y_train,Y_test=sklearn.cross_validation.train_test_split(d, topics, test_size=0.3, random_state=0)\n",
    "\n",
    "for C in (0.01,0.1,1,10,100):\n",
    "    lin_clf = sklearn.svm.LinearSVC(C=C)\n",
    "    lin_clf.fit(X_train,Y_train)\n",
    "    print \"C=%.3f  Accuracy=%.2f%%\"%(C,lin_clf.score(X_test,Y_test)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...66% is not bad, keeping in mind we have 23 classes to choose from.\n",
    "\n",
    "# Random baseline\n",
    "\n",
    "* That we have 23 classes doesn't mean our baseline is 1/23!\n",
    "* Class imbalance\n",
    "* Accuracy susceptible to this!\n",
    "\n",
    "How do we fare compared to making random choices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier predicting most frequent class: 28.88%\n",
      "Dummy classifier predicting at random by class dist.: 13.01%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.dummy\n",
    "dummy=sklearn.dummy.DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train,Y_train)\n",
    "print \"Dummy classifier predicting most frequent class: %.2f%%\"%(dummy.score(X_test,Y_test)*100.0)\n",
    "dummy=sklearn.dummy.DummyClassifier(strategy=\"stratified\")\n",
    "dummy.fit(X_train,Y_train)\n",
    "print \"Dummy classifier predicting at random by class dist.: %.2f%%\"%(dummy.score(X_test,Y_test)*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if you predict the most frequent class, you get to 28% accuracy and with the simple SVM we get 66% accuracy. I.e we can safely say the classifier is learning something. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character n-grams\n",
    "\n",
    "* Quite popular choice\n",
    "* Does it work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents x features (12453, 229764)\n",
      "feature matrix\n",
      "  (0, 327495)\t0.0279364084575\n",
      "  (0, 327494)\t0.0246940006294\n",
      "  (0, 326082)\t0.0284459123917\n",
      "  (0, 326081)\t0.0195666672323\n",
      "  (0, 325561)\t0.0570182735877\n",
      "  (0, 325556)\t0.0397059026255\n",
      "  (0, 323870)\t0.0145962063742\n",
      "  (0, 323857)\t0.0141140700881\n",
      "  (0, 323698)\t0.0329225192112\n",
      "  (0, 323691)\t0.0325440317323\n",
      "  (0, 323579)\t0.013446493561\n",
      "  (0, 323569)\t0.00752836225688\n",
      "  (0, 323164)\t0.0143551104277\n",
      "  (0, 323159)\t0.0139049754487\n",
      "  (0, 322949)\t0.0260674398704\n",
      "  (0, 322948)\t0.0252456237298\n",
      "  (0, 322845)\t0.0755417813006\n",
      "  (0, 322843)\t0.0727451050801\n",
      "  (0, 322632)\t0.0144044808613\n",
      "  (0, 322621)\t0.0124514648769\n",
      "  (0, 322401)\t0.0172161118601\n",
      "  (0, 322400)\t0.0151691640639\n",
      "  (0, 322151)\t0.0413451316873\n",
      "  (0, 322141)\t0.0229695854203\n",
      "  (0, 321922)\t0.0415038550878\n",
      "  :\t:\n",
      "  (12452, 7121)\t0.012006175183\n",
      "  (12452, 7119)\t0.0228802062083\n",
      "  (12452, 7107)\t0.0191241708685\n",
      "  (12452, 7104)\t0.00912417192638\n",
      "  (12452, 7100)\t0.0192372220089\n",
      "  (12452, 7093)\t0.0294206477113\n",
      "  (12452, 6326)\t0.0169746067645\n",
      "  (12452, 6325)\t0.0132810244705\n",
      "  (12452, 6323)\t0.0135998608957\n",
      "  (12452, 6281)\t0.0216733813397\n",
      "  (12452, 1349)\t0.0633947077443\n",
      "  (12452, 1348)\t0.0606419300251\n",
      "  (12452, 1307)\t0.0101769197325\n",
      "  (12452, 1304)\t0.0127530473273\n",
      "  (12452, 1303)\t0.0182593358082\n",
      "  (12452, 1216)\t0.0191201747253\n",
      "  (12452, 1215)\t0.0154287139419\n",
      "  (12452, 1214)\t0.0241872736056\n",
      "  (12452, 1207)\t0.0239623912573\n",
      "  (12452, 1174)\t0.0168917636929\n",
      "  (12452, 1163)\t0.0550608416555\n",
      "  (12452, 899)\t0.00946902812298\n",
      "  (12452, 893)\t0.00828576678397\n",
      "  (12452, 881)\t0.0133338344521\n",
      "  (12452, 850)\t0.0174998320168\n",
      "features\n",
      "1 \u0005 ( \n",
      "5001  70e\n",
      "10001  hah\n",
      "15001  sil\n",
      "20001  ▪ h\n",
      "25001 *k1\n",
      "30001 -31_\n",
      "35001 -zi-\n",
      "40001 .vul\n",
      "45001 /non\n",
      "50001 05/\n",
      "55001 1093\n",
      "60001 1–45\n",
      "65001 2cb\n",
      "70001 39-\n",
      "75001 4844\n",
      "80001 564b\n",
      "85001 6767\n",
      "90001 7_r\n",
      "95001 8p v\n"
     ]
    }
   ],
   "source": [
    "tfidf_v_char=sklearn.feature_extraction.text.TfidfVectorizer(analyzer='char',ngram_range=(3,4)) #,max_df=0.9\n",
    "d_char=tfidf_v_char.fit_transform(texts)\n",
    "print \"documents x features\", d.shape\n",
    "print \"feature matrix\"\n",
    "print d_char\n",
    "print \"features\"\n",
    "fnames=tfidf_v_char.get_feature_names()\n",
    "for feature_id in range(1,100000,5000):\n",
    "    print feature_id,fnames[feature_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.010  Accuracy=43.98%\n",
      "C=0.100  Accuracy=63.30%\n",
      "C=1.000  Accuracy=68.55%\n"
     ]
    }
   ],
   "source": [
    "X_train_char,X_test_char,Y_train_char,Y_test_char=\\\n",
    "    sklearn.cross_validation.train_test_split(d_char, topics, test_size=0.3, random_state=0)\n",
    "\n",
    "for C in (0.01,0.1,1):\n",
    "    lin_clf_char = sklearn.svm.LinearSVC(C=C)\n",
    "    lin_clf_char.fit(X_train_char,Y_train_char)\n",
    "    print \"C=%.3f  Accuracy=%.2f%%\"%(C,lin_clf_char.score(X_test_char,Y_test_char)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forget about words and you'll get better numbers! Cool, eh? :)\n",
    "\n",
    "Does this generalize? Let's run on Finnish tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I gathered a bunch of totally random Finnish tweets, will my model work?\n",
    "import json\n",
    "\n",
    "tweets=[]\n",
    "with open(\"fin_tweets.json\",\"r\") as f:\n",
    "    for lineno,line in enumerate(f):\n",
    "        line=line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            tweet=json.loads(line)\n",
    "        except ValueError: #some of these are broken\n",
    "            continue\n",
    "        tweets.append(tweet[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(886, 336566)\n",
      "Yhteiskunta  ---  RT @zeekends: wcw babe ; isha asli sofia rye vanessa 👅\n",
      "Yhteiskunta  ---  DaanLuyten #TilItHappensToYou #BestMovieSong #iHeartAwards\n",
      "Yhteiskunta  ---  Mulla on kangasväriä farkuissa rip 😢😢 https://t.co/67iudMBfuj\n",
      "Yhteiskunta  ---  @MaayronFerreira IJAEJIOEJIOEAJOIEAJI\n",
      "Yhteiskunta  ---  #NowPlaying BFC-radio (@BFC_radio) https://t.co/xYZVlndWyG … #Erdioo\n",
      "Yhteiskunta  ---  omfg esQUEJ MEESTOYJ\n",
      "Yhteiskunta  ---  Meikä oli jo hetken pitkäperjantaissa. Ja nyt on vasta kiiraskeskiviikko. Päivät sekoo kun on näitä pyhiä.\n",
      "Yhteiskunta  ---  [22:59:10] 118.113.52.162:4384 &gt;&gt; :1433 (TCP:SYN)\n",
      "Työ ja opiskelu  ---  Oho tukkani on ekaa kertaa vuosiin mitassa jossa se alkaa aaltoilla ellen kampaa sitä suoraksi suihkun jälkeen. Hassua.\n",
      "Yhteiskunta  ---  #vibrator adulttoys #sextoys https://t.co/dk83khR6lo\n",
      "Yhteiskunta  ---  Tänään osui Hip Hop ja Rap YouTube Video Suomessa.「Cheek」's 『Kuka Muu Muka』 https://t.co/pQQ8kJTWiL\n",
      "Yhteiskunta  ---  [23:00:26] 125.123.234.198:2980 &gt;&gt; :1433 (TCP:SYN)\n",
      "Yhteiskunta  ---  #fucking adulttoys #vibrator https://t.co/fixAjHsUTT\n",
      "Viihde ja kulttuuri  ---  #Lowongan kerja Sales Finance Business Partner - Mondelēz International Jakarta https://t.co/VBxzdYnJCN #loker lowker\n",
      "Yhteiskunta  ---  Tykkäsin @YouTube-videosta, jonka teki @pixeldan https://t.co/IIJcOiWOpu Batman v Superman Massive Mystery Box Unboxing! - Lego,\n",
      "Yhteiskunta  ---  @nicolettching @Mdcarigaba @Espanto2001 zxcvbnm kyaaaah 😍😂\n",
      "Ajanviete  ---  Uva passa https://t.co/vbn2dUmGw1\n",
      "Yhteiskunta  ---  #fucking adulttoys #sextoys https://t.co/W2O7prQfli\n",
      "Yhteiskunta  ---  RT @imazlum: Dr. Itır Toksöz presenting us on Peace Studies, Syria and Refugees #wednesdaytalks @itirtoksoz @MURCIR https://t.co/VZem98vrwo\n",
      "Yhteiskunta  ---  #sextoys adulttoys #masturbating https://t.co/DDPzcocs8P\n",
      "Yhteiskunta  ---  #fucking adulttoys #analdildo https://t.co/59lnPa0FDF\n",
      "Paikkakunnat  ---  Suomessa henkilöstöjohtajat junnaavat yhä tehokkuudessa, kun muualla sitouttaminen on tärkeää\n",
      "https://t.co/TF0OSuLaGD\n",
      "Yhteiskunta  ---  Seiyū : Kanako Mitsuhashi (1999)\n",
      "Yhteiskunta  ---  RT @Partiokuuluu: Monikulttuurisen rekrytoinnin tärkein sana on tervetuloa! https://t.co/OsDf9IhaUG #partioscout #rasisminvastainenviikko #…\n",
      "Yhteiskunta  ---  TPS:n päävalmentaja Mika Laurikainen on nimennyt kokoonpanon illan FC Honka-TPS-otteluun #FCTPS #SuomenCup #Ykkönen https://t.co/hACuGsdWh2\n",
      "Yhteiskunta  ---  RT @KiipulaAO: Ajankohtainen julkaisu, ammattitaitomaajoukkueemme juuri kisojen kynnyksellä! #Abilympics #ammatillinenkoulutus https://t.co…\n",
      "Yhteiskunta  ---  @AjatustenVanki en oo vege. Kanasalaatti on hyvää x) enkä syö muutenkaan kuin kanahamppareita xD\n",
      "Yhteiskunta  ---  RT @prillvers_kudus: @Prillverskubdg_ amiin YRA\n",
      "#CantWaitAnnivPV5th\n",
      "Yhteiskunta  ---  RT @KouvolanSanomat: Suomen ensimmäinen Youtube -opintojakso Kaakkois-Suomen ammattikorkeakouluun — opettajina maan suosituimmat… https://t…\n",
      "Yhteiskunta  ---  Mikkeli: pahoinpitely Länsi-Savo 23.3.2016 15:54 18-vuotias nainen puukotti samanikäis.. #Mikkeli https://t.co/Op9cRbdPCd\n",
      "Yhteiskunta  ---  @kenekk0317 lhmtalrtjstytyftyudrstysryfyjdsfgudtgyhimfti,yhimjnfyundrtmdrtujndrtrdtmutymdrthnrtyndrturydtydhkgfyildtysrtsyssryisrys\n",
      "Yhteiskunta  ---  Kirjoitus antoi kuvan, että miehille keskivartalolihavuus on epäterveellistä, naisille \"ei kivan näköistä\". Yllättikö neg. palaute? @ksmlfi\n",
      "Yhteiskunta  ---  LIVE-lähetys #Periscope-sovelluksessa: jooo laulua niin o https://t.co/WXgGHgrAX3\n",
      "Yhteiskunta  ---  11:11 wigetta\n",
      "Yhteiskunta  ---  @JuusoQ Ranskanbulldoggi-mittelspitz, on söpö!\n",
      "Suhteet  ---  RT @Nduweybadass: Which Rihanna? Rihanna Rihanna or Rihanna Mkhwanazi https://t.co/XghUBGt007\n",
      "Yhteiskunta  ---  @BTS_twt jin~san kakkoi desu  ^^\n",
      "Yhteiskunta  ---  RT @MitasanSharp: MX-3070N / MX-3570N / MX-4070N (Phoenix)\n",
      " \n",
      "Gelişmiş CR4 teknolojisiyle Yeni Sharp renkli ürünleri… https://t.co/XwgZz32DY1\n",
      "Yhteiskunta  ---  RT @lehtinen_esa: Suomessa HR-johto keskittyy HR-järjestelmiin, muualla yrityskulttuurin vahvistamiseen ja ihmisten sitouttamiseen.https://…\n",
      "Yhteiskunta  ---  Ruuvi säve! Karjala kadulla Alppilassa. Mitä vaa ruuvei! Sheiiiiiiiit! #studio #construction #prolevel #törkeduni https://t.co/cyXIFSthbC\n",
      "Yhteiskunta  ---  @skewnger hello joo oppa!\n",
      "Yhteiskunta  ---  @TopiYrjl Ei varmasti. Ai että sitä paskamyrskyn määrää. :D\n",
      "Yhteiskunta  ---  RT @kskokoomus: @alexstubb vastaanottaa Saarijärven #kokoomuksen terveiset Harri Lehtiseltä ja Esa Järviseltä. https://t.co/5ir4WfTxjy\n",
      "Yhteiskunta  ---  huurhun shuu https://t.co/xyQU8fmtmM\n",
      "Yhteiskunta  ---  #sextoys adulttoys #cockring https://t.co/6Cgg1eiVMd\n",
      "Yhteiskunta  ---  @kuningaskulutta Olisi ollut turhauttavaa joutua siirtämään päivittäiset raha-asiat lainan vuoksi. Jotenkin tykkään, kun ovat erillään.\n",
      "Yhteiskunta  ---  RT @OutwardBoundFIN: Satavuotiaan Mallan luonnonpuiston uusi tunnus kunnioittaa alueen ainutlaatuista luontoa https://t.co/jT5YMi5VoB https…\n",
      "Yhteiskunta  ---  RT @GreenpeaceSuomi: Myös YK:n ihmisoikeusvaltuutettu liittyi metsähallituslain arvostelijoihin! #metsähallituslaki @UNHumanRights https://…\n",
      "Yhteiskunta  ---  Kuva: Meteoriitti syöksyi Mikkeliin – tulipallo näkyi satojen kilometrien päähän {iltasanomat} https://t.co/ML75s9Uvnx\n",
      "Yhteiskunta  ---  RT @catwomaine: slvsufudjbshuygxv https://t.co/aHkyyGFpSX\n",
      "Yhteiskunta  ---  ZXCVBNM\n"
     ]
    }
   ],
   "source": [
    "d_tweet_char=tfidf_v_char.transform(tweets)\n",
    "print d_tweet_char.shape\n",
    "for counter,(tweet, cls) in enumerate(zip(tweets,lin_clf_char.predict(d_tweet_char))):\n",
    "    print cls, \" --- \", tweet\n",
    "    if counter==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-O\n",
    "\n",
    "Oh good lord - twitter is such crap! [pulling hair 1AM the night before the lecture] Let's try to apply some of our newly acquired skills to recover. :| How about we try run the tweets through the parser and check the words against the top-most Finnish vocabulary and only keep tweets of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oho tukka olla eka kerta vuosi mitta joka se alkaa aaltoilla josei kammata se suora suihku jälkeen . hassu .\n",
      "@kuningaskulutta olla olla turhauttaa joutua siirtää päivittäinen raha-asia laina vuoksi . jotenkin tykätä , kun olla erillään .\n",
      "@maijalarmo tuoda Felix uusi korkki olla ihan ykkönen\n",
      "ei haluu liikkua , pitää mennä kauppa mut ulkona sata lumi ja mä olla ruokakooma päällä ugh\n",
      "@BornForFiNRS mä ei ärsyttää vielä koska vetää just pussi fanipaloi ja nyt sattua maha lol\n",
      "@RenneKorppila vai sellanen kaveri . mä ei toisaalta mikään ihme ettäei olla koskaan kuulla ko . tyyppi .\n",
      "@Kinukki sanoma olla selvä , että ei uskoa olla väärä kun arvella sinä kertoa tämä itse ,olethan aikuinen ..\n",
      "@Nysses ei . olla ilo huomata että minä @jysk_fi tämä tapahtua päivittäin ja asiakaspalvelu olla kunnia-asia .\n",
      "paitsi ain olla kiva nähä ämmii tappelees mut veikka tämä menoo vappun sata lumi\n",
      "RT @SaaraHuttunen : mä haluta olla terve ja onnellinen . muu prioriteetti mä ei nyt olla . toki koulu ois kiva joskus valmistua\n"
     ]
    }
   ],
   "source": [
    "import lwvlib\n",
    "wv=lwvlib.load(\"pb34_lemma_200_v2.bin\",70000,70000)\n",
    "\n",
    "def read_conllu(inp):\n",
    "    tweet=[] #list of lemmas\n",
    "    for line in inp:\n",
    "        line=line.strip().replace(u\"#\",u\"\")\n",
    "        if not line:\n",
    "            yield tweet\n",
    "            tweet=[]\n",
    "        else:\n",
    "            tweet.append(line.split(u\"\\t\")[2])\n",
    "            \n",
    "import re\n",
    "wrdre=re.compile(u\"^[a-zäöå-]+$\")\n",
    "def known_words(tweet):\n",
    "    return sum(1 for word in tweet if word in wv.words and wrdre.match(word))\n",
    "\n",
    "tweets=[]\n",
    "with codecs.open(\"fin_tweets.conllu\",\"r\",\"utf-8\") as f:\n",
    "    for tweet in read_conllu(f):\n",
    "        if float(known_words(tweet))/len(tweet)>0.7:\n",
    "            tweets.append(u\" \".join(tweet).replace(u\"#\",u\"|\"))\n",
    "for t in tweets[:10]:\n",
    "    print t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 336566)\n",
      "Koti ja rakentaminen  ---  oho tukka olla eka kerta vuosi mitta joka se alkaa aaltoilla josei kammata se suora suihku jälkeen . hassu .\n",
      "\n",
      "Yhteiskunta  ---  @kuningaskulutta olla olla turhauttaa joutua siirtää päivittäinen raha-asia laina vuoksi . jotenkin tykätä , kun olla erillään .\n",
      "\n",
      "Paikkakunnat  ---  @maijalarmo tuoda Felix uusi korkki olla ihan ykkönen\n",
      "\n",
      "Suhteet  ---  ei haluu liikkua , pitää mennä kauppa mut ulkona sata lumi ja mä olla ruokakooma päällä ugh\n",
      "\n",
      "Suhteet  ---  @BornForFiNRS mä ei ärsyttää vielä koska vetää just pussi fanipaloi ja nyt sattua maha lol\n",
      "\n",
      "Yhteiskunta  ---  @RenneKorppila vai sellanen kaveri . mä ei toisaalta mikään ihme ettäei olla koskaan kuulla ko . tyyppi .\n",
      "\n",
      "Suhteet  ---  @Kinukki sanoma olla selvä , että ei uskoa olla väärä kun arvella sinä kertoa tämä itse ,olethan aikuinen ..\n",
      "\n",
      "Yhteiskunta  ---  @Nysses ei . olla ilo huomata että minä @jysk_fi tämä tapahtua päivittäin ja asiakaspalvelu olla kunnia-asia .\n",
      "\n",
      "Yhteiskunta  ---  paitsi ain olla kiva nähä ämmii tappelees mut veikka tämä menoo vappun sata lumi\n",
      "\n",
      "Nuoret  ---  RT @SaaraHuttunen : mä haluta olla terve ja onnellinen . muu prioriteetti mä ei nyt olla . toki koulu ois kiva joskus valmistua\n",
      "\n",
      "Yhteiskunta  ---  @gynsy @MikiHoijer tarkistaa vielä , että kuusi se pitää alkaa . kerta olla kyttä enemmän kuin osallistuja .\n",
      "\n",
      "Paikkakunnat  ---  Nonii , nyt paikka vähän enemmän täynnä . hämärästi täyttyä tää näin pienes ajaa\n",
      "\n",
      "Yhteiskunta  ---  @MaipuMaire @Mallas6 hyvä niin . saaristo se häijy kaveri joka levittää häijy tauti .\n",
      "\n",
      "Urheilu ja kuntoilu  ---  ja niin se olla , että kova treeni jo itsessään olla stressi ja viedä energia palautua ja henkinen stressi vielä . hyötykäyttö siis !\n",
      "\n",
      "Lemmikit  ---  @maailmanvaltias enkkuu ! jos lykky siis käydä ja päästä ... suunta ehkä opettaja mut ei sulkea muu vaihtoehtoi pois jos mieli muuttua !\n",
      "\n",
      "Yhteiskunta  ---  @ManninenJoonas katsottavahko ? varmaan se vaihe kun ei enää pysyä hereillä tai muuten keskittyä elokuva mitenkään\n",
      "\n",
      "Paikkakunnat  ---  @yleuutiset ei olla kun merkki mikä viitata suomalainen astia teollisuus . tämmöinen joskus tehdä suomi\n",
      "\n",
      "Työ ja opiskelu  ---  @emohilkka mä voida myös kirjoa ka essee ennen ku syke alkaa\n",
      "\n",
      "Yhteiskunta  ---  @Mirppu @Elmatule ei se toi aika pian loppua . vartija viimeistään puhaltaa peli poikki .\n",
      "\n",
      "Suhteet  ---  psykologia olla niin mielenkiintosta tykätä\n",
      "\n",
      "Yhteiskunta  ---  @BLAKKIIIIISSSSS jos suoraan sanoa , olla säälittävä jos ruveta tubettajaksi vain raha ja maine takia . Tubenomithautaan\n",
      "\n",
      "Suhteet  ---  ei juuri kuunnella david bowien musa mut tälleen pinnallisesti voida sanoa että olla se kyllä perkele kaunis äijä\n",
      "\n",
      "Yhteiskunta  ---  kuka helvetti tuoda tänne kämppä suklaa ? terve possu .\n",
      "\n",
      "Yhteiskunta  ---  olla melko varma , että joku mä naapuri ulkoiluttaa kissa , kun tulla työ koti . hämmentyä . ulkona olla pakkanen .\n",
      "\n",
      "Paikkakunnat  ---  nonii nyt olla eve aino ja elina tehdä jo konsepti kai se itekki piakkoin voida tietää että se kyllä ärsyttää moni anteeksi etukäteen : )\n",
      "\n",
      "Yhteiskunta  ---  @heikki_hakala olla edelleen hämi ja kummi Moskova matka tulos . että mikä se oikein olla siis .\n",
      "\n",
      "Paikkakunnat  ---  @wwimpula voida vaan alkaa hoitaa omia asioida puhelin tolleen 😂? ?\n",
      "\n",
      "Paikkakunnat  ---  se olla se vaihe menettää tapaus ku pizzeria osata tilaus ..\n",
      "\n",
      "Suhteet  ---  @montuttaja @mitavittualehti nyt olla viedä valkoinen itseinho ihan uusi taso WhiteGenocideIsReal\n",
      "\n",
      "Urheilu ja kuntoilu  ---  @LottaEmpi mä salisuunnitelma mennä muu suunnitelma kanssa ketju plörinä , huomenna treeni taas sali !\n",
      "\n",
      "Paikkakunnat  ---  tää olla sellanen cannot unsee tilanne itq\n",
      "\n",
      "Yhteiskunta  ---  onneksi olla internet ja urpoja joka purkaa oma vitutus .\n",
      "\n",
      "Yhteiskunta  ---  olla tuo syke vaan niin mukiinmenevä sarja näin keskiviikkoilta 👌\n",
      "\n",
      "Suhteet  ---  @dragmenialI äiti ja iskä mä elää olla niin ihana\n",
      "\n",
      "Suhteet  ---  nyt kun olla täysikänen ni mut pistää aina maistella alkoholijuomii . tänään testi vadelmaskumppa - kaikki nauro ku irvistellä vaan :(\n",
      "\n",
      "Paikkakunnat  ---  voida kyl olla ei ite jännittää enemmän ku poikkis mut olla se iso juttu esittäytyä koko suku ! etenkin ku olla muuttamas yhteen ihan pian\n",
      "\n",
      "Yhteiskunta  ---  tää TIsuomi olla pitää tulla lääppijä kohu aika . 😃 se olla olla helvetti irti\n",
      "\n",
      "Yhteiskunta  ---  halu toi nyt pelkästää jo esteettinen syy , herra varjella\n",
      "\n",
      "Yhteiskunta  ---  @maaaw joku vanki olla varmaan taas unohtua palata loma\n",
      "\n",
      "Paikkakunnat  ---  @dragmenialI sä olla ja kato nyt tota täydellinen konsepti\n",
      "\n",
      "Yhteiskunta  ---  @suski_kaukinen @laurahaimila tuo olla hölmö jopa sinä näppäimistö . rasismi tämä ketju olla kaikki puoli\n",
      "\n",
      "Yhteiskunta  ---  hetki ihmetellä ettäei yksikään ottelu olla mennä vielä jatkorei 'ille , mut tää uusi formaatti mukaan voida päättyä tasan . Njäh..\n",
      "\n",
      "Yhteiskunta  ---  vaarallinen\n",
      "\n",
      "Suhteet  ---  ai vittu . tajuta just ei mä ei voida jatkaa ku tajuta saattaa spoilaa . sori .\n",
      "\n",
      "Viihde ja kulttuuri  ---  pitkä kausi takana . upea hetki ja myös pieni pettymys tunne . tämä kaivaa voima ja palata vahva ensi kausi ! Ketterä\n",
      "\n",
      "Suhteet  ---  tai no , ymmärtää jos se olla kuva joka viedä koko aukeama ... mutta kuitenkin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_tweet_char=tfidf_v_char.transform(tweets)\n",
    "print d_tweet_char.shape\n",
    "for counter,(tweet, cls) in enumerate(zip(tweets,lin_clf_char.predict(d_tweet_char))):\n",
    "    print cls, \" --- \", tweet\n",
    "    print\n",
    "    if counter==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And how about the vectors, do they help any?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.10225586,  0.08287574,  0.04128639, ...,  0.01366414,\n",
       "         0.14373324,  0.17274647],\n",
       "       [-0.05364433, -0.01276515,  0.0603284 , ...,  0.00620707,\n",
       "         0.19762445,  0.13600904],\n",
       "       [-0.06920946,  0.01818488,  0.03807921, ...,  0.02176174,\n",
       "         0.13039736,  0.17019013],\n",
       "       ..., \n",
       "       [-0.07167699,  0.06385985,  0.05177857, ..., -0.00953654,\n",
       "         0.17387475,  0.13991461],\n",
       "       [-0.06337436,  0.04784775,  0.04624651, ...,  0.03932344,\n",
       "         0.09021433,  0.12855842],\n",
       "       [-0.10096667,  0.06961406,  0.01622496, ..., -0.01524248,\n",
       "         0.14144494,  0.164709  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lwvlib\n",
    "import numpy\n",
    "wv=lwvlib.load(\"pb34_lemma_200_v2.bin\",50000,50000)\n",
    "\n",
    "def doc2vec(txt,wv,i,data_matrix):\n",
    "    \"\"\"Text with whitespace tokenization\n",
    "    wv\n",
    "    i - which row are we filling\n",
    "    data_matrix - and to where?\"\"\"\n",
    "    for w in txt.split():\n",
    "        w=w.lower()\n",
    "        dim=wv.get(w)\n",
    "        if dim==None:\n",
    "            continue\n",
    "        data_matrix[i]+=wv.vectors[dim]\n",
    "\n",
    "#topics,texts\n",
    "data_matrix=numpy.zeros((len(texts),wv.vectors.shape[1]))\n",
    "for i,txt in enumerate(texts):\n",
    "    doc2vec(txt,wv,i,data_matrix)\n",
    "sklearn.preprocessing.normalize(data_matrix,copy=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls=sklearn.svm.LinearSVC(C=1.0)\n",
    "cls.fit(data_matrix[:10000],topics[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59315124337545866"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.score(data_matrix[10000:],topics[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:34: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 23\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "0s - loss: 2.6129 - acc: 0.2510 - val_loss: 2.3120 - val_acc: 0.3457\n",
      "Epoch 2/100\n",
      "0s - loss: 2.3415 - acc: 0.3149 - val_loss: 2.1417 - val_acc: 0.3963\n",
      "Epoch 3/100\n",
      "0s - loss: 2.2013 - acc: 0.3466 - val_loss: 2.0366 - val_acc: 0.4387\n",
      "Epoch 4/100\n",
      "0s - loss: 2.0875 - acc: 0.3940 - val_loss: 1.9314 - val_acc: 0.4633\n",
      "Epoch 5/100\n",
      "0s - loss: 1.9935 - acc: 0.4280 - val_loss: 1.8639 - val_acc: 0.4880\n",
      "Epoch 6/100\n",
      "0s - loss: 1.9230 - acc: 0.4533 - val_loss: 1.8401 - val_acc: 0.4793\n",
      "Epoch 7/100\n",
      "1s - loss: 1.8661 - acc: 0.4650 - val_loss: 1.7977 - val_acc: 0.4993\n",
      "Epoch 8/100\n",
      "0s - loss: 1.8140 - acc: 0.4759 - val_loss: 1.7457 - val_acc: 0.5007\n",
      "Epoch 9/100\n",
      "1s - loss: 1.7796 - acc: 0.4880 - val_loss: 1.7327 - val_acc: 0.5083\n",
      "Epoch 10/100\n",
      "1s - loss: 1.7398 - acc: 0.4964 - val_loss: 1.6941 - val_acc: 0.5173\n",
      "Epoch 11/100\n",
      "0s - loss: 1.7191 - acc: 0.5017 - val_loss: 1.7063 - val_acc: 0.5160\n",
      "Epoch 12/100\n",
      "0s - loss: 1.7055 - acc: 0.5049 - val_loss: 1.6559 - val_acc: 0.5253\n",
      "Epoch 13/100\n",
      "0s - loss: 1.6659 - acc: 0.5131 - val_loss: 1.6372 - val_acc: 0.5297\n",
      "Epoch 14/100\n",
      "0s - loss: 1.6457 - acc: 0.5190 - val_loss: 1.6180 - val_acc: 0.5417\n",
      "Epoch 15/100\n",
      "1s - loss: 1.6239 - acc: 0.5279 - val_loss: 1.6176 - val_acc: 0.5430\n",
      "Epoch 16/100\n",
      "0s - loss: 1.6152 - acc: 0.5306 - val_loss: 1.6246 - val_acc: 0.5350\n",
      "Epoch 17/100\n",
      "0s - loss: 1.5962 - acc: 0.5377 - val_loss: 1.6113 - val_acc: 0.5527\n",
      "Epoch 18/100\n",
      "0s - loss: 1.5836 - acc: 0.5441 - val_loss: 1.5843 - val_acc: 0.5473\n",
      "Epoch 19/100\n",
      "0s - loss: 1.5668 - acc: 0.5463 - val_loss: 1.6136 - val_acc: 0.5357\n",
      "Epoch 20/100\n",
      "0s - loss: 1.5509 - acc: 0.5487 - val_loss: 1.5529 - val_acc: 0.5610\n",
      "Epoch 21/100\n",
      "0s - loss: 1.5444 - acc: 0.5500 - val_loss: 1.5548 - val_acc: 0.5637\n",
      "Epoch 22/100\n",
      "0s - loss: 1.5230 - acc: 0.5573 - val_loss: 1.5401 - val_acc: 0.5650\n",
      "Epoch 23/100\n",
      "0s - loss: 1.5199 - acc: 0.5566 - val_loss: 1.5399 - val_acc: 0.5677\n",
      "Epoch 24/100\n",
      "0s - loss: 1.5040 - acc: 0.5600 - val_loss: 1.5418 - val_acc: 0.5670\n",
      "Epoch 25/100\n",
      "1s - loss: 1.4990 - acc: 0.5650 - val_loss: 1.5400 - val_acc: 0.5663\n",
      "Epoch 26/100\n",
      "0s - loss: 1.4863 - acc: 0.5644 - val_loss: 1.5799 - val_acc: 0.5650\n",
      "Epoch 27/100\n",
      "0s - loss: 1.4825 - acc: 0.5757 - val_loss: 1.5298 - val_acc: 0.5747\n",
      "Epoch 28/100\n",
      "0s - loss: 1.4687 - acc: 0.5699 - val_loss: 1.5570 - val_acc: 0.5633\n",
      "Epoch 29/100\n",
      "0s - loss: 1.4687 - acc: 0.5687 - val_loss: 1.5111 - val_acc: 0.5773\n",
      "Epoch 30/100\n",
      "0s - loss: 1.4544 - acc: 0.5791 - val_loss: 1.5511 - val_acc: 0.5573\n",
      "Epoch 31/100\n",
      "0s - loss: 1.4565 - acc: 0.5770 - val_loss: 1.5242 - val_acc: 0.5763\n",
      "Epoch 32/100\n",
      "0s - loss: 1.4483 - acc: 0.5826 - val_loss: 1.5211 - val_acc: 0.5730\n",
      "Epoch 33/100\n",
      "0s - loss: 1.4363 - acc: 0.5890 - val_loss: 1.5351 - val_acc: 0.5683\n",
      "Epoch 34/100\n",
      "0s - loss: 1.4245 - acc: 0.5843 - val_loss: 1.5412 - val_acc: 0.5670\n",
      "Epoch 35/100\n",
      "0s - loss: 1.4311 - acc: 0.5809 - val_loss: 1.5053 - val_acc: 0.5793\n",
      "Epoch 36/100\n",
      "0s - loss: 1.4338 - acc: 0.5817 - val_loss: 1.5109 - val_acc: 0.5800\n",
      "Epoch 37/100\n",
      "0s - loss: 1.4166 - acc: 0.5893 - val_loss: 1.5241 - val_acc: 0.5750\n",
      "Epoch 38/100\n",
      "0s - loss: 1.4235 - acc: 0.5836 - val_loss: 1.5037 - val_acc: 0.5780\n",
      "Epoch 39/100\n",
      "0s - loss: 1.4074 - acc: 0.5917 - val_loss: 1.5105 - val_acc: 0.5800\n",
      "Epoch 40/100\n",
      "0s - loss: 1.4006 - acc: 0.5947 - val_loss: 1.5131 - val_acc: 0.5783\n",
      "Epoch 41/100\n",
      "0s - loss: 1.4018 - acc: 0.5921 - val_loss: 1.5198 - val_acc: 0.5763\n",
      "Epoch 42/100\n",
      "0s - loss: 1.3951 - acc: 0.5943 - val_loss: 1.4977 - val_acc: 0.5813\n",
      "Epoch 43/100\n",
      "0s - loss: 1.3921 - acc: 0.5971 - val_loss: 1.4965 - val_acc: 0.5863\n",
      "Epoch 44/100\n",
      "0s - loss: 1.3955 - acc: 0.5927 - val_loss: 1.4909 - val_acc: 0.5843\n",
      "Epoch 45/100\n",
      "0s - loss: 1.3809 - acc: 0.5957 - val_loss: 1.4978 - val_acc: 0.5820\n",
      "Epoch 46/100\n",
      "0s - loss: 1.3818 - acc: 0.5917 - val_loss: 1.4897 - val_acc: 0.5903\n",
      "Epoch 47/100\n",
      "1s - loss: 1.3701 - acc: 0.5937 - val_loss: 1.5173 - val_acc: 0.5760\n",
      "Epoch 48/100\n",
      "0s - loss: 1.3614 - acc: 0.5944 - val_loss: 1.5074 - val_acc: 0.5823\n",
      "Epoch 49/100\n",
      "0s - loss: 1.3704 - acc: 0.5984 - val_loss: 1.5107 - val_acc: 0.5817\n",
      "Epoch 50/100\n",
      "0s - loss: 1.3783 - acc: 0.5999 - val_loss: 1.4935 - val_acc: 0.5860\n",
      "Epoch 51/100\n",
      "0s - loss: 1.3530 - acc: 0.6056 - val_loss: 1.5132 - val_acc: 0.5793\n",
      "Epoch 52/100\n",
      "0s - loss: 1.3714 - acc: 0.5930 - val_loss: 1.4853 - val_acc: 0.5883\n",
      "Epoch 53/100\n",
      "0s - loss: 1.3640 - acc: 0.5987 - val_loss: 1.4997 - val_acc: 0.5850\n",
      "Epoch 54/100\n",
      "0s - loss: 1.3604 - acc: 0.5964 - val_loss: 1.5126 - val_acc: 0.5820\n",
      "Epoch 55/100\n",
      "0s - loss: 1.3503 - acc: 0.6040 - val_loss: 1.5120 - val_acc: 0.5773\n",
      "Epoch 56/100\n",
      "0s - loss: 1.3523 - acc: 0.6059 - val_loss: 1.5267 - val_acc: 0.5777\n",
      "Epoch 57/100\n",
      "0s - loss: 1.3525 - acc: 0.6007 - val_loss: 1.5142 - val_acc: 0.5737\n",
      "Epoch 58/100\n",
      "0s - loss: 1.3473 - acc: 0.6014 - val_loss: 1.4944 - val_acc: 0.5873\n",
      "Epoch 59/100\n",
      "0s - loss: 1.3259 - acc: 0.6107 - val_loss: 1.5035 - val_acc: 0.5893\n",
      "Epoch 60/100\n",
      "0s - loss: 1.3465 - acc: 0.5994 - val_loss: 1.5118 - val_acc: 0.5803\n",
      "Epoch 61/100\n",
      "0s - loss: 1.3354 - acc: 0.6074 - val_loss: 1.5268 - val_acc: 0.5760\n",
      "Epoch 62/100\n",
      "0s - loss: 1.3414 - acc: 0.6000 - val_loss: 1.4950 - val_acc: 0.5833\n",
      "Epoch 63/100\n",
      "0s - loss: 1.3336 - acc: 0.6094 - val_loss: 1.5093 - val_acc: 0.5853\n",
      "Epoch 64/100\n",
      "0s - loss: 1.3253 - acc: 0.6090 - val_loss: 1.5079 - val_acc: 0.5787\n",
      "Epoch 65/100\n",
      "0s - loss: 1.3305 - acc: 0.6071 - val_loss: 1.5115 - val_acc: 0.5783\n",
      "Epoch 66/100\n",
      "0s - loss: 1.3297 - acc: 0.6047 - val_loss: 1.4960 - val_acc: 0.5920\n",
      "Epoch 67/100\n",
      "0s - loss: 1.3138 - acc: 0.6159 - val_loss: 1.5264 - val_acc: 0.5820\n",
      "Epoch 68/100\n",
      "0s - loss: 1.3197 - acc: 0.6124 - val_loss: 1.5528 - val_acc: 0.5573\n",
      "Epoch 69/100\n",
      "0s - loss: 1.3251 - acc: 0.6110 - val_loss: 1.4878 - val_acc: 0.5893\n",
      "Epoch 70/100\n",
      "0s - loss: 1.3239 - acc: 0.6091 - val_loss: 1.5268 - val_acc: 0.5710\n",
      "Epoch 71/100\n",
      "0s - loss: 1.3154 - acc: 0.6096 - val_loss: 1.5037 - val_acc: 0.5830\n",
      "Epoch 72/100\n",
      "0s - loss: 1.3123 - acc: 0.6117 - val_loss: 1.4922 - val_acc: 0.5850\n",
      "Epoch 73/100\n",
      "0s - loss: 1.3217 - acc: 0.6079 - val_loss: 1.5418 - val_acc: 0.5673\n",
      "Epoch 74/100\n",
      "0s - loss: 1.3188 - acc: 0.6131 - val_loss: 1.5183 - val_acc: 0.5677\n",
      "Epoch 75/100\n",
      "0s - loss: 1.3114 - acc: 0.6121 - val_loss: 1.4928 - val_acc: 0.5920\n",
      "Epoch 76/100\n",
      "0s - loss: 1.3135 - acc: 0.6087 - val_loss: 1.5069 - val_acc: 0.5833\n",
      "Epoch 77/100\n",
      "0s - loss: 1.3030 - acc: 0.6133 - val_loss: 1.5143 - val_acc: 0.5803\n",
      "Epoch 78/100\n",
      "0s - loss: 1.3113 - acc: 0.6130 - val_loss: 1.5007 - val_acc: 0.5860\n",
      "Epoch 79/100\n",
      "0s - loss: 1.3096 - acc: 0.6139 - val_loss: 1.4949 - val_acc: 0.5847\n",
      "Epoch 80/100\n",
      "0s - loss: 1.2992 - acc: 0.6123 - val_loss: 1.4960 - val_acc: 0.5903\n",
      "Epoch 81/100\n",
      "0s - loss: 1.3000 - acc: 0.6101 - val_loss: 1.5184 - val_acc: 0.5727\n",
      "Epoch 82/100\n",
      "0s - loss: 1.2911 - acc: 0.6200 - val_loss: 1.5222 - val_acc: 0.5777\n",
      "Epoch 83/100\n",
      "0s - loss: 1.3045 - acc: 0.6043 - val_loss: 1.5245 - val_acc: 0.5797\n",
      "Epoch 84/100\n",
      "0s - loss: 1.3004 - acc: 0.6153 - val_loss: 1.5131 - val_acc: 0.5860\n",
      "Epoch 85/100\n",
      "0s - loss: 1.2900 - acc: 0.6203 - val_loss: 1.4997 - val_acc: 0.5917\n",
      "Epoch 86/100\n",
      "0s - loss: 1.2929 - acc: 0.6111 - val_loss: 1.4995 - val_acc: 0.5890\n",
      "Epoch 87/100\n",
      "0s - loss: 1.2876 - acc: 0.6161 - val_loss: 1.5144 - val_acc: 0.5860\n",
      "Epoch 88/100\n",
      "0s - loss: 1.2857 - acc: 0.6166 - val_loss: 1.5300 - val_acc: 0.5787\n",
      "Epoch 89/100\n",
      "0s - loss: 1.2852 - acc: 0.6173 - val_loss: 1.5049 - val_acc: 0.5820\n",
      "Epoch 90/100\n",
      "0s - loss: 1.2913 - acc: 0.6184 - val_loss: 1.5159 - val_acc: 0.5817\n",
      "Epoch 91/100\n",
      "0s - loss: 1.2869 - acc: 0.6177 - val_loss: 1.5020 - val_acc: 0.5903\n",
      "Epoch 92/100\n",
      "0s - loss: 1.2873 - acc: 0.6173 - val_loss: 1.5200 - val_acc: 0.5730\n",
      "Epoch 93/100\n",
      "0s - loss: 1.2797 - acc: 0.6159 - val_loss: 1.5273 - val_acc: 0.5857\n",
      "Epoch 94/100\n",
      "0s - loss: 1.2877 - acc: 0.6196 - val_loss: 1.4955 - val_acc: 0.5930\n",
      "Epoch 95/100\n",
      "0s - loss: 1.2841 - acc: 0.6219 - val_loss: 1.5359 - val_acc: 0.5683\n",
      "Epoch 96/100\n",
      "0s - loss: 1.2686 - acc: 0.6194 - val_loss: 1.5136 - val_acc: 0.5930\n",
      "Epoch 97/100\n",
      "0s - loss: 1.2768 - acc: 0.6214 - val_loss: 1.4957 - val_acc: 0.5933\n",
      "Epoch 98/100\n",
      "0s - loss: 1.2842 - acc: 0.6203 - val_loss: 1.5309 - val_acc: 0.5813\n",
      "Epoch 99/100\n",
      "0s - loss: 1.2671 - acc: 0.6231 - val_loss: 1.5351 - val_acc: 0.5817\n",
      "Epoch 100/100\n",
      "0s - loss: 1.2643 - acc: 0.6230 - val_loss: 1.5179 - val_acc: 0.5850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14376f90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe we could try with some nonlinear stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import keras.optimizers\n",
    "import keras.utils.np_utils\n",
    "\n",
    "def class2id(topics):\n",
    "    d={}\n",
    "    nums=[]\n",
    "    for t in topics:\n",
    "        nums.append(d.setdefault(t,len(d)))\n",
    "    return nums,d\n",
    "\n",
    "topic_numbers,class_dict=class2id(topics)\n",
    "topic_numbers_matrix=keras.utils.np_utils.to_categorical(topic_numbers)\n",
    "dim_in,dim_internal,dim_out=data_matrix.shape[1],200,len(class_dict)\n",
    "\n",
    "print dim_in, dim_internal,dim_out\n",
    "\n",
    "#Neural network:\n",
    "model = Sequential()\n",
    "#Non-linear layer #1\n",
    "model.add(Dense(dim_internal, input_dim=dim_in))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(dim_internal))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Linear projection at the end\n",
    "model.add(Dense(dim_out))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,class_mode='categorical')\n",
    "#Learn!\n",
    "model.fit(data_matrix[:10000],topic_numbers_matrix[:10000],verbose=2,batch_size=200,show_accuracy=True,validation_split=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2453/2453 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58622095393395846"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \n",
    "import sklearn.metrics\n",
    "\n",
    "sklearn.metrics.accuracy_score(topic_numbers[10000:],model.predict_classes(data_matrix[10000:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
