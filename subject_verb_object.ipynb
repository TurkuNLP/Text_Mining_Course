{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVO\n",
    "\n",
    "* Subject-verb-object is an example of simple relations we could try to gather\n",
    "* a simple dep_search query would be something like `VERB >obj (NOUN|PROPN) >nsubj (NOUN|PROPN)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# db-name: /home/ginter/dep_search_py2/en_news/trees_00000.db\n",
      "# graph id: 4\n",
      "# db-name: /home/ginter/dep_search_py2/en_news/trees_00000.db\n",
      "# graph id: 5\n",
      "# graph id: 4\n",
      "# visual-style\t9\tbgColor:lightgreen\n",
      "# hittoken:\t9\tdetained\tdetain\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t3\tccomp\t_\t_\n",
      "# sent_id = 5\n",
      "# text = The church said in March that North Korea detained Lim during one of his regular humanitarian missions there.\n",
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
      "2\tchurch\tchurch\tNOUN\tNN\tNumber=Sing\t3\tnsubj\t_\t_\n",
      "3\tsaid\tsay\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
      "4\tin\tin\tADP\tIN\t_\t5\tcase\t_\t_\n",
      "5\tMarch\tMarch\tPROPN\tNNP\tNumber=Sing\t3\tobl\t_\t_\n",
      "6\tthat\tthat\tSCONJ\tWDT\tPronType=Rel\t9\tmark\t_\t_\n",
      "7\tNorth\tNorth\tPROPN\tNNP\tNumber=Sing\t8\tcompound\t_\t_\n",
      "8\tKorea\tKorea\tPROPN\tNNP\tNumber=Sing\t9\tnsubj\t_\t_\n",
      "9\tdetained\tdetain\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t3\tccomp\t_\t_\n",
      "10\tLim\tLim\tPROPN\tNNP\tNumber=Sing\t9\tobj\t_\t_\n",
      "11\tduring\tduring\tADP\tIN\t_\t12\tcase\t_\t_\n",
      "12\tone\tone\tNUM\tCD\tNumType=Card\t9\tobl\t_\t_\n",
      "13\tof\tof\tADP\tIN\t_\t17\tcase\t_\t_\n",
      "14\this\the\tPRON\tPRP$\tGender=Masc|Number=Sing|Person=3|Poss=Yes|PronType=Prs\t17\tnmod:poss\t_\t_\n",
      "15\tregular\tregular\tADJ\tJJ\tDegree=Pos\t17\tamod\t_\t_\n",
      "16\thumanitarian\thumanitarian\tADJ\tJJ\tDegree=Pos\t17\tamod\t_\t_\n",
      "17\tmissions\tmission\tNOUN\tNNS\tNumber=Plur\t12\tnmod\t_\t_\n",
      "18\tthere\tthere\tADV\tRB\tPronType=Dem\t9\tadvmod\t_\tSpaceAfter=No\n",
      "19\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\tSpacesAfter=\\n\n",
      "\n",
      "# db-name: /home/ginter/dep_search_py2/en_news/trees_00000.db\n",
      "# graph id: 12\n",
      "# graph id: 5\n",
      "# visual-style\t3\tbgColor:lightgreen\n",
      "# hittoken:\t3\tleft\tleave\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
      "# sent_id = 6\n",
      "# text = The result left United in second place behind Manchester City before both teams meet next week.\n",
      "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
      "2\tresult\tresult\tNOUN\tNN\tNumber=Sing\t3\tnsubj\t_\t_\n",
      "3\tleft\tleave\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
      "4\tUnited\tUnited\tPROPN\tNNP\tNumber=Sing\t3\tobj\t_\t_\n",
      "5\tin\tin\tADP\tIN\t_\t7\tcase\t_\t_\n",
      "6\tsecond\tsecond\tADJ\tJJ\tDegree=Pos|NumType=Ord\t7\tamod\t_\t_\n",
      "7\tplace\tplace\tNOUN\tNN\tNumber=Sing\t3\tobl\t_\t_\n",
      "8\tbehind\tbehind\tADP\tIN\t_\t10\tcase\t_\t_\n",
      "9\tManchester\tManchester\tPROPN\tNNP\tNumber=Sing\t10\tcompound\t_\t_\n",
      "10\tCity\tCity\tPROPN\tNNP\tNumber=Sing\t3\tobl\t_\t_\n",
      "11\tbefore\tbefore\tSCONJ\tIN\t_\t14\tmark\t_\t_\n",
      "12\tboth\tboth\tDET\tDT\t_\t13\tdet\t_\t_\n",
      "13\tteams\tteam\tNOUN\tNNS\tNumber=Plur\t14\tnsubj\t_\t_\n",
      "14\tmeet\tmeet\tVERB\tVBP\tMood=Ind|Tense=Pres|VerbForm=Fin\t3\tadvcl\t_\t_\n",
      "15\tnext\tnext\tADJ\tJJ\tDegree=Pos\t16\tamod\t_\t_\n",
      "16\tweek\tweek\tNOUN\tNN\tNumber=Sing\t14\tobl:tmod\t_\tSpaceAfter=No\n",
      "17\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\tSpacesAfter=\\n\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A simple way you can query dep_search API programmatically\n",
    "import requests\n",
    "\n",
    "dep_search_api=\"http://edu.turkunlp.org/dep_search_webapi\" #go here in the browser, you get help\n",
    "query=\"VERB >obj (NOUN|PROPN) >nsubj (NOUN|PROPN)\"\n",
    "parameters={\"search\":query,\n",
    "           \"db\":\"NEWS_EN_10M\",\n",
    "           \"retmax\":2,\n",
    "           \"context\":0}\n",
    "r=requests.get(dep_search_api,params=parameters)\n",
    "conllu=r.text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have a way to get S-V-O hits and the verb is marked with a \"hittoken\" line\n",
    "* Our tasks will be as follows:\n",
    "  1. Gather all verbs and their subject, object arguments\n",
    "  2. Expand the subjects and objects to whole (reasonable) subtrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('detain', 'Korea', 'Lim')\n",
      "('leave', 'result', 'United')\n",
      "('fetch', 'stamp', 'price')\n",
      "('have', 'state', 'limit')\n",
      "('launch', 'Goldenvoice', 'website')\n",
      "('have', 'Yemen', 'case')\n",
      "('set', 'Jeffrey', 'week')\n",
      "('defeat', 'Gov.', 'attorney')\n",
      "('celebrate', 'Caroline', 'thing')\n",
      "('change', 'Riyadh', 'stance')\n",
      "('limit', 'Iran', 'production')\n",
      "('make', 'bill', 'procurement')\n",
      "('visit', 'minister', 'constituency')\n",
      "('mobilize', 'law', 'opposition')\n",
      "('step', 'Britain', 'training')\n",
      "('encourage', 'finding', 'people')\n",
      "('involve', 'plan', 'power')\n",
      "('sign', 'Carla', 'deal')\n",
      "('rearrange', 'Britney', 'furniture')\n",
      "('need', 'girl', 'phone')\n",
      "('do', 'shell', 'job')\n",
      "('arrest', 'police', 'dozen')\n",
      "('lash', 'weather', 'Britain')\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "ID,FORM, LEMMA, UPOS, XPOS, FEATS, HEAD, DEPREL, DEPS, MISC=range(10) #column names\n",
    "\n",
    "def read_conllu(inp):\n",
    "    \"\"\"The simplest conllu reader I can imagine\"\"\"\n",
    "    current_comments=[]\n",
    "    current_tree=[]\n",
    "    for line in inp:\n",
    "        line=line.strip()\n",
    "        if not line: #empty line -> new tree starting, get rid of the old one\n",
    "            yield current_comments, current_tree\n",
    "            current_comments=[]\n",
    "            current_tree=[]\n",
    "        elif line.startswith(\"#\"):\n",
    "            current_comments.append(line) #this is a comment\n",
    "        else:\n",
    "            current_tree.append(line.split(\"\\t\"))\n",
    "    else: #all done\n",
    "        yield current_comments, current_tree\n",
    "\n",
    "def get_vso(comments,tree):\n",
    "    #1) We want to get the hittoken, we know there is at least one\n",
    "    results=[] #I'll gather here tuples like (verb_idx,subj_idx,obj_idx)\n",
    "    hittokens=[comment for comment in comments if comment.startswith(\"# hittoken:\")]\n",
    "    for hit in hittokens: #hit is now a just a line like: # hittoken:\t9\tdetained\tdetain\tVERB\n",
    "        columns=hit.split(\"\\t\")[1:] #split on tab, kill the first column (# hittoken:)\n",
    "        lemma=columns[LEMMA]\n",
    "        verb_idx=columns[ID] #this is now something like \"9\"\n",
    "        #now go look for subjects and objects\n",
    "        subjects=[row for row in tree if row[HEAD]==verb_idx and row[DEPREL]==\"nsubj\"]\n",
    "        objects=[row for row in tree if row[HEAD]==verb_idx and row[DEPREL]==\"obj\"]\n",
    "        #there should be at least one of each, if there is more than one, maybe we don't care about it\n",
    "        if len(subjects)>1 or len(objects)>1:\n",
    "            continue #meh, there's something weird\n",
    "        results.append((verb_idx,subjects[0][ID],objects[0][ID]))\n",
    "    return results #returns a list like [(\"9\",\"11\",\"7\")] with the indices of verb,subj,obj\n",
    "\n",
    "def get_strings(tree,vso):\n",
    "    v,s,o=vso\n",
    "    verb,subj,obj=tree[int(v)-1][LEMMA],tree[int(s)-1][LEMMA],tree[int(o)-1][LEMMA]\n",
    "    return (verb,subj,obj)\n",
    "        \n",
    "with gzip.open(\"/course_data/textmine/parsed-data/english-svo.conllu.gz\",\"rt\",encoding=\"utf-8\") as f:\n",
    "    for counter,(comments, tree) in enumerate(read_conllu(f)):\n",
    "        #now we have a single sentence with s-v-o hit in it\n",
    "        vsos=get_vso(comments,tree)\n",
    "        for vso in vsos:\n",
    "            print(get_strings(tree,vso))\n",
    "        if counter==20:\n",
    "            break\n",
    "#seems to work, to an extent, let's try to improve upon this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('detain', 'North Korea', 'Lim')\n",
      "('leave', 'result', 'United')\n",
      "('fetch', 'stamp', 'auction price')\n",
      "('have', 'state', 'limit')\n",
      "('launch', 'Goldenvoice', 'website')\n",
      "('have', 'Yemen', 'case')\n",
      "('set', 'Massachusetts Superior Court judge Jeffrey Locke', 'week')\n",
      "('defeat', 'Republican Gov. Mary Fallin', 'Oklahoma City criminal defense attorney Chad Moody')\n",
      "('celebrate', 'Caroline Wozniacki', 'thing')\n",
      "('change', 'Riyadh', 'stance')\n",
      "('limit', 'Iran', 'production')\n",
      "('make', 'bill', 'procurement')\n",
      "('visit', 'minister', 'constituency')\n",
      "('mobilize', 'law', 'opposition')\n",
      "('step', 'Britain', 'training')\n",
      "('encourage', 'finding', 'people')\n",
      "('involve', 'plan', 'power')\n",
      "('sign', 'Carla Borrego', 'deal')\n",
      "('rearrange', 'Britney Spears', 'hotel room furniture')\n",
      "('need', 'girl', 'phone')\n",
      "('do', 'shell', 'job')\n",
      "('arrest', 'police', 'dozen')\n",
      "('lash', 'weather', 'Britain')\n"
     ]
    }
   ],
   "source": [
    "def get_children(tree):\n",
    "    children=[[] for _ in range(len(tree))] #empty list for every word, will gather the indices, 0-based, of its children\n",
    "    for row in tree:\n",
    "        head_idx=int(row[HEAD])-1\n",
    "        if head_idx>=0:\n",
    "            children[head_idx].append((row[DEPREL],int(row[ID])-1)) #append e.g. (nsubj,5) meaning node idx 5 is a child, with deprel nsubj\n",
    "    return children #all we need to know here\n",
    "\n",
    "def subtree(ofnode,tree_children,gathered_so_far,only_relations=set((\"compound\",\"flat\"))):\n",
    "    #gather all children \n",
    "    for rel,child in tree_children[ofnode]:\n",
    "        if rel not in only_relations:\n",
    "            continue #this kid ain't interesting\n",
    "        gathered_so_far.append(child)\n",
    "        subtree(child,tree_children,gathered_so_far)\n",
    "\n",
    "def expand(node,tree_children,tree):\n",
    "    gathered=[node] #start with the word itself\n",
    "    subtree(node,tree_children,gathered) #expand it recursively\n",
    "    gathered=sorted(gathered) #and sort\n",
    "    #this is now a list of words\n",
    "    return \" \".join(tree[node][LEMMA] for node in gathered)\n",
    "\n",
    "def get_strings(tree,tree_children,vso):\n",
    "    v,s,o=vso\n",
    "    verb,subj,obj=tree[int(v)-1][LEMMA],expand(int(s)-1,tree_children,tree),expand(int(o)-1,tree_children,tree)\n",
    "    return (verb,subj,obj)\n",
    "\n",
    "with gzip.open(\"/course_data/textmine/parsed-data/english-svo.conllu.gz\",\"rt\",encoding=\"utf-8\") as f:\n",
    "    for counter,(comments, tree) in enumerate(read_conllu(f)):\n",
    "        #now we have a single sentence with s-v-o hit in it\n",
    "        vsos=get_vso(comments,tree)\n",
    "        tree_children=get_children(tree)\n",
    "        \n",
    "        if not vsos:\n",
    "            continue #only happens for two subjects or two objects which we skip\n",
    "        for vso in vsos:\n",
    "            print(get_strings(tree,tree_children,vso))\n",
    "        if counter==20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2378000 1396000 1658000\r"
     ]
    }
   ],
   "source": [
    "with gzip.open(\"/course_data/textmine/parsed-data/english-svo.conllu.gz\",\"rt\",encoding=\"utf-8\") as f,\\\n",
    "    open(\"triples.tsv\",\"wt\",encoding=\"utf-8\") as out:\n",
    "    for counter,(comments, tree) in enumerate(read_conllu(f)):\n",
    "        #now we have a single sentence with s-v-o hit in it\n",
    "        vsos=get_vso(comments,tree)\n",
    "        tree_children=get_children(tree)\n",
    "        if not vsos:\n",
    "            continue #only happens for two subjects or two objects which we skip\n",
    "        for vso in vsos:\n",
    "            print(\"\\t\".join(get_strings(tree,tree_children,vso)),file=out)\n",
    "        if counter%1000==0:\n",
    "            print(\"Processed\",counter,end=\"\\r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
