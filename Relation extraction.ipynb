{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Relation extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmbmobBUQrU"
      },
      "source": [
        "# Relation extraction\n",
        "\n",
        "Previously:\n",
        "\n",
        "* Introduction to Information Extraction\n",
        "* Named Entity Recognition\n",
        "* Normalization and Entity linking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnvduwYmZOJK"
      },
      "source": [
        "---\n",
        "\n",
        "**Named Entity Recognition** (NER) recognizes mentions of target entities in text and (typically) assign each a type (e.g. `PERSON`, `LOCATION`)\n",
        "\n",
        "<img width=\"90%\" src=\"https://raw.githubusercontent.com/TurkuNLP/turku-ner-corpus/master/docs/example.png\">\n",
        "\n",
        "---\n",
        "\n",
        "**Entity linking** identifies the real-word entities referred to in text by associating mentions with IDs in a knowledge base (e.g. Wikidata):\n",
        "\n",
        "<img width=\"90%\" src=\"https://github.com/TurkuNLP/Text_Mining_Course/raw/master/figs/entity-linking-marin.png\">\n",
        "\n",
        "---\n",
        "\n",
        "Here, we will assume that NER and normalization have already been performed and build on their outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgiHEaPxeq5o"
      },
      "source": [
        "**Relation extraction** aims to identify meaninful associations between mentions of (named) entities. The associations are represented as relations, which often (but not necessarily) also have a type.\n",
        "\n",
        "We previously discussed some relations found in Wikidata, such as\n",
        "\n",
        "* `instance_of(Douglas Adams, human)`\n",
        "* `date_of_birth(Douglas Adams, 11 March 1952)`\n",
        "* `country_of_citizenship(Douglas Adams, United Kingdom)`\n",
        "\n",
        "These are _typed, binary_ relations: each relation has a type (e.g. `country_of_citizenship`) and relates exactly two things (e.g. `Douglas Adams` and `United Kingdom`). These relations (and more) could be extracted from the following text:\n",
        "\n",
        "<blockquote>\n",
        "Douglas Noel Adams (11 March 1952 – 11 May 2001) was an English author\n",
        "</blockquote>\n",
        "\n",
        "As was noted at in the material on [Normalization](https://colab.research.google.com/github/TurkuNLP/Text_Mining_Course/blob/master/Normalization.ipynb), relation extraction allows us to populate knowledge bases with information discovered from text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE-Ag-v7UbfS"
      },
      "source": [
        "**Examples of relation extraction targets** include\n",
        "\n",
        "* Part-whole: `part_of(Cambridge, United Kingdom)`\n",
        "* Location: `place_of_birth(Douglas Adams, Cambridge)`\n",
        "* Family: `father(Douglas Adams, Christopher Adams)`\n",
        "* Membership: `member(Clarence Thomas, Supreme Court)`\n",
        "* Affiliation: `employee(Larry Page, Google)`\n",
        "* Ownership: `owner(John Smith, John's Hardware store)`\n",
        "* ... and many, many more (see e.g. [ACE relations](https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-relations-guidelines-v6.2.pdf))\n",
        "\n",
        "In specialized domains, relation extraction can target e.g.\n",
        "\n",
        "* Protein-protein interactions\n",
        "* Drug-disease relations\n",
        "* Drug side-effects\n",
        "* Organism-habitat relations\n",
        "* etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huCw97VOhU-3"
      },
      "source": [
        "## Task setting\n",
        "\n",
        "We could potentially target relations of any _arity_, for example\n",
        "\n",
        "* ternary: `parents(Douglas Adams, Janet Adams, Christopher Adams)`\n",
        "* ternary: `date_and_place_of_birth(Douglas Adams, 11 March 1952, Cambridge)`\n",
        "* 4-ary: `dates_of_birth_and_death_and_nationality(Douglas Adams, 11 March 1952, 11 May 2001, United Kingdom)`\n",
        "\n",
        "For simplicity, we will here focus on binary relations, also noting that many ternary, 4-ary etc. relations can be decomposed into binary relations.\n",
        "\n",
        "Let's first consider the following generalized task setting for untyped binary relation extraction:\n",
        "\n",
        "* Given a set of text documents $D = \\{ d_1, d_2, \\ldots d_n \\}$, and\n",
        "* For each document $d$, given mentions of entities in that document $M_d = \\{m_1, m_2, \\ldots, m_n \\}$\n",
        "* Return for each document relations $R_d \\subset M_d \\times M_d$ that hold between the entities based on $d$\n",
        "\n",
        "So, here a relation is represented as simply a pair of mentions.\n",
        "\n",
        "We will here assume that the mentions $m$ are identified by start and end offsets, type, and text, so that for example if\n",
        "\n",
        "$d =$ `Douglas Adams is an English author ...`\n",
        "\n",
        "we could have\n",
        "\n",
        "$M_d = \\{$ `(0, 13, \"PERSON\", \"Douglas Adams\")`, `(20, 27, \"NORP\", \"English\")`, $\\ldots \\}$\n",
        "\n",
        "in code, let's define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WXYC3_PP7kK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3330d0c3-a962-4ae7-90c1-7f66de4ce42d"
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "\n",
        "Mention = namedtuple('Mention', 'start end type text')\n",
        "\n",
        "\n",
        "# Example document and entities\n",
        "d = 'Douglas Adams is an English author'\n",
        "M_d = [\n",
        "  Mention(0, 13, 'PERSON', 'Douglas Adams'),\n",
        "  Mention(20, 27, 'GPE', 'English'),\n",
        "]\n",
        "\n",
        "# Note that mention text is redundant given text and the (start, end) offsets.\n",
        "# The mention text is included here only for convenience.\n",
        "for m in M_d:\n",
        "  print(m, '→', d[m.start:m.end])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mention(start=0, end=13, type='PERSON', text='Douglas Adams') → Douglas Adams\n",
            "Mention(start=20, end=27, type='GPE', text='English') → English\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xgW7bkoP_e1"
      },
      "source": [
        "(Note that we're not explicitly including normalization results here, but will assume normalization to be available when required.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXB8X0hnDUjQ"
      },
      "source": [
        "## Metrics\n",
        "\n",
        "As most relations in $M_d \\times M_d$ (i.e. all combinations of entity pairs in a document) do not hold, a trivial \"method\" that never returns any relations could have deceptively high _accuracy_: for example, if there are 100 possible pairs in a document and a relation holds for 5, returning an empty set of relations would give 95% accuracy.\n",
        "\n",
        "For this reason, accuracy is rarely used to evaluate relation extraction; instead, the standard information retrieval metrics are used:\n",
        "\n",
        "* **Precision**: the ratio of extracted relations that are correct\n",
        "* **Recall**: the ratio of correct relations that are extracted\n",
        "* **$F_1$-score**: the balanced harmonic mean of precision and recall\n",
        "\n",
        "(These metrics should already be familiar from previous material.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYT-x8bSlZJ3"
      },
      "source": [
        "## Relation extraction approaches\n",
        "\n",
        "There are several approaches we can take to relation extraction, including\n",
        "\n",
        "* **Co-occurrences**: assume that mentions occurring in the same context have some relation\n",
        "* **Rules**: write explicit instructions (code) for extracting relations\n",
        "* **Machine learning**: annotate example relations and train ML method to extract them\n",
        "\n",
        "We'll cover each of these in this session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uhhWQxJpd3Z"
      },
      "source": [
        "---\n",
        "\n",
        "# Co-occurrence-based relation extraction\n",
        "\n",
        "Relation extraction based primarily on the assumption that when entity mentions **occur together** in some context (e.g. sentence, paragraph, document), some relation is likely to hold between them.\n",
        "\n",
        "The simplest form of co-occurrence based relation extraction would be to always return a relation for all pairs of co-occurring entities. Let's illustrate this for a very simple sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ79jwyHoLV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb43997e-733e-4c69-e8a4-5f4e51b3e490"
      },
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "def cooccurrence_relations(mentions):\n",
        "  relations = []\n",
        "  for i, mention1 in enumerate(mentions):\n",
        "    for j, mention2 in enumerate(mentions[i+1:]):\n",
        "      relations.append((mention1, mention2))\n",
        "  return relations\n",
        "\n",
        "\n",
        "text = 'Douglas Adams (born March 11th 1952) was a British author.'\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "for m1, m2 in cooccurrence_relations(doc.ents):\n",
        "  print((m1.text, m2.text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Douglas Adams', 'March 11th 1952')\n",
            "('Douglas Adams', 'British')\n",
            "('March 11th 1952', 'British')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxhFOV1Px6X9"
      },
      "source": [
        "For this simple example, we get two valid relations:\n",
        "\n",
        "* (Douglas Adams, March 11th 1952)\n",
        "* (Douglas Adams, British)\n",
        "\n",
        "and one erroneous (or meaningless) relation:\n",
        "\n",
        "* (March 11th 1952, British)\n",
        "\n",
        "In general, the naive co-occurrence based approach has perfect recall (all relevant relations are included) but typically very poor precision: most of the returned relations are wrong. This is evident already with slightly longer text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02k6_sU_xXJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b0eefb-5c76-42a8-c0a6-7452bd7ff33e"
      },
      "source": [
        "text = [\n",
        "  'Adams was born on 11 March 1952 to Janet and Christopher Adams in Cambridge.',\n",
        "  'The family later moved to London, where his sister, Susan, was born.',\n",
        "]\n",
        "\n",
        "doc = nlp(' '.join(text))\n",
        "for m1, m2 in cooccurrence_relations(doc.ents):\n",
        "  print((m1.text, m2.text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Adams', '11 March 1952')\n",
            "('Adams', 'Janet')\n",
            "('Adams', 'Christopher Adams')\n",
            "('Adams', 'Cambridge')\n",
            "('Adams', 'London')\n",
            "('Adams', 'Susan')\n",
            "('11 March 1952', 'Janet')\n",
            "('11 March 1952', 'Christopher Adams')\n",
            "('11 March 1952', 'Cambridge')\n",
            "('11 March 1952', 'London')\n",
            "('11 March 1952', 'Susan')\n",
            "('Janet', 'Christopher Adams')\n",
            "('Janet', 'Cambridge')\n",
            "('Janet', 'London')\n",
            "('Janet', 'Susan')\n",
            "('Christopher Adams', 'Cambridge')\n",
            "('Christopher Adams', 'London')\n",
            "('Christopher Adams', 'Susan')\n",
            "('Cambridge', 'London')\n",
            "('Cambridge', 'Susan')\n",
            "('London', 'Susan')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEnXoQNfyaQ3"
      },
      "source": [
        "The combinatorial explosion of wrong or irrelevant pairs arising from naive co-occurrence based relation extraction can be alleviated by restricting the scope of considered co-occurrences to e.g. sentences, but this does compromise on the perfect recall of the approach: relations can involve entities mentioned in different sentences.\n",
        "\n",
        "Note additionally that this approach does not provide any information about the _types_ of the relations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJVoVUH8Z3rJ"
      },
      "source": [
        "## Statistical approaches\n",
        "\n",
        "Co-occurrence provides only weak evidence that the co-mentioned entities are associated. However, by accumulating such evidence over a large corpus, it is possible to identify associations with higher confidence than a single co-occurrence can give.\n",
        "\n",
        "Let's illustrate this by looking at mentions tagged in a sample of English Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0iEcknrFG-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ea0c83-0689-4aff-e3df-11f38c88f6a7"
      },
      "source": [
        "!wget -nc https://a3s.fi/TKO_8964_2021/en-wiki-sample-ontonotes.conll.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-19 05:28:38--  https://a3s.fi/TKO_8964_2021/en-wiki-sample-ontonotes.conll.gz\n",
            "Resolving a3s.fi (a3s.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to a3s.fi (a3s.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79442456 (76M) [application/gzip]\n",
            "Saving to: ‘en-wiki-sample-ontonotes.conll.gz’\n",
            "\n",
            "en-wiki-sample-onto 100%[===================>]  75.76M  68.7MB/s    in 1.1s    \n",
            "\n",
            "2021-04-19 05:28:39 (68.7 MB/s) - ‘en-wiki-sample-ontonotes.conll.gz’ saved [79442456/79442456]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvl9NquVbFaV"
      },
      "source": [
        "We'll use a reader function for the two-column (text, tag) CoNLL format. You should already be familiar with this representation from previous material."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEBkb8FqF4S0"
      },
      "source": [
        "import gzip\n",
        "\n",
        "\n",
        "def read_conll_entities(stream):\n",
        "  words, tags = [], []\n",
        "  for ln, line in enumerate(stream, start=1):\n",
        "    if line.startswith('#'):\n",
        "      continue    # skip comments\n",
        "    elif line.isspace():\n",
        "      if words and tags:\n",
        "        yield words, tags\n",
        "      words, tags = [], []\n",
        "    else:\n",
        "      word, tag = line.rstrip('\\n').split('\\t')\n",
        "      words.append(word)\n",
        "      tags.append(tag)\n",
        "  if words and tags:\n",
        "    yield words, tags\n",
        "\n",
        "\n",
        "conll_sentences = []\n",
        "with gzip.open('en-wiki-sample-ontonotes.conll.gz', 'rt', encoding='utf-8') as f:\n",
        "  for words, tags in read_conll_entities(f):\n",
        "    conll_sentences.append((words, tags))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j04RJh0boVo"
      },
      "source": [
        "This NER annotation is represented in the familiar IOB (in-out-begin) format (see [NER notebook](https://colab.research.google.com/github/TurkuNLP/Text_Mining_Course/blob/master/NER_introduction.ipynb)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgOLkutbR21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf653a34-78d3-4b57-cc2c-57df1aab8098"
      },
      "source": [
        "for word, tag in zip(*conll_sentences[1]):\n",
        "  print(f'{word}\\t{tag}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ayn\tB-PERSON\n",
            "Rand\tI-PERSON\n",
            "(\tO\n",
            ";\tO\n",
            "born\tO\n",
            "Alisa\tB-PERSON\n",
            "Zinovyevna\tI-PERSON\n",
            "Rosenbaum\tI-PERSON\n",
            ";\tO\n",
            "–\tO\n",
            "March\tB-DATE\n",
            "6\tI-DATE\n",
            ",\tI-DATE\n",
            "1982\tI-DATE\n",
            ")\tO\n",
            "was\tO\n",
            "a\tO\n",
            "Russian\tB-NORP\n",
            "-\tI-NORP\n",
            "American\tI-NORP\n",
            "writer\tO\n",
            "and\tO\n",
            "philosopher\tO\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjeDy3yNb4hL"
      },
      "source": [
        "Let's next convert these IOB-tagged sentences into the mention format defined above, where each mention is defined by its start and end offsets, type, and text. (You don't need to understand the conversion steps in detail.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heqajmewMUCR"
      },
      "source": [
        "def conll_to_mentions(words, tags):\n",
        "  mentions, offset, start, label = [], 0, None, None\n",
        "  sentence = ' '.join(words)\n",
        "  for word, tag in zip(words, tags):\n",
        "    if tag[0] in 'OB' and start is not None:    # current ends\n",
        "      end = offset-1\n",
        "      mentions.append(Mention(start, end, label, sentence[start:end]))\n",
        "      start, label = None, None\n",
        "    if tag[0] == 'B':\n",
        "      start, label = offset, tag[2:]\n",
        "    elif tag[0] == 'I':\n",
        "      if start is None:    # I without B, but nevermind\n",
        "        start, label = offset, tag[2:]\n",
        "    else:\n",
        "      assert tag == 'O', 'unexpected tag {}'.format(tag)\n",
        "    offset += len(word) + 1    # +1 for space\n",
        "  if start is not None:    # span open at sentence end\n",
        "    end = offset-1\n",
        "    mentions.append(Mention(start, end, label, sentence[start:end]))\n",
        "  return mentions\n",
        "\n",
        "\n",
        "sentences = []\n",
        "mentions_by_sentence = []\n",
        "for words, tags in conll_sentences:\n",
        "  sentences.append(' '.join(words))\n",
        "  mentions_by_sentence.append(conll_to_mentions(words, tags))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGfdb3uqcGQ0"
      },
      "source": [
        "Now we have for the above example sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDcRZ69cKWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c889aed-6bc8-4c7b-d7cc-a0bdc295df78"
      },
      "source": [
        "for mention in mentions_by_sentence[1]:\n",
        "  print(mention)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mention(start=0, end=8, type='PERSON', text='Ayn Rand')\n",
            "Mention(start=18, end=44, type='PERSON', text='Alisa Zinovyevna Rosenbaum')\n",
            "Mention(start=49, end=63, type='DATE', text='March 6 , 1982')\n",
            "Mention(start=72, end=90, type='NORP', text='Russian - American')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIDLJz30cZCt"
      },
      "source": [
        "This is the `(start, end, type, text)` representation that we want for relation extraction.\n",
        "\n",
        "Let's next see if we can find anything of interest just by looking at the most common co-occurrences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDnhJIbTUXd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dcd1f4-c628-47c2-d7d4-6bfa91b890a2"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "relation_counts = Counter()\n",
        "for mentions in mentions_by_sentence:\n",
        "  for relation in cooccurrence_relations(mentions):\n",
        "    relation_counts[relation] += 1\n",
        "\n",
        "for relation, count in relation_counts.most_common(10):\n",
        "  m1, m2 = relation[0], relation[1]\n",
        "  print(f'{count}\\t({m1.text}/{m1.type}, {m2.text}/{m2.type})')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3939\t(every 100/CARDINAL, age 18/DATE)\n",
            "3738\t(Hispanic/NORP, Latino/NORP)\n",
            "1177\t(25 to 44/DATE, 45 to 64/DATE)\n",
            "1095\t(the age of 18/DATE, 45 to 64/DATE)\n",
            "1087\t(the age of 18/DATE, 25 to 44/DATE)\n",
            "1020\t(the age of 18/DATE, 65 years of age or older/DATE)\n",
            "999\t(45 to 64/DATE, 65 years of age or older/DATE)\n",
            "986\t(25 to 44/DATE, 65 years of age or older/DATE)\n",
            "816\t(18/CARDINAL, 24/CARDINAL)\n",
            "807\t(24/CARDINAL, 45 to 64/DATE)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8gtB7bbdUjb"
      },
      "source": [
        "These aren't really interesting; most of the pairs involve a pair of numeric mention types. On reflection, it seems reasonable to assume that at least one of each pair of potentially related entities should have something other than a numeric type. We might also get more relevant associations by focusing further on specific types. Let's try this out.\n",
        "\n",
        "This data uses [OntoNotes types](https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf#page=21):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txO_aVSEeviA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f7424a-cd65-43ee-8fb4-9f39d8226a8c"
      },
      "source": [
        "ALL_TYPES = set(m.type for mentions in mentions_by_sentence for m in mentions)\n",
        "\n",
        "ALL_TYPES"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CARDINAL',\n",
              " 'DATE',\n",
              " 'EVENT',\n",
              " 'FAC',\n",
              " 'GPE',\n",
              " 'LANGUAGE',\n",
              " 'LAW',\n",
              " 'LOC',\n",
              " 'MONEY',\n",
              " 'NORP',\n",
              " 'ORDINAL',\n",
              " 'ORG',\n",
              " 'PERCENT',\n",
              " 'PERSON',\n",
              " 'PRODUCT',\n",
              " 'QUANTITY',\n",
              " 'TIME',\n",
              " 'WORK_OF_ART'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOU4tAkefry0"
      },
      "source": [
        "Let's see if we get more interesting pairings by filtering by type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIG8YmYkYcy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb2a8ea-a47c-4bb6-b2a9-8f53ce8828bc"
      },
      "source": [
        "def filtered_cooccurrence_relations(mentions, types1, types2):\n",
        "  relations = []\n",
        "  for i, mention1 in enumerate(mentions):\n",
        "    for mention2 in mentions[i+1:]:\n",
        "      if (mention1.type in types1 and mention2.type in types2 and\n",
        "          mention1.type != mention2.type):\n",
        "        relations.append((mention1, mention2))\n",
        "  return relations\n",
        "\n",
        "\n",
        "# Try changing the following to other types! (see above for list)\n",
        "TYPES1 = { 'PERSON' }\n",
        "TYPES2 = { 'ORG' }\n",
        "\n",
        "relation_counts = Counter()\n",
        "for mentions in mentions_by_sentence:\n",
        "  for relation in filtered_cooccurrence_relations(mentions, TYPES1, TYPES2):\n",
        "    relation_counts[relation] += 1\n",
        "\n",
        "for relation, count in relation_counts.most_common(20):\n",
        "  m1, m2 = relation[0], relation[1]\n",
        "  print(f'{count}\\t({m1.text}/{m1.type}, {m2.text}/{m2.type})')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\t(Bosley Crowther/PERSON, `` The New York Times/ORG)\n",
            "8\t(Vincent Canby/PERSON, The New York Times/ORG)\n",
            "8\t(Janet Maslin/PERSON, The New York Times/ORG)\n",
            "7\t(Gene Siskel/PERSON, the `` Chicago Tribune/ORG)\n",
            "6\t(Charles Champlin/PERSON, the `` Los Angeles Times/ORG)\n",
            "4\t(Roger Ebert/PERSON, Chicago Sun-Times/ORG)\n",
            "3\t(Gary Arnold/PERSON, The Washington Post/ORG)\n",
            "3\t(A. O. Scott/PERSON, The New York Times/ORG)\n",
            "3\t(St John 's/PERSON, College/ORG)\n",
            "3\t(A. H. Weiler/PERSON, The New York Times/ORG)\n",
            "3\t(Häkkinen/PERSON, McLaren/ORG)\n",
            "3\t(Tuoba Xianbei/PERSON, the Northern Wei/ORG)\n",
            "2\t(Stephen Thomas Erlewine/PERSON, AllMusic/ORG)\n",
            "2\t(Martin Richards/PERSON, the University of Cambridge/ORG)\n",
            "2\t(Charles II/PERSON, the Hudson 's Bay Company/ORG)\n",
            "2\t(Charles II/PERSON, HBC/ORG)\n",
            "2\t(Cranmer/PERSON, Church/ORG)\n",
            "2\t(Cranmer/PERSON, Prayer Books/ORG)\n",
            "2\t(Roosevelt/PERSON, Congress/ORG)\n",
            "2\t(Mick LaSalle/PERSON, the `` San Francisco Chronicle/ORG)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgladGZniG3d"
      },
      "source": [
        "That's better, there are definitely valid relations there that could potentially serve as entries in a knowledge base given normalization (and a relation type!)\n",
        "\n",
        "In this simple statistical approach, we have ranked the relations by their total count in the corpus. While this simple ranking approach can work, it should be noted that it fails to account for the probability of chance co-occurrence.\n",
        "\n",
        "An improved statistical approach would be to use the overall frequency of occurrence in the data to get an estimate of the expected number of co-occurrences for each pair, and divide the counts of actual co-occurrences by this number to determine which pairs co-occur more frequently than expected by chance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbCGhWmH-7WY"
      },
      "source": [
        "---\n",
        "\n",
        "# Rule-based relation extraction\n",
        "\n",
        "Broadly, any method involving explicitly written instructions for how to extract relations. (Contrast with machine learning approaches, where the \"rules\" are learned from examples.)\n",
        "\n",
        "Let's first consider a simple extension of naive co-occurrence based relation extraction to assign candidate types to co-occurring mentions by looking for keywords in their context -- here, the words in between the mentions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkGDC8qVQS3x",
        "outputId": "72613fc2-2968-4980-e295-21bed9cc2d71"
      },
      "source": [
        "relation_keywords = {\n",
        "    'date_of_birth': ['born', 'birth'],\n",
        "    'date_of_death': ['died', 'dead', 'killed'],\n",
        "}\n",
        "\n",
        "relation_counts = Counter()\n",
        "for sentence, mentions in zip(sentences, mentions_by_sentence):\n",
        "  for i, mention1 in enumerate(mentions):\n",
        "    for mention2 in mentions[i+1:]:\n",
        "      if mention1.type == 'PERSON' and mention2.type == 'DATE':\n",
        "        between_words = sentence[mention1.end:mention2.start].split()\n",
        "        for rel, keywords in relation_keywords.items():\n",
        "          if any(k in between_words for k in keywords):\n",
        "            relation_counts[(rel, mention1.text, mention2.text)] += 1\n",
        "\n",
        "for relation, count in relation_counts.most_common(20):\n",
        "  rel, m1, m2 = relation[0], relation[1], relation[2]\n",
        "  print(f'{count}\\t{rel}({m1}, {m2})')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\tdate_of_death(Richard Montgomery, 1775)\n",
            "3\tdate_of_birth(Afonso, 1109)\n",
            "3\tdate_of_death(Queen Victoria, 22 January 1901)\n",
            "3\tdate_of_death(Garret Hobart, 1899)\n",
            "2\tdate_of_death(Afonso, 1185)\n",
            "2\tdate_of_death(Isabella, 1103)\n",
            "2\tdate_of_death(Peter, 1103)\n",
            "2\tdate_of_birth(Mozart, about four months)\n",
            "2\tdate_of_death(Gur, October 1967)\n",
            "2\tdate_of_death(Gur, 11)\n",
            "2\tdate_of_birth(Britney Jean Spears, December 2 , 1981)\n",
            "2\tdate_of_birth(Billy Bob Thornton, August 4 , 1955)\n",
            "2\tdate_of_death(DeMille, November 1959)\n",
            "2\tdate_of_birth(David Andrew, August 28 , 1962)\n",
            "2\tdate_of_birth(Leo Fincher, August 28 , 1962)\n",
            "2\tdate_of_birth(Denis Colin Leary, 18 August 1957)\n",
            "2\tdate_of_birth(Eve Arden, April 30 , 1908)\n",
            "2\tdate_of_death(Franco, 1975)\n",
            "2\tdate_of_death(Louis XVIII, September 1824)\n",
            "2\tdate_of_death(Charles II, 1700)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1hwqpOLS_S0"
      },
      "source": [
        "There's a lot of noise here, but at least the following relation extracted for [Queen Victoria](https://en.wikipedia.org/wiki/Queen_Victoria) appears to hold:\n",
        "\n",
        "```\n",
        "date_of_death(Queen Victoria, 22 January 1901)\n",
        "```\n",
        "\n",
        "Like co-occurrence based extraction, this simple approach suffers from low precision. To improve on this, let's look at an important subclass of rule-based relation extraction methods, ones that involve explicit **patterns** for relation extraction.\n",
        "\n",
        "Extraction patterns can be expressed over the linear sequence of words (\"flat\" patterns) or over some representation of syntactic structure (e.g. dependency patterns). We'll look into both in the following.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ToxdR0rBr82"
      },
      "source": [
        "## Flat pattern matching\n",
        "\n",
        "Flat pattern matching can be implemented using standard tools such as [regular expressions](https://en.wikipedia.org/wiki/Regular_expression). (If you're not familiar with regular expression syntax or need a refresher, you may want to have a look at e.g. the detailed [regular expression HOWTO](https://docs.python.org/3/howto/regex.html) included in Python documentation.)\n",
        "\n",
        "Let's first briefly revisit the extraction of is-a relations using [Hearst patterns](https://people.ischool.berkeley.edu/~hearst/papers/coling92.pdf). The basic idea is that we can infer _is-a_ (or _type-of_, or [_hyponym_](https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy)) relations by looking for patterns such as the following:\n",
        "\n",
        "```\n",
        "authors such as Shakespeare    →  is-a(author, Shakespeare)\n",
        "libraries and other buildings  →  is-a(building, library)\n",
        "countries, including Finland   →  is-a(country, Finland)\n",
        "```\n",
        "\n",
        "Let's try a \"such as\" pattern on our example Wikipedia data. We're here fixing one participant in the relation to be an entity mention, and simply matching the other as a string using a regular expression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amoAlalIy2kx",
        "outputId": "1a79e6dd-58ea-452b-c013-e38ab684d3e8"
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# Explanation for regular expression:\n",
        "# \\b         matches word boundary\n",
        "# [a-z]+s    matches any sequence of \"a\" to \"z\" characters, ending with \"s\"\n",
        "# ( ,)?      matches optional comma\n",
        "# such as $  matches the text \"such as\" at the end of the string\n",
        "SUCH_AS_RE = re.compile(r'\\b([a-z]+s)( ,)? such as $')\n",
        "\n",
        "\n",
        "relation_counts = Counter()\n",
        "for sentence, mentions in zip(sentences, mentions_by_sentence):\n",
        "  for mention2 in mentions:\n",
        "    before = sentence[:mention2.start]\n",
        "    m = SUCH_AS_RE.search(before) \n",
        "    if m:\n",
        "      mention1 = m.group(1)\n",
        "      relation = ('is-a', mention1, mention2.text)\n",
        "      relation_counts[relation] += 1\n",
        "\n",
        "\n",
        "for relation, count in relation_counts.most_common(10):\n",
        "  type_, m1, m2 = relation[0], relation[1], relation[2]\n",
        "  print(f'{count}:\\t{type_}({m1}, {m2})')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8:\tis-a(countries, the United States)\n",
            "8:\tis-a(countries, China)\n",
            "5:\tis-a(languages, Hindi)\n",
            "5:\tis-a(countries, India)\n",
            "5:\tis-a(countries, Japan)\n",
            "5:\tis-a(countries, France)\n",
            "4:\tis-a(languages, French)\n",
            "4:\tis-a(languages, English)\n",
            "4:\tis-a(countries, the United Kingdom)\n",
            "4:\tis-a(countries, Germany)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chf0tAU-1igq"
      },
      "source": [
        "Not bad, but those plural forms really don't work here. Let's add a quick fix to lemmatize these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awLhC2do2AHc",
        "outputId": "80a75aa5-0b24-4688-ef94-87891e58f02a"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpw1uOIL1qOY",
        "outputId": "8d2c006d-5fc7-4087-be69-59d3f5bd4ef5"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for relation, count in relation_counts.most_common(20):\n",
        "  type_, m1, m2 = relation[0], relation[1], relation[2]\n",
        "  m1 = lemmatizer.lemmatize(m1)\n",
        "  print(f'{count}:\\t{type_}({m1}, {m2})')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8:\tis-a(country, the United States)\n",
            "8:\tis-a(country, China)\n",
            "5:\tis-a(language, Hindi)\n",
            "5:\tis-a(country, India)\n",
            "5:\tis-a(country, Japan)\n",
            "5:\tis-a(country, France)\n",
            "4:\tis-a(language, French)\n",
            "4:\tis-a(language, English)\n",
            "4:\tis-a(country, the United Kingdom)\n",
            "4:\tis-a(country, Germany)\n",
            "3:\tis-a(power, France)\n",
            "3:\tis-a(country, Australia)\n",
            "3:\tis-a(city, London)\n",
            "3:\tis-a(country, Egypt)\n",
            "3:\tis-a(country, Saudi Arabia)\n",
            "3:\tis-a(band, Korn)\n",
            "3:\tis-a(language, Haskell)\n",
            "3:\tis-a(city, Bukhara)\n",
            "3:\tis-a(language, Sanskrit)\n",
            "2:\tis-a(city, Athens)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KkEci4vjJjx"
      },
      "source": [
        "Or, alternatively, we can group these by hypernym:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sBj1JdT6JRJ",
        "outputId": "81d6dacd-9f07-4183-906d-029bc4c37a17"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "names_by_hypernym = defaultdict(list)\n",
        "for relation in relation_counts:\n",
        "  type_, m1, m2 = relation[0], relation[1], relation[2]\n",
        "  names_by_hypernym[m1].append(m2)\n",
        "\n",
        "# only print longer lists to avoid excessive output\n",
        "for m1, m2_list in names_by_hypernym.items():\n",
        "  if len(m2_list) > 25:\n",
        "    print(f'{m1:14s}:', ', '.join(m2_list))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writers       : Erika Holzer, Hesiod, Francis Bacon 's, Richard Hakluyt, Edward A. Pollard, Lactantius, Frank Báez, Virgil, Gail Simone, Hippolytus, Ursula K. Le Guin, James Fordyce, the 17th - century, Allen Ginsberg, Constance Cumbey, H. G. Wells, Goldstücker, Alexander Pope, Ahmad Shamlou, Giovanni Villani, Machiavelli, William S. Burroughs, Clark Ashton Smith, Saint Jerome, Michael Field, Elizabeth Harrower, Beaumont, Glenn Reynolds, Stephen Crane, Paul Huson, Alejo Carpentier, Salman Rushdie, Albert Camus, Moritz August von Thümmel, Lao She, Plutarch, Remarque, Helen Stevenson, Robert E. Howard, Emile Danoën, Stephen White, Alan Watts, Kerouac, Miguel de Cervantes, Samuel Presbiter, Mathew, Kristine Kathryn Rusch, Isaac Asimov, Richard Dawkins, Anna Seward, Olive Schreiner, John McGahern, Humfrey Barwick\n",
            "languages     : Hindi, Eiffel, Python, Jalapa Mazatec, French, English, Catalan, JavaScript, CSS, Spanish, Hausa, Sindhi, Banda, Serui, Nicaraguan Sign Language, Korean, Latin, Arabic, Mehri, Hindi , Gujarati, Pascal, Greek, Czech, Swedish, German, Italian, Serbian, Fortran, Chinese, Java, Haskell, Perl, Gelao, Cheyenne, Word 's WordBASIC, Sanskrit, Marathi, Dutch, Urdu, Mandarin Chinese, Japanese, Taiwanese, Afrikaans, Gujarati, Algerian Sign Language, Lisp, ECMAScript, Ruby, Xiongu, Albanian, Kashmiri, Hittite, Fijian, Gondi, Akkadian, Georgian, Picard\n",
            "cities        : Athens, Valdivia, Ciudad Real, London, Ghent, Tarragona, Apollonia, Manado, Chicago, Lahore, Delhi, New Orleans, Caracas, Albany, Pattaya, Moscow, Riyadh, Washington D.C., Bukhara, Rio de Janeiro, Armavir, Artaxata, Strasbourg, Sarajevo, Bilaspur, Durg, North Las Vegas, Amsterdam, Jaén, Myrhorod, San Antonio, Little Rock, Fustat, Mons, Delft, Montreal, Lyon, Algiers, Marseilles, San Francisco, Los Angeles, Nice, Thousand, Rochester, Buffalo, Pomerode, Harrisonburg, Indian Lake, Raleigh, Tongeren, Vernon, South Gate, Irvine, San Luis Obispo, Indianapolis, Nashua, Worcester, The Hague, Petrini 's Markets, Pittsburgh, New York, Norwalk, Washington\n",
            "figures       : Socrates, 99, Cunedda, Rob Roy, Caserini, Hermann Hesse, Voltaire, Mohamed Nasheed ( Anni, Liu Shaoqi, Johann Herder, Hermann Göring, Alastair Campbell, Scelba, Ahmed Yassin, M. P. Shiel, Sarutobi Sasuke, Chelsea Clinton, Mussolini, Pierre Guillaume, Mordechai Vanunu, Andrean, Walther von der Vogelweide, Gianlorenzo Bernini, Subramanian Swamy, Louis -Joseph Papineau, Swede Hanson\n",
            "companies     : Viz, the Diamond Jubilee Investment Trust, Spinnaker Software, Dassault Aviation, Starbucks, Epyx, Ocean Software, MIBA, Metro Servicios Turísticos, Verizon Communications, the J. C. Williamson Gilbert, English National Opera, NYGASP, Netscape, Toyota, the Maribor Automobile Factory, USPCC, United States, Herr 's Snacks, Bykea, MMG Mobile Marketing Group, NCR Corporation, SpaceX, the Vandalia Company, Boise Cascade LLC, Wevorce, the Company of Merchant Adventurers, HP, Seadog Ventures, Roland Corporation, Amazon, the National Commercial Bank ( NCB, British, the D'Oyly Carte Opera Company, Apple, Statoil, Goodwin & amp ; Co., Crosfield Electronics, INAX, Google, Panasonic, Optware, Kodak, the Chamber Ballet of Jalisco, Frog, Anigrand, Evojet, General Electric, the Milford Center Lumber and Supply Company, American Tobacco Company, Georgia Pacific, Columbia, Hoseasons, Ryanair, EPB, Vulcan Materials, Alliant Techsystems, Intel, Navient, Pepsi, CEJN AB, Autoliv, COWI, FedEx Express, AT & amp, Nakamichi, Mobile Fidelity\n",
            "countries     : India, the United States, Syria, Jamaica, Trinidad, China, the American Contract Bridge League, Japan, Greece, Australia, Chad, the United Kingdom, West Germany, France, Lebanon, Romania, Cuba, Liberia, French, Turkey, Egypt, Saudi Arabia, Poland, the Czech Republic, South Africa, Canada, Liechtenstein, the Dominican Republic, Afghanistan, Sweden, Ethiopia, Germany, Nigeria, Algeria, Burkina Faso, Croatia, Austria, Ghana, Jordan, Israel, Libya, Kuwait, Belgium, Malta, Ireland, Ukraine, Pakistan, Hamas, Venezuela, Zimbabwe, Russia, Finland, Argentina, Ecuador, Senegal, Barbados, South Korea, Burma, Bahrain, Nepal\n",
            "works         : Robert A. Heinlein 's, Schubert, Moreno Torroba, Brian Ferneyhough 's, Sheer Pluck, Nicholas Nickleby, the Endless Column, the CRC Handbook of Chemistry and Physics, Roberto Rossellini 's, Elizabeth Burgoyne Corbett 's, the `` Psalm of the Cannons `` by Arvi Järventaus, Gilbert and Sullivan for All, the `` Mona Lisa, Newton, Ravel, Masses, Boccaccio, Caroline Norton 's, the Bibliotheca Fratrum Polonorum, Milton, `` The Garden Party, Meno, Rabelais, Hayao Miyazaki 's, the `` Historia Britonum, Death of a Salesman and Grease\n",
            "scholars      : Aurel Stein, Christopher I. Beckwith, Erich Frauwallner, Richard Gombrich, Albrecht Alt, Bender, Marija Gimbutas, Greenwell, Henricus Sedulius, Andrew Lang, Scholem, Howard Hibbard, Gerbert, Hermann of Reichenau, Max Müller, Robert, Hasan, Hasan of Basra, Alfred L. Kroeber, Mobo Gao, Lee Feigon, Claudia Johnson, Julius Wellhausen, Mario Aguilar, Masood Ashraf Raja, Arden L. Bement Jr., German, Sten Konow, George Abraham Grierson, Hermann Jacobi, Ashley Montagu, Brugger, Braulio of Zaragoza, United States, Sandra Harding, Guido Bruck, Gari Ledyard, Sanping Chen, Jin Qiu, Marcuse, Mariano Veytia, David Carrasco, Beattie, Jan Assmann, Isaiah Berlin, Amartya Sen, Abu Bakr ibn al - ‘ Arabi, Jay Tolson, Anne Berthoff, Ekki Lu, Basque, Everett Ferguson, Leland S. Person, García Fernández, Syed Farid Alatas, George Makdisi, J. M. Peñuela, Schuyler V. Cammann, James Romano, Eileen Jensen Krige, Anthony Smith, Douglas North, Anwar Qureshi, Sedulius Scottus, Paul Pelliot, Ho\n",
            "others        : Ananda W. P. Guruge, Cave 16, the University of California , Berkeley, Hammerbrook, Walcher of Malvern, Gordon Baker, Picard, the United Kingdom, Frank Herbert, Julian Barbour, J. Robert Oppenheimer, Sijilmasa, the Bite of Oregon, Donner, London Underground, Gustav Seyffarth, Font Sellabona, Rex Stout, Yoshikazu Kawaguchi, Michael Ghiselin, Nancy Wingate, James Stuart Blackton, Roger Kimball, Charles Holcombe, Godolphin, Frederick Delius, Tom Waits, Angelo Mosca, Iowa, Central Parkway\n",
            "acts          : Mariah Carey, Stevie Wonder, Fünf Sterne, Robert Plant, Asia, Michael Stanley Band , Shoes , Blotto, R.E.M, Pantera , Death, Weezer, Aaliyah, Limp Bizkit and Kid Rock, Lady Gaga, Dream Syndicate, the Dave Clark Five , the Animals, Isaac Hayes, Led Zeppelin, the Gakondo Group, Southside Johnny, Depeche Mode , Queen , King Crimson, Joy Division , New Order, The Frustrators, The Last Poets, The Cure , KISS , The Rolling Stones , The Beatles, Minutemen, Madonna, British, Bruce Springsteen, The Smashing Pumpkins, Missile Girl Scout, Sugar Soul, Dalida\n",
            "artists       : Willie Nelson, James Brown, Jay - Z, Selena Gomez, Nicole Scherzinger, Nick Lowe, André Mare, Ian Hamilton Finlay, François - Bernard Lépicié, Public Enemy, André Breton, Tzara , Picabia , Schwitters , Arp, Kid Rock, Britney Spears, Wayne Thiebaud, John Romita Sr., Jay-Z, The Notorious B.I.G, Baba Saad, Giggs, 150, Dirk Bouts, Al Jourgensen, Timbaland, the Grateful Dead , Incredible String Band , the Rolling Stones , the Move and Traffic, Dickie Valentine, Robert Buelteman, Keith Haring, Bad Company, Muddy Waters, Donatello, Delacroix, Odilon Redon, the Sala Leandre Cristòfol, Joan Manuel Serrat, Thierry Noir, Janet Jackson, Leonardo, Agnolo Bronzino, Korn, Bhuri Bai, Sinn Sisamouth, Cem Karaca, Howie B, Pete Loeffler, Chet Zar, Buzz Osborne, William Blake, Jamini Roy, The Beatles, Ai Weiwei, Jeff Koons, Andy Warhol, Albrecht Dürer, Augustus John, Frans Hals, Metsu, Feng Zikai, U2, Linkin Park, William Turner, Youp, The Prodigy , Cut La Roc, Jacek Malczewski, Jimmy Barnes, Peter Murphy, Gu Kaizhi, Mario Schifano, Carl Perkins, Gene Bilbrew, Cornershop, Army of Freshmen, LeRoy Neiman, Belinda Carlisle, K Koke, Sixpence None the Richer , Chevelle, John Crome, Alexandre Cabanel, Frank Sinatra, Jimi Hendrix, Robert Cray, Marinus Gidding, Little Boots, Mobb Deep, Rihanna, Ryan Adams, Yoann, Paul Klee, Donald Judd, Marcel Duchamp, Bruce Springsteen, Edwin Starr, Johnny Cash, Bill Tytla, Millard Lee, Pearl Buck, Noir\n",
            "organizations : Aide, International Council of Air Shows and European Airshow Council, the Anita Borg Institute, Save the Children, the American Association of Cheerleading Coaches and Advisors, the Ontario Cheerleading Federation ( Ontario, Paul Newman 's, Ecclesia Gnostica Catholica, the Conference of the High Contracting Parties, the Rashtriya Swayamsevak Sangh, The `` Association of Help of Poles in the East Kresy, O.R.A, NATO, UFC, Armies, SIL International, the Commemorative Air Force, the Communist Party, the National Council of Negro Women ( NCNW, Dell, the American Urological Association, the Intersex Society of North America, the Imperial Order of the Daughters of Empire, the Jewish National Fund, the International Colored Gemstone Association ( ICGA, the Appalachian Center for Wilderness Medicine, the American Nurses Credentialing Center, ANSI, UNICEF, the Humane Society of the United States and World Animal Protection, Valencia Nova, the Leipzig Musicians Pension Fund, the Intercollegiate Tennis Association and World TeamTennis, the Ethiopian Lawyers ' Association, the Ku Klux Klan, Lions Clubs International, La Ola, ItalianAware, the National Italian American Foundation, the Mum Festival Committee, Pride FC, Amnesty International, the Federalist Society, the National Health Service, Taproot Foundation\n",
            "leaders       : Gul Agha Sherzai, Walter Reuther, Ali Pasha, Liu Shaoqi, North Korea 's, B. P. Koirala, Elders, Talgat Tadzhuddin, Alvan E. Bovay, Abdurrauf Fitrat, Faizulla Khojayev, Giuseppe Dossetti, Missouri, Gary Hart, Patrick Henry, Peng Zhen, Yalta, Pedro de Alvarado, George T. Ruby, François Guizot, Vicent Doménech el Palleter, Sukarno, William McIntosh, Benson, Ben Bella, Norton P. Chipman, Bill Gothard, Nikolai Bukharin, Osama bin Ladin, Waban, Google, Attacullaculla, Kwame Nkrumah, Atal Bihari Vajpayee, Cungšan\n",
            "states        : Troy, the United Kingdom, Silla, Tyre, France, Burundi, Athens, Indian State of Haryana, Bolivia, Bryan, Tasmania, Florida, South Carolina, Colorado, the Kingdom of Westphalia, Madhya Pradesh, California, Tamil Nadu, Germany, Arizona, New York, Aptera, Georgia, the Dutch Republic, Croatia, Virginia, Alabama, Maryland, Michigan, Ghana, Nigeria, Illinois\n",
            "musicians     : Ry Cooder, Alan Stivell, George Clinton, Coleman Hawkins, Ravi Shankar, John Coltrane, Amorphis, Adam Ant, Elvis Presley, Bob Dylan, Evan Parker, César Isella, Patricio Manns, Aretha Franklin, Kate Bush, Neil Young, Moura Lympany, Louis Armstrong, Richard Wright, Jean Michel Jarre, Juan Atkins, Terri Alard, Elvis Presley , The Beatles, Rosolino, R.E.M, Balin\n",
            "events        : the Walk -A - Thon, the Indianapolis 500, the Cocoanut Grove, Wikimania, the Indo-Pakistani War of 1971, the British - Irish Council, the Great Plague of London, Baronial Arts and Sciences, Shakespeare, the Boston Marathon, the Annual Ball, Jazz, Fiesta San Antonio, the Adelaide 500, the Bathurst 1000, the Paris Commune, New Year 's Eve, the USENIX Annual Technical Conference, the Big Day Out, New Wine Christian festival, the Congreso de Artistas y Trabajadores ( Conference of Artists and Workers, Western, the Greater Manchester Youth Games, the Gaspee Affair, the World Series, Riverbend, Frontier Days, the Union City Arts and Crafts Festival, Broadway, Sweden, the Wadsworth Running Club 's, Chili Cook - off &, Jugaremos en Familia, Santa Paddle, the Ice Breaker Festival\n",
            "bands         : the Backstreet Boys and the Spice Girls, Deep Purple, Mötley Crüe, the Backstreet Boys, Papa Roach, Limp Bizkit, Godsmack, Motograter, Coal Chamber, Korn, Korn and Deftones, Drowning Pool , Coal Chamber, Linkin Park, Jet and The Darkness, Disturbed and Drowning Pool, the Grateful Dead, Pink Floyd, Soft Machine, Hawkwind, Kilburn, Orange Juice, The Jesus & amp, Kleenex / Liliput, The Cranberries, Gregg Allman, Alternative TV, Gone, Bad Brains , Minutemen , Descendents , Meat Puppets, Duran Duran, Orchestral Manoeuvres in the Dark\n",
            "names         : Balcia, San Juan Chamula, Farid Bang, Trowlesworthy Warren, Shoshone, Nike, Leandro Fernández de Moratín, Baulkham Hills, Heliax, Fitzgerald, Wurzbach, the Miami Marlins, the Boston Red Sox, Thomondgate, Eugen, Yunggai, Mexican, Tyzack, Kellond, Pottery Lane, Norman Foster, George Clinton, Fortin, S. Center St., Benny Goodman, Robin Redbreast, Fritz Von Goering, Greg Valentine\n",
            "towns         : Mutare, Devol, Dagnum, Jayapura, Spanish, Tunica Resorts, Cluj -Napoca, Innamincka, Racine, Grays, Wendover, Stralsund, Manchester, South Pass City, Dunkirk, New Braunfels, Towcester, Bexhill - on - Sea, Hailsham, Ashland, Wigan, Pelham, Jumbo , Moyers , Clayton and Albion, Khotan, Hartlepool, Danville, Paisley, Camden, Wellesley, Cut Bank, West New York, Roseto, Watson, Silver City, Salt Lake City, Cantalejo, Arad, Gourock\n",
            "authors       : Peter Ladefoged, Laver, Hesiod, Hervé, Marion Zimmer Bradley, Huber, Sextus Empiricus, J. R. R. Tolkien, Willem Elsschot, Joanna Russ, Orbilius Pupillus, Knud Jeppesen, Thomas Mann, Gemetchu Megerssa, Ernest Renan, Neal Stephenson, Halldorsson et al, R. A. Salvatore, Geoffrey Chaucer, Galen, G. S. Godkin, Octavia Butler, William Hope Hodgson, Lawrence, Lucien Febvre, Bligger von Steinach, Andrew Flood, Johann Geiler, Michael Moorcock, Don DeLillo, Giorgio Bassani, Erwin Schrödinger, John of Ephesus, Geoffrey, J. K. Rowling\n",
            "composers     : Weber, Louis Spohr, Raúl de Ramón, John Dowland, Johann Kaspar Mertz, Federico Moreno Torroba, Manuel Ponce, Hans Werner Henze, Erwin Schulhoff, Nigel Osborne, Claude Debussy, Puccini, Claudio Monteverdi, Giacomo Meyerbeer, Ivan Caryll, Christoph Willibald Gluck, Giovanni Paisiello, Berlioz, Beethoven, Scott Joplin, Isaac Albéniz, Fall, Edward German, Offenbach, Antonio Vivaldi, Debussy, Maxwell Davies, Mozart, Henri Woollett, Edgard Varèse 's, Steve Reich, Fernando Sor, Gonzalo Curiel, Giuseppe Verdi 's, Béla Bartók, Erik Satie, Modest Mussorgsky, J.S, Gustav Mahler, Antonio Bertali\n",
            "areas         : Zakouma National Park, Ocosingo, San Juan Chamula, Santo Domingo, Dalry, Dumbiedykes, Los Angeles, Fredericton, Castile, Jayapura, South Asia, the Nile Delta, Makoshika State Park, Niamey, Toluca, Kandahar, the Taiwan Strait, Australia, Limerick, Human Resource Development, Al -Akhdam, the Central Rim, Glasgow, Papua New Guinea, the Solana Valley, Luanda Kongo, Victor, Bengal, Japan, the North Caucasus, Ghana, the Modoc National Wildlife Refuge, the Iberian System, the Kings Road, Orkney, Cleveland, Boston, Winsford, American Samoa, Iraq, the Board of Health , Board of Social Services, Notting Hill, Garden State Plaza, Santa Maria, Birmingham, Riverside Park, Diamond Valley, the Natural Park\n",
            "groups        : African, Tibesti, Los de Ramón, Jews, PDC, the Jubilee Debt Campaign, the Trilateral Commission, the Provisional IRA, the Blue Lodges, Thespianz Theater, Siger / Sengwer, the Boys ' Brigade and Scouts, Militant, the Spice Girls, the Parents Music Resource Center, Kazakhs, SierraRios, My Ticket Home , Stray from the Path, Abu Sayyaf, the Ifugaos of the Cordillera, the Jimi Hendrix Experience and Cream, Qibla, Gun Control Australia, the Communist Party of Nepal ( Maoist Centre, the Society of St. Pius X, the Neue Forum, Janet Jackson, Al - Anon, the Ellen MacArthur Foundation, the British Royal Society, the World Bank, Sotho, the Opera Quotannis, Helmet , Rollins Band, the Socialist Turner Societies, Armenians, Human Rights Watch, Reclaim, the Swan Theatre Company, the Humane Society, People for the Ethical Treatment of Animals, Hound , Terrier , Working , Herding , Sporting , Non-Sporting, the Red Cross, Human Rights Watch , Landmine Action, the Palestine Liberation Organization, the Victorian Society, UDTJ, the Revolutionary Armed Forces of Colombia, The Dubliners , The Chieftains\n",
            "philosophers  : Shao Yong, Valluvar, Plato, John Rawls, Irving Babbitt, Descartes, John Locke, John Stuart Mill, Wittgenstein, Gorgias, Kant, Alfred Tarski, J.L, Darwin, Jean - Jacques Rousseau, David Lewis, Daniel Dennett, Tibor Machan, Murray Rothbard, Newton da Costa, Voltaire, Rousseau, Ibn Arabi, Thomas Kuhn, Arthur Schopenhauer, Gottlob Frege, Peter Carruthers, Friedrich Nietzsche, Henri Bergson, Immanuel Kant 's\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUipwu-Y8Ga7"
      },
      "source": [
        "Note that the relations above are still expressed in terms of strings, not IDs representing the relevant entities in a knowledgebase. \n",
        "\n",
        "To have fully structured relations, we would need to associate the strings such as \"author\" with knowledge base IDs such as Wikidata [Q482980](https://www.wikidata.org/wiki/Q482980) and make use of normalization information for the named entity mention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU7AMoLj9RZf"
      },
      "source": [
        "## Dependency pattern matching\n",
        "\n",
        "The \"flat\" Hearst patterns succeed in part because the expressions that they match have limited syntactic variability. Let's look at a relation that is commonly expressed in more varied ways, finding strings containing \"married\" between two `PERSON` mentions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SppBI_JR9Qys",
        "outputId": "afdc1212-789d-4587-fd62-b1d08dcd66e4"
      },
      "source": [
        "between_counts = Counter()\n",
        "for sentence, mentions in zip(sentences, mentions_by_sentence):\n",
        "  for i, mention1 in enumerate(mentions):\n",
        "    for j, mention2 in enumerate(mentions[i+1:]):\n",
        "      if mention1.type == 'PERSON' and mention2.type == 'PERSON':\n",
        "        between = sentence[mention1.end:mention2.start]\n",
        "        if 'married' in between:\n",
        "          between_counts[between] += 1\n",
        "\n",
        "\n",
        "for between, count in between_counts.most_common(10):\n",
        "  print(f'{count}\\tPERSON1{between}PERSON2')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "214\tPERSON1 married PERSON2\n",
            "19\tPERSON1 , married PERSON2\n",
            "16\tPERSON1 was married to PERSON2\n",
            "7\tPERSON1 married his first wife , PERSON2\n",
            "6\tPERSON1 had married PERSON2\n",
            "6\tPERSON1 , who married PERSON2\n",
            "5\tPERSON1 is married to PERSON2\n",
            "5\tPERSON1 married his second wife , PERSON2\n",
            "5\tPERSON1 , married to PERSON2\n",
            "4\tPERSON1 married actress PERSON2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mweQDAcAWnL"
      },
      "source": [
        "Here we see much more variability in the linear word sequence. However, if we instead look at dependency analyses for these sentences: (try the [parser demo](http://bionlp-www.utu.fi/parser_demo/) live!):\n",
        "\n",
        "<img width=\"65%\" src=\"https://github.com/TurkuNLP/Text_Mining_Course/raw/master/figs/john-married-jane.png\">\n",
        "\n",
        "We see that the _dependency paths_ connecting the two named entities are much more regular:\n",
        "\n",
        "```\n",
        "John  ←      nsubj ← married → obj → Jane\n",
        "John  ← nsubj:pass ← married → obj → Jane\n",
        "John  ← nsubj:pass ← married → obj → Jane\n",
        "John  ←      nsubj ← married → obj → wife → appos → Jane\n",
        "```\n",
        "\n",
        "(The definitions for the dependency types can be found in the [Universal Dependencies](https://universaldependencies.org/) documentation: [nsubj](https://universaldependencies.org/u/dep/nsubj.html), [nsubj:pass](https://universaldependencies.org/u/dep/nsubj-pass.html), [obj](https://universaldependencies.org/u/dep/obj.html), [appos](https://universaldependencies.org/u/dep/appos.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsbDcIVrLJ-o"
      },
      "source": [
        "The observation that the _shortest dependency path_ connecting two entity mentions contains most of the information regarding their relation (if any) has inspired [many relation extraction methods](https://scholar.google.com/scholar?q=\"shortest+dependency+path\"+\"relation+extraction\").\n",
        "\n",
        "We won't go into full code here, but we can sketch a dependency pattern-based relation extraction approach as follows:\n",
        "\n",
        "---\n",
        "\n",
        "* Write extraction patterns over dependency paths\n",
        "* For each sentence $s$:\n",
        "    * Parse sentence $s$, producing dependency graph $d$\n",
        "    * For each pair of entity mentions in the sentence $(m_1, m_2)$:\n",
        "        * Find the shortest path in $d$ connecting $m_1$ to $m_2$\n",
        "        * Linearize the shortest path (e.g. to `ENTITY1 ← nsubj ← married → obj → ENTITY2`)\n",
        "        * Match each pattern against the dependency path representation and return a relation for each pattern that matches\n",
        "\n",
        "---\n",
        "\n",
        "Note that because dependency paths can be linearized to strings, we can use standard methods such as regular expressions to match patterns also against dependency paths. Alternatively, we could use dedicated tools such as [Tregex](https://nlp.stanford.edu/software/tregex.shtml)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDplWzPpeWDZ"
      },
      "source": [
        "## Open Information Extraction\n",
        "\n",
        "The rule-based approaches considered above have required us to specify the relation types in advance, e.g. through keywords or patters for each type. By contrast, Open Information Extraction (Open IE) methods aim to identify _any_ relation stated in text, extracting the relation type along with the participating entities.\n",
        "\n",
        "Open IE methods can operate over the linear sequence of words (making use of e.g. part-of-speech patterns) or over syntactic structures, such as in the following example from the [Stanford Open IE system](https://nlp.stanford.edu/software/openie.html):\n",
        "\n",
        "<img width=\"90%\" src=\"https://nlp.stanford.edu/static/img/openie.png\">\n",
        "\n",
        "(Figure from https://nlp.stanford.edu/software/openie.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z7KXDGeiYsg"
      },
      "source": [
        "Open IE is at its best when applied to very large corpora. Instead of trying to run a large-scale implementation in this notebook, let's have a look at the results of the [ReVerb](http://reverb.cs.washington.edu/) Open IE system applied to 500 million web pages on this demo site: https://openie.allenai.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvcRsB2hjowY"
      },
      "source": [
        "While Open IE systems have mostly been developed for English, the introduction of the cross-lingually consistent [Universal Dependencies](https://universaldependencies.org/) resources has made it possible to write Open IE rules in a (largely) language-independent way. [PredPatt](https://github.com/hltcoe/PredPatt) implements one such approach; we'll have a brief practical look at it next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyPp6tmery5D"
      },
      "source": [
        "Install the PredPatt library (with some changes for better support for Finnish)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN40ER_tl8Zm",
        "outputId": "8c77d10b-0ee4-400f-f587-382b4f68fdf0"
      },
      "source": [
        "!pip install --quiet git+https://github.com/spyysalo/PredPatt.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 368kB 11.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 22.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 27.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 6.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1MB 35.7MB/s \n",
            "\u001b[?25h  Building wheel for predpatt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for concrete (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0tl4U3MtPev"
      },
      "source": [
        "Add a `parse_sentence` function using the [Turku Neural parser](http://turkunlp.org/Turku-neural-parser-pipeline/) as a web service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BpJB6eZkbQT"
      },
      "source": [
        "!pip install --quiet requests\n",
        "\n",
        "import requests\n",
        "from predpatt import load_conllu\n",
        "\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    SERVER_URL = 'http://86.50.253.19:8002/parser/parse'\n",
        "    response = requests.post(SERVER_URL, data={ 'text': sentence })\n",
        "    return load_conllu(response.text)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY99XrndtY6f"
      },
      "source": [
        "(**NOTE**: if you're running this after the 2021 spring course, this service is likely no longer available at the above URL.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5hhQk_YtqjE"
      },
      "source": [
        "Parse example sentences using the Turku parser, and extract relations from each parse using PredPatt.\n",
        "\n",
        "(The technical details are not important here; this is just demonstrating an Open IE approach for Finnish.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tF441cYkj1S",
        "outputId": "57658851-2cd0-4d80-b3bb-6f986f1b2c1c"
      },
      "source": [
        "from predpatt import PredPatt, PredPattOpts\n",
        "\n",
        "\n",
        "# PredPatt options\n",
        "options = PredPattOpts(\n",
        "  resolve_relcl=True,\n",
        "  resolve_appos=True,\n",
        "  resolve_conj=True,\n",
        "  ud='2.0'\n",
        ")\n",
        "\n",
        "\n",
        "# Function to format PredPatt result as a string\n",
        "def format_predicate(predicate):\n",
        "  rel = '-'.join(token.text for token in predicate.tokens)\n",
        "  args = []\n",
        "  for argument in predicate.arguments:\n",
        "    args.append(' '.join(token.text for token in argument.tokens))\n",
        "  arg_string = ', '.join(args)\n",
        "  return f'{rel}({arg_string})'\n",
        "\n",
        "\n",
        "# Try changing these!\n",
        "example_sentences = [\n",
        "  'Turun yliopisto perustettiin vuonna 1920.',\n",
        "  'Turun kampus sijaitsee Yliopistonmäen läheisyydessä.',\n",
        "  'Turun yliopisto toimii Turussa, Raumalla ja Porissa.',\n",
        "]\n",
        "\n",
        "\n",
        "for sentence in example_sentences:\n",
        "  for id_, parse in parse_sentence(sentence):\n",
        "    ppatt = PredPatt(parse, opts=options)\n",
        "    print(sentence)\n",
        "    for predicate in ppatt.instances:\n",
        "      print('→', format_predicate(predicate))\n",
        "    print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Turun yliopisto perustettiin vuonna 1920.\n",
            "→ perustettiin(Turun yliopisto, vuonna 1920)\n",
            "\n",
            "Turun kampus sijaitsee Yliopistonmäen läheisyydessä.\n",
            "→ sijaitsee(Turun kampus, Yliopistonmäen läheisyydessä)\n",
            "\n",
            "Turun yliopisto toimii Turussa, Raumalla ja Porissa.\n",
            "→ toimii(Turun yliopisto, Turussa)\n",
            "→ toimii(Turun yliopisto, Raumalla)\n",
            "→ toimii(Turun yliopisto, Porissa)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PXKi4tYuOJE"
      },
      "source": [
        "Note again that these extractions are just strings; to enter the extracted relations into a knowledge base, we would need to map the text spans to normalized entity mentions and relation IDs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zxUh9VWzOeE"
      },
      "source": [
        "---\n",
        "\n",
        "# Relation extraction using machine learning\n",
        "\n",
        "The most accurate relation extraction methods are based on supervised machine learning, i.e. models trained on examples of which relations to extract from documents.\n",
        "\n",
        "We'll here first look at two options for annotating data for relation extraction, and then sketch a machine learning approach for learning to extract relations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf3Ky7SgzQ_M"
      },
      "source": [
        "## Relation annotation\n",
        "\n",
        "Like all supervised machine learning approaches, ML-based relation extraction methods must be trained on examples of inputs with correct outputs. Recall that in our task setting, the input includes document texts $d$ and entity mentions $M_d = \\{m_1, m_2, \\ldots, m_n \\}$ in each document.\n",
        "\n",
        "We will then assume that the output consists of typed binary relations $R_d \\subset T \\times M_d \\times M_d$ where $T$ is the set of types. We could for example have $T = \\{$ `employee`, `owner`, `founder` $\\}$ for person-organization relations.\n",
        "\n",
        "Using a **document-oriented** annotation approach (here the open-source tool [brat](https://brat.nlplab.org)), our starting point could then look like the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV_dXrPF5tGi"
      },
      "source": [
        "<img width=\"65%\" src=\"https://github.com/TurkuNLP/Text_Mining_Course/raw/master/figs/relation-annotation-empty.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwlPczXY6hmb"
      },
      "source": [
        "We would then read the text of the documents (here, sentences) and mark all applicable relations:\n",
        "\n",
        "<img width=\"65%\" src=\"https://github.com/TurkuNLP/Text_Mining_Course/raw/master/figs/relation-annotation-complete.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUtlHlV663Ce"
      },
      "source": [
        "The annotated relations are then positive examples for machine learning:\n",
        "\n",
        "```\n",
        "founder(Bill Gates, Microsoft)\n",
        "founder(Paul Allen, Microsoft)\n",
        "employee(Steve Ballmer, Microsoft)\n",
        "```\n",
        "\n",
        "Here, we have not explicitly marked any _negative_ examples. For training machine learning methods, negatives are instead generated using the _closed world assumption_: any relation that is not explicitly present is assumed to be negative, including e.g.\n",
        "\n",
        "```\n",
        "founder(Allen, IBM)\n",
        "employee(Allen, IBM)\n",
        "owner(Allen, IBM)\n",
        "...\n",
        "founder(Steve Ballmer, Microsoft)\n",
        "owner(Steve Ballmer, Microsoft)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "946fBx5s9Dp2"
      },
      "source": [
        "Alternatively, we can take a **relation-oriented** annotation approach (here using [Prodigy](https://prodi.gy/)), where the tool prompts the annotator to identify the type of relation (if any) that holds between two entities:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMM71dtnVJh0"
      },
      "source": [
        "<img width=\"65%\" src=\"https://github.com/TurkuNLP/Text_Mining_Course/raw/master/figs/prodigy-typed-relation-annotation.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5JQIL0_VTlw"
      },
      "source": [
        "Here negative examples are explicitly marked by the annotator (label `NONE`). While this approach thus requires the annotator to enter a larger number of labels, individual decisions can be faster to enter, and the explicitness can help reduce errors of omission.\n",
        "\n",
        "This approach can be carried further by incorporating the type of the relation into the prompt, only asking the annotator whether a `(relation, mention-1, mention-2)` triple holds or not. In this case, the decision can be a simple binary yes/no, further accelerating the annotation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKjG5UlObCZs"
      },
      "source": [
        "## Machine learning task formulation\n",
        "\n",
        "Given manually annotated examples where each consists of\n",
        "\n",
        "* Document text $d$\n",
        "* Two entity mentions in that document, $m_1$ and $m_2$\n",
        "* Relation type (e.g. `employee`) or `NONE` to signify no relation\n",
        "\n",
        "relation extraction can be formulated as a classification task by creating an representation of the mentions $m_1$ and $m_2$ in their context ($d$) as input and the relation type (or `NONE`) as output. (Note that this assumes at most one relation type holds per entity pair.)\n",
        "\n",
        "In previous state-of-the-art approaches, considerable effort was invested into creating representations of the mentions in context for ML methods, frequently involving e.g. carefully engineered representations of dependency paths.\n",
        "\n",
        "Fortunately for us, with recent Transformer-based approaches such as BERT, these representations can be simplified into marking the entities in the original text in some way, and providing the text with marked entities to the model as input.\n",
        "\n",
        "For example, given\n",
        "\n",
        "* Document text $d$ = `Bill Gates and Paul Allen founded Microsoft`\n",
        "* Mentions $m_1$ = `(0, 10, PERSON, Bill Gates)` and $m_2$ = `(34, 43, ORG, Microsoft)`\n",
        "* Relation type `founder`\n",
        "\n",
        "We could formulate the classification example e.g. as\n",
        "\n",
        "* input: `PERSON and Paul Allen founded ORGANIZATION`\n",
        "* output: `founder`\n",
        "\n",
        "Here using the literal type strings `PERSON` and `ORGANIZATION` to mark the two mentions under consideration. (Note that other mentions in context are not marked.)\n",
        "\n",
        "## Project work\n",
        "\n",
        "As the course project involves implementing a relation extraction system along the lines outlined above, we will not provide an implementation here. You may find the previously covered notebooks on text classification helpful as references for your implementation.\n",
        "\n",
        "(We will provide support for annotating training and evaluation data for your project work.)"
      ]
    }
  ]
}