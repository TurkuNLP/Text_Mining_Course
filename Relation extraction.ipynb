{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation extraction\n",
    "* Goal: find meaningful associations between named entities\n",
    "* Co-occurrences will already tell us something\n",
    "    * Entity pairs appearing in the same context (e.g. sentences) often tend to be somehow related\n",
    "    * Type of association will remain a mystery\n",
    "* Usually we have a predefined set of relation types we are interested in\n",
    "    * Specific to our domain of interest\n",
    "    * E.g. located-at/in, subsidiary, works-at\n",
    "\n",
    "# RE as a classification task\n",
    "* First we generate all relevant entity pairs\n",
    "    * Usually from a single sentence\n",
    "    * Note: if we are looking for works-at relations, it makes no sense to generate ORG-ORG pairs etc.\n",
    "* For each pair a classification makes a decision: relation exists (and type) or no relation\n",
    "* Which pairs to consider here: Frank and James worked for Comcast, not for Time Warner.\n",
    "* Features should now capture some information about the association of the given entity pair in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets give it a try with our familiar TFIDF vectors\n",
    "* Our data consists of biomedical publications and we want to find out where different types of bacteria live in\n",
    "    * i.e. find the relations between bacteria and habitat entities\n",
    "    * Take a look: [http://evexdb.org/curation/brat/#/bb2016/train_brat/BB-event-18845825](http://evexdb.org/curation/brat/#/bb2016/train_brat/BB-event-18845825)\n",
    "    * Or here: [http://evexdb.org/curation/brat/#/bb2016/train_brat/BB-event-19175621](http://evexdb.org/curation/brat/#/bb2016/train_brat/BB-event-19175621)\n",
    "* Only one relation type, so our problem is a binary classification task\n",
    "* Would it make sense to see what words appear between the given entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.etree import cElementTree as ET\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from gzip import GzipFile\n",
    "from itertools import product, tee, izip\n",
    "import scipy\n",
    "import networkx as nx\n",
    "\n",
    "def open_xml(input_xml):\n",
    "    if input_xml.endswith('.gz'):\n",
    "        with GzipFile(input_xml) as xml_file:\n",
    "            tree = ET.parse(xml_file)\n",
    "    else:\n",
    "        tree = ET.parse(input_xml)\n",
    "    return tree\n",
    "\n",
    "def generate_pairs(tree, features='tfidf', vectorizer=None):\n",
    "    \"\"\"\n",
    "    Generates all pairs for relation classification.\n",
    "    \"\"\"\n",
    "    if features == 'tfidf' and vectorizer == None:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "        documents = [d.get('text') for d in tree.findall('document')]\n",
    "        vectorizer.fit(documents)\n",
    "    \n",
    "    labels = []\n",
    "    feature_matrix = []\n",
    "    \n",
    "    for sentence in tree.findall('.//sentence'):\n",
    "        bacteria = sentence.findall('entity[@type=\"Bacteria\"]')\n",
    "        hab = sentence.findall('entity[@type=\"Habitat\"]') + sentence.findall('entity[@type=\"Geographical\"]')\n",
    "        for i, (b, h) in enumerate(product(bacteria, hab)):\n",
    "            #import pdb; pdb.set_trace()\n",
    "            if sentence.find('interaction[@e1=\"%s\"][@e2=\"%s\"][@type=\"Lives_In\"]' % (b.get('id'), h.get('id'))) != None:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "            if features == 'tfidf':\n",
    "                feature_matrix.append(tfidf_features(b, h, sentence, vectorizer))\n",
    "            else:\n",
    "                feature_matrix.append(parse_features(b, h, sentence))\n",
    "    \n",
    "    if features != 'tfidf':\n",
    "        if vectorizer == None:\n",
    "            vectorizer = DictVectorizer()\n",
    "            vectorizer.fit(feature_matrix)\n",
    "        feature_matrix = vectorizer.transform(feature_matrix)\n",
    "    \n",
    "    return labels, scipy.sparse.vstack(feature_matrix), vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tfidf features for the words occurring between the given entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_features(bacteria, habitat, sentence, vectorizer):\n",
    "    \"\"\"\n",
    "    Builds tfidf vectors for the words between the entities.\n",
    "    \"\"\"\n",
    "    b_beg, b_end = bacteria.get('charOffset').split(',')[0].split('-')\n",
    "    h_beg, h_end = habitat.get('charOffset').split(',')[0].split('-')\n",
    "\n",
    "    if b_beg < h_beg:\n",
    "        text_between = sentence.get('text')[int(b_end)+1:int(h_beg)]\n",
    "    else:\n",
    "        text_between = sentence.get('text')[int(h_end)+1:int(b_beg)]\n",
    "    \n",
    "    return vectorizer.transform([text_between])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation extraction with TFIDF vectors\n",
      "Number of features: 21746\n",
      "Devel set: 506 examples, 173 positive, 333 negative\n",
      "Random baseline accuracy: 47.628, f-score: 37.762\n",
      "All positive baseline accuracy: 34.190, f-score: 50.957\n",
      "C: 2^-15  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-14  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-13  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-12  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-11  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-10  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-9  Accuracy: 65.810  F-score: 0.000\n",
      "C: 2^-8  Accuracy: 65.810  F-score: 7.487\n",
      "C: 2^-7  Accuracy: 67.194  F-score: 16.162\n",
      "C: 2^-6  Accuracy: 68.972  F-score: 25.592\n",
      "C: 2^-5  Accuracy: 69.368  F-score: 29.864\n",
      "C: 2^-4  Accuracy: 69.565  F-score: 33.621\n",
      "C: 2^-3  Accuracy: 69.565  F-score: 35.833\n",
      "C: 2^-2  Accuracy: 69.763  F-score: 38.554\n",
      "C: 2^-1  Accuracy: 69.368  F-score: 39.216\n",
      "C: 2^0  Accuracy: 68.972  F-score: 37.450\n",
      "C: 2^1  Accuracy: 69.170  F-score: 38.095\n",
      "C: 2^2  Accuracy: 67.984  F-score: 37.209\n",
      "C: 2^3  Accuracy: 68.972  F-score: 39.382\n",
      "C: 2^4  Accuracy: 69.170  F-score: 40.000\n",
      "C: 2^5  Accuracy: 68.775  F-score: 39.695\n",
      "C: 2^6  Accuracy: 68.775  F-score: 39.695\n",
      "C: 2^7  Accuracy: 68.775  F-score: 39.231\n",
      "C: 2^8  Accuracy: 70.949  F-score: 38.494\n",
      "C: 2^9  Accuracy: 40.316  F-score: 52.665\n",
      "C: 2^10  Accuracy: 68.972  F-score: 25.592\n",
      "C: 2^11  Accuracy: 67.391  F-score: 12.698\n",
      "C: 2^12  Accuracy: 71.344  F-score: 39.834\n",
      "C: 2^13  Accuracy: 71.542  F-score: 40.496\n",
      "C: 2^14  Accuracy: 67.787  F-score: 20.488\n"
     ]
    }
   ],
   "source": [
    "print \"Relation extraction with TFIDF vectors\"\n",
    "\n",
    "train_tree = open_xml('BB_EVENT_16-train.xml')\n",
    "train_labels, train_features, train_vectorizer = generate_pairs(train_tree)\n",
    "\n",
    "print \"Number of features: %s\" % train_features.shape[1]\n",
    "\n",
    "devel_tree = open_xml('BB_EVENT_16-devel.xml')\n",
    "devel_labels, devel_features = generate_pairs(devel_tree, vectorizer=train_vectorizer)[:2]\n",
    "\n",
    "print \"Devel set: %s examples, %s positive, %s negative\" % (len(devel_labels), devel_labels.count(1), devel_labels.count(0))\n",
    "\n",
    "baseline = DummyClassifier(strategy='uniform')\n",
    "baseline.fit(train_features, train_labels)\n",
    "print 'Random baseline accuracy: %.3f, f-score: %.3f' % (baseline.score(devel_features, devel_labels)*100,\n",
    "                                                  metrics.f1_score(devel_labels, baseline.predict(devel_features))*100)\n",
    "\n",
    "print 'All positive baseline accuracy: %.3f, f-score: %.3f' % (metrics.accuracy_score(devel_labels, [1]*len(devel_labels))*100,\n",
    "                                                  metrics.f1_score(devel_labels, [1]*len(devel_labels))*100)\n",
    "\n",
    "for c in range(-15, 15):\n",
    "    classifier = LinearSVC(C=2**c, random_state=42)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    pred = classifier.predict(devel_features)\n",
    "    print \"C: 2^%s  Accuracy: %.3f  F-score: %.3f\" % (c, metrics.accuracy_score(devel_labels, pred)*100,\n",
    "                                                      metrics.f1_score(devel_labels, pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is pretty poor metric in this case: the class distribution is not uniform and in the end we are interested only in the positive class (Lives_In relation).\n",
    "\n",
    "F-score not familiar? Check this: [https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency parses to the rescue!\n",
    "* The same semantic relation of two entities can be expressed in limitless ways\n",
    "* Just looking at the words between the entities won't cut it\n",
    "* Lets have a look at this sentence and assume we are interested in the relation between ATR and Nor1 proteins:\n",
    "<img src=\"figs/parse_path.png\">\n",
    "* In linear order there are 12 tokens between these entities. Most likely the same word sequence won't appear anywhere else in the whole biomedical literature.\n",
    "* On the other hand looking at the shortest dependency path between the same entities has only 3 tokens separating them\n",
    "    * Using dependencies tends to densify our feature space\n",
    "    * Dependency types are also a strong indicator of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get back to our task, this time with a bigger hammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_features(bacteria, habitat, sentence):\n",
    "    \"\"\"\n",
    "    Builds simple dependency path features for the pair.\n",
    "    \"\"\"\n",
    "    b_head_token = sentence.find('.//token[@charOffset=\"%s\"]' % bacteria.get('headOffset'))\n",
    "    h_head_token = sentence.find('.//token[@charOffset=\"%s\"]' % habitat.get('headOffset'))\n",
    "\n",
    "    graph, token_dict = _build_graph(sentence)\n",
    "\n",
    "    path = nx.shortest_path(graph, source=b_head_token.get('id'), target=h_head_token.get('id'))\n",
    "    \n",
    "    edges = []\n",
    "    for t1, t2 in pairwise(path):\n",
    "        edge = graph.edge[t1][t2]\n",
    "        if edge['direction'][0] == t1:\n",
    "            direction = '>'\n",
    "        else:\n",
    "            direction = '<'\n",
    "        \n",
    "        edges.append((token_dict[t1], token_dict[t2], direction, edge['type']))\n",
    "\n",
    "\n",
    "    features = {}\n",
    "    for e in edges:\n",
    "        features[e[2]+e[3]] = 1 # Undirected dependency unigram\n",
    "        features[e[3]] = 1 # Directed dep unigram\n",
    "    \"\"\"\n",
    "        features['W_'+e[1].get('text')] = 1 # Word unigrams along the dep path\n",
    "\n",
    "    # Dependency bigrams\n",
    "    for i in range(len(edges)-1):\n",
    "        path_string = '.'.join(p[3] for p in edges[i:i+1])\n",
    "        features['D_ngram_:'+path_string] = 1\n",
    "\n",
    "    # Dependency trigrams\n",
    "    for i in range(len(edges)-2):\n",
    "        path_string = '.'.join(p[3] for p in edges[i:i+2])\n",
    "        features['D_ngram_:'+path_string] = 1\n",
    "    \"\"\"\n",
    "\n",
    "    return features\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return izip(a, b)\n",
    "\n",
    "def _build_graph(sentence):\n",
    "    \"\"\"\n",
    "    Builds a graph from the syntactic parse.\n",
    "    \"\"\"\n",
    "    graph = nx.Graph() # undirected graph, since we want to find undirected shortest paths\n",
    "    \n",
    "    analyses = sentence.find('analyses')\n",
    "    tokenization = analyses.find('tokenization')\n",
    "    tokens = tokenization.findall('token')\n",
    "    \n",
    "    token_dict = {t.attrib['id']: t for t in tokens}\n",
    "    \n",
    "    for token in tokens:\n",
    "        graph.add_node(token.attrib['id'])\n",
    "        \n",
    "    parses = analyses.find('parse')\n",
    "    dependencies = parses.findall('dependency')\n",
    "    for d in dependencies:\n",
    "        graph.add_edge(d.attrib['t1'], d.attrib['t2'], id=d.attrib['id'], type=d.attrib['type'],\n",
    "                       direction=(d.attrib['t1'], d.attrib['t2']))\n",
    "\n",
    "    return graph, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation extraction with parse features\n",
      "Number of features: 163\n",
      "C: 2^-15  Accuracy: 67.589  F-score: 21.154\n",
      "C: 2^-14  Accuracy: 68.577  F-score: 26.047\n",
      "C: 2^-13  Accuracy: 68.577  F-score: 32.340\n",
      "C: 2^-12  Accuracy: 69.170  F-score: 37.097\n",
      "C: 2^-11  Accuracy: 67.391  F-score: 38.662\n",
      "C: 2^-10  Accuracy: 67.984  F-score: 43.750\n",
      "C: 2^-9  Accuracy: 67.787  F-score: 46.557\n",
      "C: 2^-8  Accuracy: 67.787  F-score: 48.903\n",
      "C: 2^-7  Accuracy: 68.182  F-score: 52.226\n",
      "C: 2^-6  Accuracy: 67.984  F-score: 53.179\n",
      "C: 2^-5  Accuracy: 67.391  F-score: 53.782\n",
      "C: 2^-4  Accuracy: 67.589  F-score: 56.614\n",
      "C: 2^-3  Accuracy: 67.391  F-score: 56.693\n",
      "C: 2^-2  Accuracy: 66.008  F-score: 53.763\n",
      "C: 2^-1  Accuracy: 65.020  F-score: 52.291\n",
      "C: 2^0  Accuracy: 64.229  F-score: 51.733\n",
      "C: 2^1  Accuracy: 65.217  F-score: 53.439\n",
      "C: 2^2  Accuracy: 65.613  F-score: 54.211\n",
      "C: 2^3  Accuracy: 64.625  F-score: 52.520\n",
      "C: 2^4  Accuracy: 64.032  F-score: 52.105\n",
      "C: 2^5  Accuracy: 64.229  F-score: 48.433\n",
      "C: 2^6  Accuracy: 64.625  F-score: 46.884\n",
      "C: 2^7  Accuracy: 60.079  F-score: 48.731\n",
      "C: 2^8  Accuracy: 60.277  F-score: 44.321\n",
      "C: 2^9  Accuracy: 61.462  F-score: 53.461\n",
      "C: 2^10  Accuracy: 61.067  F-score: 52.530\n",
      "C: 2^11  Accuracy: 61.462  F-score: 46.281\n",
      "C: 2^12  Accuracy: 57.708  F-score: 40.223\n",
      "C: 2^13  Accuracy: 62.055  F-score: 28.889\n",
      "C: 2^14  Accuracy: 62.253  F-score: 29.520\n"
     ]
    }
   ],
   "source": [
    "print \"Relation extraction with parse features\"\n",
    "train_labels, train_features, train_vectorizer = generate_pairs(train_tree, features='parse')\n",
    "devel_labels, devel_features = generate_pairs(devel_tree, vectorizer=train_vectorizer, features='parse')[:2]\n",
    "\n",
    "print \"Number of features: %s\" % train_features.shape[1]\n",
    "\n",
    "for c in range(-15, 15):\n",
    "    classifier = LinearSVC(C=2**c, random_state=42)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    pred = classifier.predict(devel_features)\n",
    "    print \"C: 2^%s  Accuracy: %.3f  F-score: %.3f\" % (c, metrics.accuracy_score(devel_labels, pred)*100,\n",
    "                                                      metrics.f1_score(devel_labels, pred)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without showing a single word to the classifier we ended up with an F-score of 56.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<abbrev', '<advcl', '<advmod', '<agent', '<amod', '<appos', '<ccomp', '<conj_and', '<csubj', '<dep', '<dobj', '<hyphen', '<infmod', '<nn', '<nsubj', '<nsubjpass', '<num', '<parataxis', '<partmod', '<pobj', '<prep', '<prep_after', '<prep_against', '<prep_among', '<prep_as', '<prep_at', '<prep_before', '<prep_by', '<prep_due_to', '<prep_during', '<prep_followed_by', '<prep_for', '<prep_from', '<prep_in', '<prep_in_addition_to', '<prep_of', '<prep_on', '<prep_throughout', '<prep_to', '<prep_with', '<prep_within', '<prepc_for', '<prepc_in', '<prepc_with', '<purpcl', '<rcmod', '<xcomp', '<xsubj', '>abbrev', '>advcl', '>advmod', '>agent', '>amod', '>appos', '>ccomp', '>conj_and', '>conj_but', '>csubj', '>dep', '>dobj', '>hyphen', '>infmod', '>nn', '>npadvmod', '>nsubj', '>nsubjpass', '>parataxis', '>partmod', '>pobj', '>poss', '>prep_against', '>prep_among', '>prep_as', '>prep_before', '>prep_between', '>prep_by', '>prep_for', '>prep_from', '>prep_in', '>prep_including', '>prep_inside', '>prep_into', '>prep_of', '>prep_on', '>prep_than', '>prep_to', '>prep_under', '>prep_upon', '>prep_via', '>prep_with', '>prep_within', '>prepc_by', '>prepc_for', '>prepc_in', '>prepc_with', '>purpcl', '>rcmod', '>rel', '>tmod', '>xcomp', '>xsubj', 'abbrev', 'advcl', 'advmod', 'agent', 'amod', 'appos', 'ccomp', 'conj_and', 'conj_but', 'csubj', 'dep', 'dobj', 'hyphen', 'infmod', 'nn', 'npadvmod', 'nsubj', 'nsubjpass', 'num', 'parataxis', 'partmod', 'pobj', 'poss', 'prep', 'prep_after', 'prep_against', 'prep_among', 'prep_as', 'prep_at', 'prep_before', 'prep_between', 'prep_by', 'prep_due_to', 'prep_during', 'prep_followed_by', 'prep_for', 'prep_from', 'prep_in', 'prep_in_addition_to', 'prep_including', 'prep_inside', 'prep_into', 'prep_of', 'prep_on', 'prep_than', 'prep_throughout', 'prep_to', 'prep_under', 'prep_upon', 'prep_via', 'prep_with', 'prep_within', 'prepc_by', 'prepc_for', 'prepc_in', 'prepc_with', 'purpcl', 'rcmod', 'rel', 'tmod', 'xcomp', 'xsubj']\n"
     ]
    }
   ],
   "source": [
    "print train_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEES\n",
    "* Feature engineering for relation extraction is painful\n",
    "* Luckily there are free tools available\n",
    "* One of them is [TEES (Turku Event Extraction System)](http://jbjorne.github.io/TEES/)\n",
    "    * Warning: comes bundled with tools specifically trained for biomedical domain, use your own parser etc. for other purposes\n",
    "    * Uses the same XML format seen in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEES system\n",
      "TEES accuracy: 77.075, f-score: 68.478\n"
     ]
    }
   ],
   "source": [
    "print \"TEES system\"\n",
    "TEES_tree = open_xml('devel-pred.xml.gz')\n",
    "TEES_labels, TEES_features = generate_pairs(TEES_tree, vectorizer=train_vectorizer, features='parse')[:2]\n",
    "print 'TEES accuracy: %.3f, f-score: %.3f' % (metrics.accuracy_score(devel_labels, TEES_labels)*100,\n",
    "                                              metrics.f1_score(devel_labels, TEES_labels)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, no competition here... Then again, TEES uses ~40K features for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVEX\n",
    "* Biomedical events extracted from the whole biomedical literature\n",
    "    * Imagine an event as a collection of pairwise relations between genes and proteins\n",
    "* Website: [http://www.evexdb.org/](http://www.evexdb.org/)\n",
    "* The fun begins when you start looking into things on a large-scale:\n",
    "<img src=\"figs/network.png\">\n",
    "* This is an automatically produced gene regulatory network with 13K human genes and 236K relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: so, what are these events?\n",
    "* Have a look at this sentence: Kuluttajatuotteita kotiin, puutarhaan ja ulkoiluun valmistavan Fiskarsin liikevaihto kasvoi heinä–syyskuussa 62 prosenttia verrattuna vuoden takaiseen ajankohtaan.\n",
    "* Rough translation: ... Fiskars increased its revenue by 62% compared to the previous year during Q3.\n",
    "* Relevant entities here are Fiskars (organization), 62% (amount), Q3 (time)\n",
    "* How would you represent this information structurally? Binary relations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What next?\n",
    "* Annotating text-level mentions of entity relations is extremely labor-intensive\n",
    "* In many cases we just don't have the training data for supervised relation classification\n",
    "* Next week we'll look into unsupervised or distantly supervised alternatives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
